{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "from params import args\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train_proc_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = pd.read_csv('data/depths.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.merge(depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[test.z==63].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(args.masks_dir,'{}.png'.format('88839f49f9'))\n",
    "m = cv2.imread(path, cv2.IMREAD_GRAYSCALE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.augmentation_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from params import args\n",
    "from augmentations import get_augmentations\n",
    "def read_image(path, input_size):\n",
    "    img = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    # img = cv2.resize(img, input_size)\n",
    "    # [:,:,::-1]\n",
    "\n",
    "    return img\n",
    "    \n",
    "def read_mask(path, input_size):\n",
    "    mask = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    # mask = cv2.resize(mask, input_size)\n",
    "\n",
    "    return mask  \n",
    "\n",
    "id = '0f5ada4dc3'\n",
    "\n",
    "# Read with resizing\n",
    "img = read_image(os.path.join(args.images_dir,'{}.png'.format(id)), None)\n",
    "mask = read_mask(os.path.join(args.masks_dir,'{}.png'.format(id)), None)\n",
    "\n",
    "plt.figure(figsize=(3,3))\n",
    "plt.imshow(img)\n",
    "\n",
    "print(img[0][0])\n",
    "\n",
    "# Random Crops during training\n",
    "augs = get_augmentations(args.augmentation_name, p=args.augmentation_prob, input_shape=(args.input_size, args.input_size, 3))\n",
    "\n",
    "if augs:\n",
    "    data = {\"image\": img, \"mask\": mask}\n",
    "    augmented = augs(**data)\n",
    "    img, mask = augmented[\"image\"], augmented[\"mask\"]\n",
    "    \n",
    "plt.figure(figsize=(3,3))\n",
    "plt.imshow(img)\n",
    "print(img[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train.sort_values('rle_mask')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "borders = []\n",
    "all_imgs_test = []\n",
    "\n",
    "for id in test[test.z==942].id.values:\n",
    "    path = os.path.join(args.test_folder,'{}.png'.format(id))\n",
    "    img = cv2.imread(path, cv2.IMREAD_COLOR)    \n",
    "    all_imgs_test.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "borders = []\n",
    "all_imgs_train = []\n",
    "\n",
    "for id in train[train.z==942].id.values:\n",
    "    path = os.path.join(args.images_dir,'{}.png'.format(id))\n",
    "    path_mask = os.path.join(args.masks_dir,'{}.png'.format(id))\n",
    "    img = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    mask = cv2.imread(path_mask, cv2.IMREAD_GRAYSCALE)     \n",
    "    all_imgs_train.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.hstack([all_imgs_test[-1],all_imgs_train[-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.hstack(all_imgs_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.hstack(all_imgs_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "borders = []\n",
    "\n",
    "for id in train[train.z==63].id.values:\n",
    "    path = os.path.join(args.images_dir,'{}.png'.format(id))\n",
    "    path_mask = os.path.join(args.masks_dir,'{}.png'.format(id))\n",
    "    img = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    mask = cv2.imread(path_mask, cv2.IMREAD_GRAYSCALE)     \n",
    "    \n",
    "    plt.figure(figsize=(4,4))\n",
    "    plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train.sort_values('z')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "borders = []\n",
    "\n",
    "for id in train.id.values:\n",
    "    path = os.path.join(args.images_dir,'{}.png'.format(id))\n",
    "    path_mask = os.path.join(args.masks_dir,'{}.png'.format(id))\n",
    "    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    mask = cv2.imread(path_mask, cv2.IMREAD_GRAYSCALE)     \n",
    "    \n",
    "    up_border = img[0,:]\n",
    "    down_border = img[-1,:]\n",
    "    left_border = img[:,0]\n",
    "    right_border = img[:,-1]\n",
    "    \n",
    "    borders.extend(up_border,down_border,left_border,right_border)\n",
    "\n",
    "# prepare df with all data\n",
    "lens = [len(border) for border in borders]\n",
    "img_idx = list(range(len(border)//4))*4\n",
    "position = ['up','down','left','right']*len(len(border)//4)\n",
    "nn = [None]*len(position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img[0,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height, width = img.shape[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_raw_data(image_size=(101, 101), space = 'bgr',load_mask=True):\n",
    "    \"\"\"Load raw data.\"\"\"\n",
    "    # Python lists to store the training images/masks and test images.\n",
    "    x_train, y_train, x_test = [],[],[]\n",
    "\n",
    "    for id in tqdm.tqdm_notebook(train.id.values):\n",
    "        path = os.path.join(args.images_dir,'{}.png'.format(id))\n",
    "        path_mask = os.path.join(args.masks_dir,'{}.png'.format(id))\n",
    "        img = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "        if load_mask:\n",
    "            mask = cv2.imread(path_mask, cv2.IMREAD_GRAYSCALE)\n",
    "            mask = np.expand_dims(mask, axis=2)\n",
    "            y_train.append(mask)\n",
    "        x_train.append(img)\n",
    "        \n",
    "    # Read and resize test images. \n",
    "    \n",
    "    for id in tqdm.tqdm_notebook(test.id.values):\n",
    "        path = os.path.join(args.test_folder,'{}.png'.format(id))\n",
    "        img = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "        x_test.append(img)\n",
    "\n",
    "    # Transform lists into 4-dim numpy arrays.\n",
    "    x_train = np.array(x_train)\n",
    "    #if load_mask:\n",
    "    y_train = np.array(y_train)\n",
    "    #return x_train, y_train\n",
    "    #y_train = np.expand_dims(np.array(y_train), axis=4)\n",
    "    x_test = np.array(x_test)\n",
    "    print('Data loaded')\n",
    "    if load_mask:\n",
    "        return x_train, y_train, x_test\n",
    "    else:\n",
    "        return x_train, x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test = load_raw_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_images(data,indexes):\n",
    "    \"\"\" Combines img from data using indexes as follows:\n",
    "        0 1\n",
    "        2 3 \n",
    "    \"\"\"\n",
    "    up = np.hstack([data[indexes[0]],data[indexes[1]]])\n",
    "    down = np.hstack([data[indexes[2]],data[indexes[3]]])\n",
    "    full = np.vstack([up,down])\n",
    "    return full\n",
    "\n",
    "def make_mosaic(data,return_connectivity = False, plot_images = False,external_df = None):\n",
    "    \"\"\"Find images with simular borders and combine them to one big image\"\"\"\n",
    "    if external_df is not None:\n",
    "        external_df['mosaic_idx'] = np.nan\n",
    "        external_df['mosaic_position'] = np.nan\n",
    "        # print(external_df.head())\n",
    "    \n",
    "    # extract borders from images\n",
    "    borders = []\n",
    "    for x in data:\n",
    "        borders.extend([x[0,:,:].flatten(),x[-1,:,:].flatten(),\n",
    "                        x[:,0,:].flatten(),x[:,-1,:].flatten()])\n",
    "    borders = list(np.array(borders))\n",
    "\n",
    "    # prepare df with all data\n",
    "    lens = [len(border) for border in borders]\n",
    "    img_idx = list(range(len(data)))*4\n",
    "    img_idx.sort()\n",
    "    position = ['up','down','left','right']*len(data)\n",
    "    nn = [None]*len(position)\n",
    "    #print(np.vstack([img_idx,position,borders,lens,nn]).shape)\n",
    "    # df = pd.DataFrame([img_idx,position,borders,lens,nn])\n",
    "    df = pd.DataFrame({'img_idx':img_idx,'position':position,'border':borders,'len':lens,'nn':nn})\n",
    "#     df = pd.DataFrame(data=np.vstack([img_idx,position,borders,,nn]).T,\n",
    "#                       columns=['img_idx','position','border',,'nn'])\n",
    "    uniq_lens = df['len'].unique()\n",
    "    \n",
    "    for idx,l in enumerate(uniq_lens):\n",
    "        # fit NN on borders of certain size with 1 neighbor\n",
    "        nn = NearestNeighbors(n_neighbors=1).fit(np.stack(df[df.len == l]['border'].values))\n",
    "        distances, neighbors = nn.kneighbors()\n",
    "        real_neighbor = np.array([None]*len(neighbors))\n",
    "        distances, neighbors = distances.flatten(),neighbors.flatten()\n",
    "\n",
    "        # if many borders are close to one, we want to take only the closest\n",
    "        uniq_neighbors = np.unique(neighbors)\n",
    "\n",
    "        # difficult to understand but works :c\n",
    "        for un_n in uniq_neighbors:\n",
    "            # min distance for borders with same nn\n",
    "            min_index = list(distances).index(distances[neighbors == un_n].min())\n",
    "            # check that min is double-sided\n",
    "            double_sided = distances[neighbors[min_index]] == distances[neighbors == un_n].min()\n",
    "            if double_sided and distances[neighbors[min_index]] < 1000:\n",
    "                real_neighbor[min_index] = neighbors[min_index]\n",
    "                real_neighbor[neighbors[min_index]] = min_index\n",
    "        indexes = df[df.len == l].index\n",
    "        for idx2,r_n in enumerate(real_neighbor):\n",
    "            if r_n is not None:\n",
    "                df['nn'].iloc[indexes[idx2]] = indexes[r_n]\n",
    "    \n",
    "    # img connectivity graph. \n",
    "    img_connectivity = {}\n",
    "    for img in df.img_idx.unique():\n",
    "        slc = df[df['img_idx'] == img]\n",
    "        img_nn = {}\n",
    "\n",
    "        # get near images_id & position\n",
    "        for nn_border,position in zip(slc[slc['nn'].notnull()]['nn'],\n",
    "                                      slc[slc['nn'].notnull()]['position']):\n",
    "\n",
    "            # filter obvious errors when we try to connect bottom of one image to bottom of another\n",
    "            # my hypotesis is that images were simply cut, without rotation\n",
    "            if position == df.iloc[nn_border]['position']:\n",
    "                continue\n",
    "            img_nn[position] = df.iloc[nn_border]['img_idx']\n",
    "        img_connectivity[img] = img_nn\n",
    "\n",
    "    imgs = []\n",
    "    indexes = set()\n",
    "    mosaic_idx = 0\n",
    "    \n",
    "    # errors in connectivity are filtered \n",
    "    good_img_connectivity = {}\n",
    "    for k,v in img_connectivity.items():\n",
    "        if v.get('down') is not None:\n",
    "            if v.get('right') is not None:\n",
    "                # need down right image\n",
    "                # check if both right and down image are connected to the same image in the down right corner\n",
    "                if (img_connectivity[v['right']].get('down') is not None) and img_connectivity[v['down']].get('right') is not None:\n",
    "                    if img_connectivity[v['right']]['down'] == img_connectivity[v['down']]['right']:\n",
    "                        v['down_right'] = img_connectivity[v['right']]['down']\n",
    "                        temp_indexes = [k,v['right'],v['down'],v['down_right']]\n",
    "                        if (len(np.unique(temp_indexes)) < 4) or (len(indexes.intersection(temp_indexes)) > 0):\n",
    "                            continue\n",
    "                        # надо тут фильтровать что они не одинаковые\n",
    "                        good_img_connectivity[k] = temp_indexes\n",
    "                        indexes.update(temp_indexes)\n",
    "                        imgs.append(combine_images(data,temp_indexes))\n",
    "                        if external_df is not None:\n",
    "                            external_df['mosaic_idx'].iloc[temp_indexes] = mosaic_idx\n",
    "                            external_df['mosaic_position'].iloc[temp_indexes] = ['up_left','up_right','down_left','down_right']\n",
    "                            mosaic_idx += 1\n",
    "                        continue\n",
    "            if v.get('left') is not None:\n",
    "                # need down left image\n",
    "                if img_connectivity[v['left']].get('down') is not None and img_connectivity[v['down']].get('left') is not None:\n",
    "                    if img_connectivity[v['left']]['down'] == img_connectivity[v['down']]['left']:\n",
    "                        v['down_left'] = img_connectivity[v['left']]['down']\n",
    "                        temp_indexes = [v['left'],k,v['down_left'],v['down']]\n",
    "                        if (len(np.unique(temp_indexes)) < 4) or (len(indexes.intersection(temp_indexes)) > 0):\n",
    "                            continue\n",
    "                        good_img_connectivity[k] = temp_indexes\n",
    "                        indexes.update(temp_indexes)\n",
    "                        imgs.append(combine_images(data,temp_indexes))\n",
    "                        \n",
    "                        if external_df is not None:\n",
    "                            external_df['mosaic_idx'].iloc[temp_indexes] = mosaic_idx\n",
    "                            external_df['mosaic_position'].iloc[temp_indexes] = ['up_left','up_right','down_left','down_right']\n",
    "                            \n",
    "                            mosaic_idx += 1 \n",
    "                        continue\n",
    "        if v.get('up') is not None:\n",
    "            if v.get('right') is not None:\n",
    "                # need up right image\n",
    "                if img_connectivity[v['right']].get('up') is not None and img_connectivity[v['up']].get('right') is not None:\n",
    "                    if img_connectivity[v['right']]['up'] == img_connectivity[v['up']]['right']:\n",
    "                        v['up_right'] = img_connectivity[v['right']]['up']\n",
    "                        temp_indexes = [v['up'],v['up_right'],k,v['right']]\n",
    "                        if (len(np.unique(temp_indexes)) < 4) or (len(indexes.intersection(temp_indexes)) > 0):\n",
    "                            continue\n",
    "                        good_img_connectivity[k] = temp_indexes\n",
    "                        indexes.update(temp_indexes)\n",
    "                        imgs.append(combine_images(data,temp_indexes))\n",
    "                        \n",
    "                        if external_df is not None:\n",
    "                            external_df['mosaic_idx'].iloc[temp_indexes] = mosaic_idx\n",
    "                            external_df['mosaic_position'].iloc[temp_indexes] = ['up_left','up_right','down_left','down_right']\n",
    "                            \n",
    "                            mosaic_idx += 1 \n",
    "                        continue\n",
    "            if v.get('left') is not None:\n",
    "                # need up left image\n",
    "                if img_connectivity[v['left']].get('up') is not None and img_connectivity[v['up']].get('left') is not None:\n",
    "                    if img_connectivity[v['left']]['up'] == img_connectivity[v['up']]['left']:\n",
    "                        v['up_left'] = img_connectivity[v['left']]['up']\n",
    "                        temp_indexes = [v['up_left'],v['up'],v['left'],k]\n",
    "                        if (len(np.unique(temp_indexes)) < 4) or (len(indexes.intersection(temp_indexes)) > 0):\n",
    "                            continue\n",
    "                        good_img_connectivity[k] = temp_indexes\n",
    "                        indexes.update(temp_indexes)\n",
    "                        imgs.append(combine_images(data,temp_indexes))\n",
    "                        \n",
    "                        if external_df is not None:\n",
    "                            external_df['mosaic_idx'].iloc[temp_indexes] = mosaic_idx\n",
    "                            external_df['mosaic_position'].iloc[temp_indexes] = ['up_left','up_right','down_left','down_right']\n",
    "                            \n",
    "                            mosaic_idx += 1 \n",
    "                        continue\n",
    "\n",
    "    # same images are present 4 times (one for every piece) so we need to filter them\n",
    "    print('Images before filtering: {}'.format(np.shape(imgs)))\n",
    "    \n",
    "    # can use np. unique only on images of one size, flatten first, then select\n",
    "    flattened = np.array([i.flatten() for i in imgs])\n",
    "    uniq_lens = np.unique([i.shape for i in flattened])\n",
    "    filtered_imgs = []\n",
    "    for un_l in uniq_lens:\n",
    "        filtered_imgs.extend(np.unique(np.array([i for i in imgs if i.flatten().shape == un_l]),axis=0))\n",
    "        \n",
    "    filtered_imgs = np.array(filtered_imgs)\n",
    "    print('Images after filtering: {}'.format(np.shape(filtered_imgs)))\n",
    "    \n",
    "    if return_connectivity:\n",
    "        print(good_img_connectivity)\n",
    "    \n",
    "    if plot_images:\n",
    "        for i in filtered_imgs:\n",
    "            plt.imshow(i)\n",
    "            plt.show()\n",
    "            \n",
    "    # list of not combined images. return if you need\n",
    "    not_combined = list(set(range(len(data))) - indexes)\n",
    "    \n",
    "    if external_df is not None:\n",
    "        #un_mos_id = external_df[external_df.mosaic_idx.notnull()].mosaic_idx.unique()\n",
    "        #mos_dict = {k:v for k,v in zip(un_mos_id,range(len(un_mos_id)))}\n",
    "        #external_df.mosaic_idx = external_df.mosaic_idx.map(mos_dict)\n",
    "        ## print(temp.mosaic_idx.shape[0])\n",
    "        ## print(len(temp.mosaic_idx[temp.mosaic_idx.isnull()] ))\n",
    "        ## print(len(list(range(temp.mosaic_idx.shape[0]-len(temp.mosaic_idx[temp.mosaic_idx.isnull()]),\n",
    "        ##                     temp.mosaic_idx.shape[0]))))\n",
    "        external_df.loc[external_df[external_df['mosaic_idx'].isnull()].index,'mosaic_idx'] = range(\n",
    "            int(np.nanmax(external_df.mosaic_idx.unique())) + 1,\n",
    "            int(np.nanmax(external_df.mosaic_idx.unique())) + 1 + len(external_df.mosaic_idx[external_df.mosaic_idx.isnull()]))\n",
    "        external_df['mosaic_idx'] = external_df['mosaic_idx'].astype(np.int32)\n",
    "        if return_connectivity:\n",
    "            return filtered_imgs, external_df, good_img_connectivity\n",
    "        else:\n",
    "            return filtered_imgs, external_df\n",
    "    if return_connectivity:\n",
    "        return filtered_imgs,good_img_connectivity\n",
    "    else:\n",
    "        return filtered_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_imgs,good_img_connectivity = make_mosaic(x_test,return_connectivity=True,plot_images=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.iloc[175,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.iloc[1523,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.iloc[12757,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.iloc[5335,:].z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for el in [175, 1523, 12757, 5335]:\n",
    "    print(test.iloc[el,:].z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for el in [7569, 8689, 5412, 246]:\n",
    "    print(test.iloc[el,:].z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_img_connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_mosaic(x_train,return_connectivity=False,plot_images=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_img_connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Визуально картинки одной глубины, бывают сильно похожими на соседние, но крайне редко.\n",
    "d = 655\n",
    "width = 5\n",
    "height = len(depths[depths.z == d].index.values)//width + (len(depths[depths.z == d].index.values)%width >0)\n",
    "fig, axs = plt.subplots(height, width, figsize=(15, 14))\n",
    "for i, names in enumerate(depths[depths.z == d].index.values):\n",
    "   ax = axs[i // width, i % width]\n",
    "   try:\n",
    "       ax.imshow(np.asarray(Image.open(osp.join(path_train, 'images', f'{names}.png'))))\n",
    "   except:\n",
    "       ax.imshow(np.asarray(Image.open(osp.join(path_test, 'images', f'{names}.png'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = read_image(), self.input_shape)\n",
    "mask = read_mask(os.path.join(args.masks_dir,'{}.png'.format('3577258d6b')), self.input_shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
