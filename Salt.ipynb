{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "import gc\n",
    "from keras.optimizers import Adam, RMSprop, SGD\n",
    "\n",
    "from utils import predict_test, evaluate, ensemble, ThreadsafeIter, classification_predict_test\n",
    "from datasets.generators import SegmentationDataGenerator, ClassificationDataGenerator\n",
    "\n",
    "from params import args\n",
    "from callbacks import get_callback\n",
    "from augmentations import get_augmentations\n",
    "\n",
    "from models.models import get_model\n",
    "\n",
    "from losses import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = '/home/p/babakhin/Branding/salt/data/'\n",
    "train = pd.read_csv(os.path.join(DATA_ROOT,'train_proc_v2.csv'))\n",
    "test = pd.read_csv(os.path.join(DATA_ROOT,'sample_submission.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(os.path.join(args.images_dir,'{}.png'.format('88839f49f9')), cv2.IMREAD_COLOR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from albumentations import *\n",
    "#augmentation = PadIfNeeded(min_height=128, min_width=128, p=1.0, border_mode=0) \n",
    "augmentation = Compose([\n",
    "            #RandomRotate90(p=1),\n",
    "                HorizontalFlip(p=.5),\n",
    "                RandomBrightness(p=.2,limit=0.2),\n",
    "                RandomContrast(p=.1,limit=0.2),\n",
    "                ShiftScaleRotate(shift_limit=0.1625, scale_limit=0., rotate_limit=0, p=1),\n",
    "                RandomCrop(height=96, width=96,p=1)\n",
    "            ], p=1)\n",
    "\n",
    "data = {\"image\": img}\n",
    "augmented = augmentation(**data)\n",
    "img_pad = augmented[\"image\"]\n",
    "\n",
    "# from albumentations import PadIfNeeded\n",
    "# augmentation = PadIfNeeded(min_height=128, min_width=128, p=1.0, border_mode=4) \n",
    "# data = {\"image\": img}\n",
    "# augmented = augmentation(**data)\n",
    "# img_pad = augmented[\"image\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for network in args.network.split(','):\n",
    "    folds = [int(f) for f in args.fold.split(',')]\n",
    "    for fold in folds:\n",
    "        K.clear_session()\n",
    "        print('***************************** FOLD {} *****************************'.format(fold))\n",
    "\n",
    "        MODEL_PATH = os.path.join(args.models_dir,network+args.alias)\n",
    "\n",
    "        if fold == 0:\n",
    "            if os.path.isdir(MODEL_PATH):\n",
    "                raise ValueError('Such Model already exists')\n",
    "            os.system(\"mkdir {}\".format(MODEL_PATH))\n",
    "            os.system(\"cp params.py {}\".format(MODEL_PATH))\n",
    "\n",
    "        df_train = train[train.fold != fold].copy().reset_index(drop=True)\n",
    "        df_valid = train[train.fold == fold].copy().reset_index(drop=True)\n",
    "\n",
    "        ids_train, ids_valid = df_train[df_train.unique_pixels>1].id.values, df_valid.id.values\n",
    "\n",
    "        # Fold 0\n",
    "        # Training on 3127 samples\n",
    "        # Validating on 810 samples\n",
    "        # ids_train, ids_valid = df_train[(df_train.unique_pixels>1)&(~df_train.id.isin(bad_masks))].id.values, df_valid.id.values\n",
    "\n",
    "\n",
    "        print('Training on {} samples'.format(ids_train.shape[0]))\n",
    "        print('Validating on {} samples'.format(ids_valid.shape[0]))\n",
    "\n",
    "        # Initialize Model\n",
    "        weights_path = os.path.join(MODEL_PATH,'fold_{fold}.hdf5'.format(fold=fold))\n",
    "        #weights_path = os.path.join(MODEL_PATH,'fold_{fold}'.format(fold=fold))\n",
    "        \n",
    "        print(weights_path.split('/')[-2:])\n",
    "\n",
    "\n",
    "        model, preprocess = get_model(network, input_shape=(args.input_size, args.input_size, 3), train_base=True)\n",
    "        print(model.summary())\n",
    "        model.compile(optimizer=RMSprop(lr=args.learning_rate), loss=make_loss(args.loss_function),\n",
    "                          metrics=[Kaggle_IoU_Precision])\n",
    "\n",
    "        if args.weights is None:\n",
    "            print('No weights passed, training from scratch')\n",
    "        else:\n",
    "            wp = args.weights.format(fold)\n",
    "            print('Loading weights from {}'.format(wp))\n",
    "            model.load_weights(wp, by_name=True)\n",
    "\n",
    "        augs = get_augmentations(args.augmentation_name, p=args.augmentation_prob, input_shape=(args.input_size, args.input_size, 3))\n",
    "\n",
    "\n",
    "        dg = SegmentationDataGenerator(input_shape=(args.input_size, args.input_size), batch_size = args.batch_size, augs = augs,\n",
    "                          preprocess = preprocess)\n",
    "\n",
    "        train_generator = dg.train_batch_generator(ids_train)\n",
    "        validation_generator = dg.evaluation_batch_generator(ids_valid)\n",
    "\n",
    "        callbacks = get_callback(args.callback, weights_path=weights_path,\n",
    "                                fold = fold)\n",
    "\n",
    "        # Fit the model with Generators:\n",
    "        model.fit_generator(generator=ThreadsafeIter(train_generator),\n",
    "                        steps_per_epoch=ids_train.shape[0] // args.batch_size * 2,\n",
    "                        epochs=args.epochs,\n",
    "                        callbacks=callbacks,\n",
    "                        validation_data=ThreadsafeIter(validation_generator),\n",
    "                        validation_steps=np.ceil(ids_valid.shape[0] / args.batch_size),\n",
    "                        workers=12)\n",
    "\n",
    "        \n",
    "#         dir_path = os.path.join(MODEL_PATH,'oof')\n",
    "#         os.system(\"mkdir {}\".format(dir_path))\n",
    "#         best_res = 0\n",
    "#         best_weights_path = ''\n",
    "#         for w in sorted(os.listdir(MODEL_PATH))[-13:-2]:\n",
    "#             print(w)\n",
    "#             weights_path = os.path.join(MODEL_PATH,w)\n",
    "#             model.load_weights(weights_path,by_name=False)\n",
    "\n",
    "#             # SAVE OOF PREDICTIONS\n",
    "#             pred = predict_test(model=model,\n",
    "#                             preds_path=dir_path,\n",
    "#                             oof=True,\n",
    "#                             ids=ids_valid,\n",
    "#                             batch_size=args.batch_size*2,\n",
    "#                             thr=0.5,\n",
    "#                             TTA='',\n",
    "#                             preprocess=preprocess)\n",
    "#             res = evaluate([MODEL_PATH], train[train.fold.isin([fold])].id.values, 0.5, classification='')\n",
    "#             print(np.mean(res['iout']))\n",
    "#             if np.mean(res['iout']) > best_res:\n",
    "#                 best_res = np.mean(res['iout'])\n",
    "#                 best_weights_path = weights_path\n",
    "        \n",
    "#         print(best_weights_path)\n",
    "#         print(best_res)\n",
    "        \n",
    "        best_weights_path = weights_path\n",
    "        model.load_weights(best_weights_path)\n",
    "\n",
    "        # SAVE OOF PREDICTIONS\n",
    "        dir_path = os.path.join(MODEL_PATH,'oof')\n",
    "        os.system(\"mkdir {}\".format(dir_path))\n",
    "        pred = predict_test(model=model,\n",
    "                        preds_path=dir_path,\n",
    "                        oof=True,\n",
    "                        ids=ids_valid,\n",
    "                        batch_size=args.batch_size*2,\n",
    "                        thr=0.5,\n",
    "                        TTA='',\n",
    "                        preprocess=preprocess)\n",
    "\n",
    "#         # SAVE TEST PREDICTIONS\n",
    "#         dir_path = os.path.join(MODEL_PATH,'fold_{}'.format(fold))\n",
    "#         os.system(\"mkdir {}\".format(dir_path))\n",
    "#         pred = predict_test(model=model,\n",
    "#                         preds_path=dir_path,\n",
    "#                         oof=False,\n",
    "#                         ids=test.id.values,\n",
    "#                         batch_size=args.batch_size*2,\n",
    "#                         thr=0.5,\n",
    "#                         TTA='flip',\n",
    "#                         preprocess=preprocess)\n",
    "\n",
    "        K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.alias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NEEW!\n",
    "\n",
    "unet_resnet_34_exp_0_resize_144_pad_192_cyclic_lr_metric_checkpoint_v1\n",
    "0.82593 / 0.87479 / 0.85012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir_path = os.path.join(MODEL_PATH,'oof')\n",
    "# os.system(\"mkdir {}\".format(dir_path))\n",
    "\n",
    "dir_path = os.path.join(MODEL_PATH,'oof')\n",
    "w='fold_0.25-0.17-0.8067-0.8226.hdf5'\n",
    "weights_path = os.path.join(MODEL_PATH,w)\n",
    "model.load_weights(weights_path,by_name=False)\n",
    "\n",
    "# SAVE OOF PREDICTIONS\n",
    "pred = predict_test(model=model,\n",
    "                preds_path=dir_path,\n",
    "                oof=True,\n",
    "                ids=ids_valid,\n",
    "                batch_size=args.batch_size*2,\n",
    "                thr=0.5,\n",
    "                TTA='',\n",
    "                preprocess=preprocess)\n",
    "res = evaluate([MODEL_PATH], train[train.fold.isin([0])].id.values, 0.5, classification='')\n",
    "print(np.mean(res['iout']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet_resnet_34_exp_0_resize_144_pad_192_early_stopping\n",
    "0.79975 / 0.85854 / 0.83097\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet_resnet_34_do_exp_0_resize_144_pad_192_do_04_02_middle_cycle_lr_div_16_1\n",
    "fold_0.39-0.19-0.8095-0.8258.hdf5\n",
    "0.8293827160493826\n",
    "\n",
    "fold_0.29-0.16-0.7881-0.8075.hdf5\n",
    "0.8212345679012346\n",
    "\n",
    "fold_0.37-0.19-0.8130-0.8294.hdf5\n",
    "0.8325925925925927"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet_resnet_34_do_exp_0_resize_144_pad_192_do_04_02_middle_checkpoint_cycle_lr\n",
    "fold_0.27-0.19-0.8004-0.8186.hdf5\n",
    "0.8218518518518519\n",
    "\n",
    "fold_0.17-0.16-0.8068-0.8210.hdf5\n",
    "0.8303703703703704\n",
    "\n",
    "fold_0.23-0.17-0.8112-0.8298.hdf5\n",
    "0.8306172839506172"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet_resnet_34_do_exp_0_resize_144_pad_192_do_04_02_middle_cycle_lr_1_x6\n",
    "fold_0.17-0.16-0.8068-0.8230.hdf5\n",
    "0.8288888888888889\n",
    "\n",
    "fold_0.25-0.17-0.8067-0.8226.hdf5\n",
    "0.8314814814814815\n",
    "without pixel deletion: 0.8267901234567901"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best?\n",
    "fold_0.24-0.15-0.8235-0.8385.hdf5\n",
    "0.83877 / 0.88339 / 0.85986\n",
    "\n",
    "fold_0.34-0.16-0.8289-0.8448.hdf5\n",
    "0.84704 / 0.88595 / 0.86255\n",
    "\n",
    "fold_0.33-0.16-0.8325-0.8449.hdf5\n",
    "0.84753 / 0.88669 / 0.86399\n",
    "\n",
    "fold_0.32-0.16-0.8275-0.8435.hdf5\n",
    "0.84309 / 0.88288 / 0.85965\n",
    "\n",
    "fold_0.31-0.16-0.8241-0.8394.hdf5\n",
    "0.84358 / 0.88345 / 0.85945\n",
    "\n",
    "fold_0.30-0.16-0.8268-0.8417.hdf5\n",
    "0.84148 / 0.88327 / 0.85987\n",
    "\n",
    "fold_0.29-0.16-0.8360-0.8509.hdf5\n",
    "0.85 / 0.89057 / 0.86772"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Total params: 25,282,186\n",
    "Trainable params: 25,264,132\n",
    "Non-trainable params: 18,054\n",
    "\n",
    "psp concat:\n",
    "Total params: 25,283,338\n",
    "Trainable params: 25,265,284\n",
    "Non-trainable params: 18,054\n",
    "    \n",
    "with UpSampling:\n",
    "Total params: 28,748,554\n",
    "Trainable params: 28,730,500\n",
    "Non-trainable params: 18,054\n",
    "    \n",
    "2 conv_blocks in the middle\n",
    "Total params: 30,005,898\n",
    "Trainable params: 29,985,796\n",
    "Non-trainable params: 20,102\n",
    "    \n",
    "increase capacity x2:\n",
    "Total params: 33,003,594\n",
    "Trainable params: 32,982,852\n",
    "Non-trainable params: 20,742"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = '/home/branding_images/salt/unet_resnet_50_valid_plus_resize_202_pad_256_bs_24'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'/home/branding_images/salt/classification/oof'\n",
    "res = evaluate([MODEL_PATH], train[train.fold.isin([0,1])].id.values, 0.5, classification='')\n",
    "print(\"{} / {} / {}\".format(np.round(np.mean(res['iout']),5),np.round(np.mean(res['dice']),5),np.round(np.mean(res['jacard']),5)))\n",
    "res = evaluate([MODEL_PATH], train[train.fold.isin([0])].id.values, 0.5, classification='')\n",
    "print(\"{} / {} / {}\".format(np.round(np.mean(res['iout']),5),np.round(np.mean(res['dice']),5),np.round(np.mean(res['jacard']),5)))\n",
    "res = evaluate([MODEL_PATH], train[train.fold.isin([1])].id.values, 0.5, classification='')\n",
    "print(\"{} / {} / {}\".format(np.round(np.mean(res['iout']),5),np.round(np.mean(res['dice']),5),np.round(np.mean(res['jacard']),5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = evaluate([MODEL_PATH], train[train.fold.isin([0])].id.values, 0.5, classification='')\n",
    "print(\"{} / {} / {}\".format(np.round(np.mean(res['iout']),5),np.round(np.mean(res['dice']),5),np.round(np.mean(res['jacard']),5)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res = evaluate(model_pathes, train[train.fold.isin([0])].id.values, 0.5, classification='')\n",
    "# print(\"{} / {} / {}\".format(np.round(np.mean(res['iout']),5),np.round(np.mean(res['dice']),5),np.round(np.mean(res['jacard']),5)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "96 -- 3x3\n",
    "192 -- 6x6\n",
    "256 -- 8x8\n",
    "//32\n",
    "288 -- would be 9x9\n",
    "384 -- would be 12x12\n",
    "512 -- would be 16x16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet_resnet_34_do_exp_0_resize_144_pad_192_do_04_last\n",
    "0.83432 / 0.88136 / 0.8565\n",
    "unet_resnet_34_do_exp_0_resize_144_pad_192_do_04_last_again\n",
    "0.84728 / 0.89039 / 0.86695\n",
    "\n",
    "unet_resnet_34_do_exp_0_resize_144_pad_192_do_04_last_02_do_in_middle\n",
    "0.84864 / 0.89183 / 0.86803\n",
    "    TTA: 0.8521 / 0.89261 / 0.86979\n",
    "unet_resnet_34_do_exp_0_resize_144_pad_192_do_04_last_02_do_in_middle_again\n",
    "0.84802 / 0.88714 / 0.8648\n",
    "unet_resnet_34_do_exp_0_resize_144_pad_192_do_04_last_02_do_in_middle_try\n",
    "0.84556 / 0.88715 / 0.8643\n",
    "\n",
    "0.83753 / 0.88699 / 0.86237\n",
    "\n",
    "unet_resnet_34_do_exp_0_resize_144_pad_192_do_04_last_02_do_in_middle_from_scratch\n",
    "0.79198 / 0.84075 / 0.81404\n",
    "\n",
    "unet_resnet_34_do_exp_0_resize_144_pad_192_do_04_last_02_do_in_middle_lr_0001\n",
    "0.82654 / 0.86517 / 0.84159\n",
    "\n",
    "unet_resnet_34_do_exp_0_resize_144_pad_192_do_04_last_02_do_in_middle_Conv2DTranspose\n",
    "0.83728 / 0.88476 / 0.86042\n",
    "unet_resnet_34_do_exp_0_resize_144_pad_192_do_04_last_02_do_in_middle_Conv2DTranspose_again\n",
    "0.83802 / 0.88051 / 0.85617\n",
    "\n",
    "unet_resnet_34_do_exp_0_resize_144_pad_192_do_04_last_02_do_in_middle_2_conv_blocks_in_middle\n",
    "0.84049 / 0.87981 / 0.85704\n",
    "\n",
    "unet_resnet_34_do_exp_0_resize_144_pad_192_do_04_last_02_do_in_middle_x2_capacity\n",
    "0.84074 / 0.88782 / 0.86356\n",
    "\n",
    "RMSPROP!\n",
    "unet_resnet_34_do_exp_0_resize_144_pad_192_do_04_last_02_do_in_middle_sgd_0001\n",
    "0.82802 / 0.86422 / 0.84122\n",
    "\n",
    "unet_resnet_34_do_exp_0_resize_144_pad_192_do_04_last_02_do_in_middle_sgd_001\n",
    "0.7579 / 0.82288 / 0.7932\n",
    "\n",
    "unet_resnet_34_do_exp_0_resize_144_pad_192_do_04_last_02_do_in_middle_adam_00001\n",
    "0.83988 / 0.88111 / 0.85803\n",
    "\n",
    "\n",
    "psp_concat\n",
    "unet_resnet_34_do_exp_0_resize_144_pad_192_do_04_last_psp_concat\n",
    "0.84333 / 0.88874 / 0.86519\n",
    "unet_resnet_34_do_exp_0_resize_144_pad_192_do_04_last_psp_concat_again\n",
    "0.83877 / 0.88339 / 0.85986\n",
    "\n",
    "    \n",
    "unet_resnet_34_do_exp_0_resize_144_pad_192_do_04_02_in_middle_96_crop    \n",
    "0.83667 / 0.8827 / 0.85833    \n",
    " \n",
    "# YOU'VE UPDATED ALBUMENTATIOOONNSS!\n",
    "unet_resnet_34_do_exp_0_resize_144_pad_192_do_04_02_in_middle_92_crop_resize_101\n",
    "0.83235 / 0.87777 / 0.85349\n",
    "\n",
    "# YOU'VE UPDATED ALBUMENTATIOOONNSS!\n",
    "unet_resnet_34_do_exp_0_resize_144_pad_192_do_04_02_in_middle_96_crop_no_scaling\n",
    "0.83716 / 0.87899 / 0.85579\n",
    "\n",
    "\n",
    "\n",
    "# YOU'VE UPDATED ALBUMENTATIOOONNSS!\n",
    "RESIZE TO 192!\n",
    "unet_resnet_34_do_exp_0_resize_192_do_04_02_in_middle\n",
    "0.83086 / 0.87579 / 0.85235\n",
    "unet_resnet_34_do_exp_0_resize_144_pad_192_do_04_02_middle_checkpoint\n",
    "0.83593 / 0.87663 / 0.85302\n",
    "unet_resnet_34_do_exp_0_resize_144_pad_192_do_04_02_middle_checkpoint_again\n",
    "0.82901 / 0.87291 / 0.84924\n",
    "\n",
    "# YOU'VE UPDATED ALBUMENTATIOOONNSS!\n",
    "unet_resnet_34_do_exp_0_resize_144_pad_192_do_04_02_middle_checkpoint_corr\n",
    "0.8258 / 0.87866 / 0.85393\n",
    "unet_resnet_34_do_exp_0_resize_144_pad_192_do_04_02_middle_checkpoint_corr_again\n",
    "0.84432 / 0.8842 / 0.86197\n",
    "unet_resnet_34_do_exp_0_resize_144_pad_192_do_04_02_middle_checkpoint_revert_albumentations\n",
    "0.83753 / 0.88699 / 0.86237\n",
    "< 30 pix: 0.84111 / 0.88865 / 0.8645\n",
    "*********************************************************\n",
    "unet_resnet_34_exp_0_resize_144_pad_192\n",
    "0.82519 / 0.87639 / 0.85106\n",
    "\n",
    "unet_resnet_34_do_exp_0_resize_144_pad_192\n",
    "0.83086 / 0.87799 / 0.85441\n",
    "\n",
    "resnet34_fpn_do_exp_0_resize_144_pad_192\n",
    "0.8342 / 0.88145 / 0.85613\n",
    "\n",
    "unet_resnet_50_do_exp_0_resize_144_pad_192\n",
    "0.83531 / 0.88551 / 0.86118\n",
    "\n",
    "resnet50_fpn_exp_0_resize_144_pad_192\n",
    "0.84185 / 0.88208 / 0.85874    \n",
    "*********************************************************\n",
    "    \n",
    "unet_resnet_34_do_exp_0_resize_144_pad_192_wtf\n",
    "0.83333 / 0.88131 / 0.85726\n",
    "    TTA: 0.8442 / 0.88683 / 0.86383\n",
    "unet_resnet_34_do_exp_0_resize_144_pad_192_wtf_again\n",
    "0.84062 / 0.88159 / 0.85864\n",
    "    TTA: 0.84198 / 0.884 / 0.86134\n",
    "\n",
    "just on epoch to freeze the encoder (to warm-up decoder a little bit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet_resnet_34_exp_2_resize_144_pad_192 \n",
    "0.83451 / 0.88055 / 0.857\n",
    "    fold 0: 0.84716 / 0.88915 / 0.86693\n",
    "    fold 1: 0.82177 / 0.87189 / 0.847\n",
    "unet_resnet_34_exp_2_resize_144_pad_192_again\n",
    "0.83271 / 0.87971 / 0.85611\n",
    "    fold 0: 0.84222 / 0.88539 / 0.8622\n",
    "    fold 1: 0.82313 / 0.87398 / 0.84997\n",
    "        \n",
    "unet_resnet_34exp_2_resize_144_pad_192_start\n",
    "0.83538 / 0.87858 / 0.85525\n",
    "    fold 0: 0.84358 / 0.88594 / 0.86279\n",
    "    fold 1: 0.82711 / 0.87116 / 0.84765\n",
    "\n",
    "unet_resnet_34_exp_2_resize_144_pad_192_mask_thr\n",
    "0.83222 / 0.87609 / 0.85278\n",
    "    fold 0: 0.84259 / 0.88166 / 0.85915\n",
    "    fold 1: 0.82177 / 0.87047 / 0.84637\n",
    "        \n",
    "unet_resnet_34_do_exp_2_resize_144_pad_192_delete_do -- Deleting DO -- good candidate for the ensemble\n",
    "0.82999 / 0.87756 / 0.85355\n",
    "    fold 0: 0.82951 / 0.87334 / 0.84972\n",
    "    fold 1: 0.83047 / 0.8818 / 0.85741\n",
    "\n",
    "        \n",
    "unet_resnet_34_do_exp_2_resize_144_pad_192_do_04_last\n",
    "0.8381 / 0.88303 / 0.85918\n",
    "    fold 0: 0.84728 / 0.89413 / 0.86973\n",
    "    fold 1: 0.82886 / 0.87184 / 0.84856\n",
    "\n",
    "unet_resnet_34_do_exp_2_resize_144_pad_192_do_04_last_again        \n",
    "0.83178 / 0.87809 / 0.85378\n",
    "    0.83395 / 0.87813 / 0.85414\n",
    "    0.8296 / 0.87804 / 0.85341\n",
    "\n",
    "unet_resnet_34_do_exp_2_resize_144_pad_192_do_03_last_02_2_prev\n",
    "0.83216 / 0.88123 / 0.85614\n",
    "    0.83531 / 0.88476 / 0.85978\n",
    "    0.82898 / 0.87768 / 0.85247\n",
    "\n",
    "unet_resnet_34_do_exp_2_resize_144_pad_192_do_02_2_prev\n",
    "0.82999 / 0.87626 / 0.85208\n",
    "    0.84963 / 0.88953 / 0.86673\n",
    "    0.8102 / 0.86289 / 0.83732\n",
    "    \n",
    "unet_resnet_34_do_exp_2_resize_144_pad_192_do_02_2_prev_02_last\n",
    "0.82999 / 0.87628 / 0.85176\n",
    "    0.84012 / 0.88533 / 0.86138\n",
    "    0.81978 / 0.86716 / 0.84208\n",
    "    \n",
    "unet_resnet_34_do_exp_2_resize_144_pad_192_do_04_last_no_bn\n",
    "0.81964 / 0.8681 / 0.84299\n",
    "    0.81889 / 0.86998 / 0.84438\n",
    "    0.8204 / 0.8662 / 0.84159\n",
    "\n",
    "unet_resnet_152_exp_0_resize_144_pad_192_do_04_last\n",
    "0.85531 / 0.89504 / 0.87287\n",
    "\n",
    "unet_resnet_152_exp_0_resize_144_pad_192_do_04_last_finetune\n",
    "0.85222 / 0.89078 / 0.86944\n",
    "\n",
    "unet_resnet_152_exp_0_resize_144_pad_192_do_04_last_lb_metric\n",
    "0.84667 / 0.88902 / 0.86639\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet_resnet_34_exp_2_resize_192\n",
    "0.83389 / 0.87669 / 0.8532\n",
    "    fold 0: 0.84123 / 0.8801 / 0.85735\n",
    "    fold 1: 0.82649 / 0.87325 / 0.84902\n",
    "unet_resnet_34_exp_2_resize_192_again\n",
    "0.83209 / 0.87658 / 0.85316\n",
    "    fold 0: 0.84506 / 0.88389 / 0.86132\n",
    "    fold 1: 0.81903 / 0.86922 / 0.84493\n",
    "\n",
    "unet_resnet_34_exp_2_resize_144_pad_192 \n",
    "0.83451 / 0.88055 / 0.857\n",
    "    fold 0: 0.84716 / 0.88915 / 0.86693\n",
    "    fold 1: 0.82177 / 0.87189 / 0.847\n",
    "unet_resnet_34_exp_2_resize_144_pad_192_again\n",
    "0.83271 / 0.87971 / 0.85611\n",
    "    fold 0: 0.84222 / 0.88539 / 0.8622\n",
    "    fold 1: 0.82313 / 0.87398 / 0.84997\n",
    "    \n",
    "unet_resnet_34_valid_plus_resize_202_pad_256_bs_24\n",
    "0.8412 / 0.88176 / 0.85929\n",
    "    fold 0: 0.84901 / 0.88497 / 0.86356\n",
    "    fold 1: 0.83333 / 0.87852 / 0.85499\n",
    "unet_resnet_34_exp_2_resize_202_pad_256_bs_24_again\n",
    "0.83835 / 0.88224 / 0.85882\n",
    "    fold 0: 0.84691 / 0.88655 / 0.86338\n",
    "    fold 1: 0.82973 / 0.8779 / 0.85421\n",
    "\n",
    "unet_resnet_50_exp_2_exp_2_resize_144_pad_192\n",
    "0.82214 / 0.87442 / 0.85021\n",
    "\n",
    "unet_resnet_50_valid_plus_resize_202_pad_256_bs_24\n",
    "0.83848 / 0.88182 / 0.85931\n",
    "\n",
    "unet_resnet_152_valid_plus_resize_202_pad_256_bs_12_corr\n",
    "0.85031 / 0.88821 / 0.86668\n",
    "    0.85716 / 0.89305 / 0.87196\n",
    "    0.84341 / 0.88334 / 0.86136\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res = evaluate([MODEL_PATH], train.id.values, 0.5, classification='')\n",
    "print(\"{} / {} / {}\".format(np.round(np.mean(res['iout']),5),np.round(np.mean(res['dice']),5),np.round(np.mean(res['jacard']),5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['unet_resnet_34_valid_plus_resize_202_pad_256_bs_24',\n",
    "'unet_resnet_50_valid_plus_resize_202_pad_256_bs_24',\n",
    "         'unet_resnet_152_valid_plus_resize_202_pad_256_bs_12_corr','resnet50_fpn_96'\n",
    "         ]\n",
    "model_pathes = ['/home/branding_images/salt/'+x for x in models]\n",
    "res = evaluate(model_pathes, train.id.values, 0.5, classification='')\n",
    "print(\"{} / {} / {}\".format(np.round(np.mean(res['iout']),5),np.round(np.mean(res['dice']),5),np.round(np.mean(res['jacard']),5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base 0.85105 / 0.88973 / 0.86871\n",
    "\n",
    "resnet50_fpn_96\n",
    "0.85245 / 0.8922 / 0.87103\n",
    "\n",
    "30 pixels:\n",
    "0.85262 / 0.89038 / 0.8698\n",
    "\n",
    "10 pixels:\n",
    "0.85255 / 0.89154 / 0.87058"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['iout'] = res['iout']\n",
    "train.groupby('fold').iout.aggregate('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pred = ensemble(model_pathes,[0,1,2,3,4],test.id.values,0.5, classification='')\n",
    "pred = ensemble([MODEL_PATH],[0],test.id.values,0.5, classification='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test['rle_mask'] = pred\n",
    "#test[['id','rle_mask']].to_csv('101_102_103_85105.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['rle_mask'] = pred\n",
    "test[['id','rle_mask']].to_csv('unet_resnet_152_valid_plus_resize_202_pad_256_bs_12_corr_0_fold_tta_85716.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.rle_mask.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.rle_mask.value_counts(normalize=True,dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot2x2Array(image, mask):\n",
    "    f, axarr = plt.subplots(1,2)\n",
    "    axarr[0].imshow(image)\n",
    "    axarr[1].imshow(mask)\n",
    "    axarr[0].grid()\n",
    "    axarr[1].grid()\n",
    "    axarr[0].set_title('Image')\n",
    "    axarr[1].set_title('Mask')\n",
    "    \n",
    "for i in range(5):\n",
    "    image, mask = dataset[np.random.randint(0, len(dataset))]\n",
    "    plot2x2Array(image, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_results(idx):\n",
    "    from rle import rle_decode\n",
    "    img = rle_decode(pred[idx],(101,101))\n",
    "    plt.figure(figsize=(4,4))\n",
    "    plt.imshow(img)\n",
    "    \n",
    "    plt.figure(figsize=(4,4))\n",
    "    plt.imshow(cv2.imread('train/images/{}.png'.format(ids_valid[idx])))\n",
    "    plt.figure(figsize=(4,4))\n",
    "    plt.imshow(cv2.imread('train/masks/{}.png'.format(ids_valid[idx])))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    show_results(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_probs=[]\n",
    "network = 'classification'\n",
    "folds = [int(f) for f in args.fold.split(',')]\n",
    "for fold in folds:\n",
    "    K.clear_session()\n",
    "    print('***************************** FOLD {} *****************************'.format(fold))\n",
    "\n",
    "    MODEL_PATH = os.path.join(args.models_dir,network+args.alias)\n",
    "\n",
    "    if fold == 0:\n",
    "        if os.path.isdir(MODEL_PATH):\n",
    "            raise ValueError('Such Model already exists')\n",
    "        os.system(\"mkdir {}\".format(MODEL_PATH))\n",
    "        os.system(\"cp params.py {}\".format(MODEL_PATH))\n",
    "\n",
    "    df_train = train[train.fold != fold].copy().reset_index(drop=True)\n",
    "    df_valid = train[train.fold == fold].copy().reset_index(drop=True)\n",
    "\n",
    "    ids_train, ids_valid = df_train.id.values, df_valid.id.values\n",
    "\n",
    "    print('Training on {} samples'.format(ids_train.shape[0]))\n",
    "    print('Validating on {} samples'.format(ids_valid.shape[0]))\n",
    "\n",
    "    # Initialize Model\n",
    "    weights_path = os.path.join(MODEL_PATH,'fold_{fold}.hdf5'.format(fold=fold))\n",
    "\n",
    "    print(weights_path.split('/')[-2:])\n",
    "\n",
    "    model, preprocess = get_model(network, input_shape=(args.input_size, args.input_size, 3), train_base=True)\n",
    "    print(model.summary())\n",
    "    model.compile(optimizer=RMSprop(lr=args.learning_rate), loss='binary_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "    if args.weights is None:\n",
    "        print('No weights passed, training from scratch')\n",
    "    else:\n",
    "        wp = args.weights.format(fold)\n",
    "        print('Loading weights from {}'.format(wp))\n",
    "        model.load_weights(wp, by_name=True)\n",
    "\n",
    "    augs = get_augmentations(args.augmentation_name, p=args.augmentation_prob, input_shape=(args.input_size, args.input_size, 3))\n",
    "\n",
    "\n",
    "    dg = ClassificationDataGenerator(input_shape=(args.input_size, args.input_size), batch_size = args.batch_size, augs = augs,\n",
    "                      preprocess = preprocess)\n",
    "\n",
    "    train_generator = dg.train_batch_generator(ids_train)\n",
    "    validation_generator = dg.evaluation_batch_generator(ids_valid)\n",
    "\n",
    "    callbacks = get_callback(args.callback, weights_path=weights_path,\n",
    "                            fold = fold)\n",
    "\n",
    "    # Fit the model with Generators:\n",
    "    model.fit_generator(generator=ThreadsafeIter(train_generator),\n",
    "                    steps_per_epoch=ids_train.shape[0] // args.batch_size * 2,\n",
    "                    epochs=args.epochs,\n",
    "                    callbacks=callbacks,\n",
    "                    validation_data=ThreadsafeIter(validation_generator),\n",
    "                    validation_steps=np.ceil(ids_valid.shape[0] / args.batch_size),\n",
    "                    workers=8)\n",
    "\n",
    "    model.load_weights(weights_path)\n",
    "\n",
    "    # SAVE OOF PREDICTIONS\n",
    "    dir_path = os.path.join(MODEL_PATH,'oof')\n",
    "    os.system(\"mkdir {}\".format(dir_path))\n",
    "    pred = classification_predict_test(model=model,\n",
    "                    preds_path=dir_path,\n",
    "                    oof=True,\n",
    "                    ids=ids_valid,\n",
    "                    batch_size=args.batch_size*4,\n",
    "                    thr=0.5,\n",
    "                    TTA='',\n",
    "                    preprocess=preprocess)\n",
    "    df_valid['prob'] = pred\n",
    "    validation_probs.append(df_valid)\n",
    "\n",
    "    # SAVE TEST PREDICTIONS\n",
    "    dir_path = os.path.join(MODEL_PATH,'fold_{}'.format(fold))\n",
    "    os.system(\"mkdir {}\".format(dir_path))\n",
    "    pred = classification_predict_test(model=model,\n",
    "                    preds_path=dir_path,\n",
    "                    oof=False,\n",
    "                    ids=test.id.values,\n",
    "                    batch_size=args.batch_size*4,\n",
    "                    thr=0.5,\n",
    "                    TTA='',\n",
    "                    preprocess=preprocess)\n",
    "    test['prob'] = pred\n",
    "    test.to_csv(os.path.join(dir_path,'probs_test_fold_{}.csv'.format(fold)),index=False)\n",
    "\n",
    "    K.clear_session()\n",
    "    # Run a single fold\n",
    "    # break\n",
    "\n",
    "dir_path = os.path.join(MODEL_PATH,'oof')\n",
    "pd.concat(validation_probs).to_csv(os.path.join(dir_path,'probs_oof.csv'),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
