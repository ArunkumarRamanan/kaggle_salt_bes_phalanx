{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!chmod u+x predict_all.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "***************************** FOLD 0 *****************************\n",
      "Training on 3127 samples\n",
      "Validating on 793 samples\n",
      "['unet_resnet_50_exp_0_144_192_snapshot_50_epochs_vp_1', 'fold_0.hdf5']\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "data (InputLayer)               (None, 192, 192, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bn_data (BatchNormalization)    (None, 192, 192, 3)  9           data[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPadding2D (None, 198, 198, 3)  0           bn_data[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv0 (Conv2D)                  (None, 96, 96, 64)   9408        zero_padding2d_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bn0 (BatchNormalization)        (None, 96, 96, 64)   256         conv0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "relu0 (Activation)              (None, 96, 96, 64)   0           bn0[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPadding2D (None, 98, 98, 64)   0           relu0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "pooling0 (MaxPooling2D)         (None, 48, 48, 64)   0           zero_padding2d_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_bn1 (BatchNormaliz (None, 48, 48, 64)   256         pooling0[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_relu1 (Activation) (None, 48, 48, 64)   0           stage1_unit1_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_conv1 (Conv2D)     (None, 48, 48, 64)   4096        stage1_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_bn2 (BatchNormaliz (None, 48, 48, 64)   256         stage1_unit1_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_relu2 (Activation) (None, 48, 48, 64)   0           stage1_unit1_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_3 (ZeroPadding2D (None, 50, 50, 64)   0           stage1_unit1_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_conv2 (Conv2D)     (None, 48, 48, 64)   36864       zero_padding2d_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_bn3 (BatchNormaliz (None, 48, 48, 64)   256         stage1_unit1_conv2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_relu3 (Activation) (None, 48, 48, 64)   0           stage1_unit1_bn3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_conv3 (Conv2D)     (None, 48, 48, 256)  16384       stage1_unit1_relu3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_sc (Conv2D)        (None, 48, 48, 256)  16384       stage1_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 48, 48, 256)  0           stage1_unit1_conv3[0][0]         \n",
      "                                                                 stage1_unit1_sc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_bn1 (BatchNormaliz (None, 48, 48, 256)  1024        add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_relu1 (Activation) (None, 48, 48, 256)  0           stage1_unit2_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_conv1 (Conv2D)     (None, 48, 48, 64)   16384       stage1_unit2_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_bn2 (BatchNormaliz (None, 48, 48, 64)   256         stage1_unit2_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_relu2 (Activation) (None, 48, 48, 64)   0           stage1_unit2_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_4 (ZeroPadding2D (None, 50, 50, 64)   0           stage1_unit2_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_conv2 (Conv2D)     (None, 48, 48, 64)   36864       zero_padding2d_4[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_bn3 (BatchNormaliz (None, 48, 48, 64)   256         stage1_unit2_conv2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_relu3 (Activation) (None, 48, 48, 64)   0           stage1_unit2_bn3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_conv3 (Conv2D)     (None, 48, 48, 256)  16384       stage1_unit2_relu3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 48, 48, 256)  0           stage1_unit2_conv3[0][0]         \n",
      "                                                                 add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_bn1 (BatchNormaliz (None, 48, 48, 256)  1024        add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_relu1 (Activation) (None, 48, 48, 256)  0           stage1_unit3_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_conv1 (Conv2D)     (None, 48, 48, 64)   16384       stage1_unit3_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_bn2 (BatchNormaliz (None, 48, 48, 64)   256         stage1_unit3_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_relu2 (Activation) (None, 48, 48, 64)   0           stage1_unit3_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_5 (ZeroPadding2D (None, 50, 50, 64)   0           stage1_unit3_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_conv2 (Conv2D)     (None, 48, 48, 64)   36864       zero_padding2d_5[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_bn3 (BatchNormaliz (None, 48, 48, 64)   256         stage1_unit3_conv2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_relu3 (Activation) (None, 48, 48, 64)   0           stage1_unit3_bn3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_conv3 (Conv2D)     (None, 48, 48, 256)  16384       stage1_unit3_relu3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 48, 48, 256)  0           stage1_unit3_conv3[0][0]         \n",
      "                                                                 add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_bn1 (BatchNormaliz (None, 48, 48, 256)  1024        add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_relu1 (Activation) (None, 48, 48, 256)  0           stage2_unit1_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_conv1 (Conv2D)     (None, 48, 48, 128)  32768       stage2_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_bn2 (BatchNormaliz (None, 48, 48, 128)  512         stage2_unit1_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_relu2 (Activation) (None, 48, 48, 128)  0           stage2_unit1_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_6 (ZeroPadding2D (None, 50, 50, 128)  0           stage2_unit1_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_conv2 (Conv2D)     (None, 24, 24, 128)  147456      zero_padding2d_6[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_bn3 (BatchNormaliz (None, 24, 24, 128)  512         stage2_unit1_conv2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_relu3 (Activation) (None, 24, 24, 128)  0           stage2_unit1_bn3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_conv3 (Conv2D)     (None, 24, 24, 512)  65536       stage2_unit1_relu3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_sc (Conv2D)        (None, 24, 24, 512)  131072      stage2_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 24, 24, 512)  0           stage2_unit1_conv3[0][0]         \n",
      "                                                                 stage2_unit1_sc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_bn1 (BatchNormaliz (None, 24, 24, 512)  2048        add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_relu1 (Activation) (None, 24, 24, 512)  0           stage2_unit2_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_conv1 (Conv2D)     (None, 24, 24, 128)  65536       stage2_unit2_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_bn2 (BatchNormaliz (None, 24, 24, 128)  512         stage2_unit2_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_relu2 (Activation) (None, 24, 24, 128)  0           stage2_unit2_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_7 (ZeroPadding2D (None, 26, 26, 128)  0           stage2_unit2_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_conv2 (Conv2D)     (None, 24, 24, 128)  147456      zero_padding2d_7[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_bn3 (BatchNormaliz (None, 24, 24, 128)  512         stage2_unit2_conv2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_relu3 (Activation) (None, 24, 24, 128)  0           stage2_unit2_bn3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_conv3 (Conv2D)     (None, 24, 24, 512)  65536       stage2_unit2_relu3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 24, 24, 512)  0           stage2_unit2_conv3[0][0]         \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_bn1 (BatchNormaliz (None, 24, 24, 512)  2048        add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_relu1 (Activation) (None, 24, 24, 512)  0           stage2_unit3_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_conv1 (Conv2D)     (None, 24, 24, 128)  65536       stage2_unit3_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_bn2 (BatchNormaliz (None, 24, 24, 128)  512         stage2_unit3_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_relu2 (Activation) (None, 24, 24, 128)  0           stage2_unit3_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_8 (ZeroPadding2D (None, 26, 26, 128)  0           stage2_unit3_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_conv2 (Conv2D)     (None, 24, 24, 128)  147456      zero_padding2d_8[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_bn3 (BatchNormaliz (None, 24, 24, 128)  512         stage2_unit3_conv2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_relu3 (Activation) (None, 24, 24, 128)  0           stage2_unit3_bn3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_conv3 (Conv2D)     (None, 24, 24, 512)  65536       stage2_unit3_relu3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 24, 24, 512)  0           stage2_unit3_conv3[0][0]         \n",
      "                                                                 add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_bn1 (BatchNormaliz (None, 24, 24, 512)  2048        add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_relu1 (Activation) (None, 24, 24, 512)  0           stage2_unit4_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_conv1 (Conv2D)     (None, 24, 24, 128)  65536       stage2_unit4_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_bn2 (BatchNormaliz (None, 24, 24, 128)  512         stage2_unit4_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_relu2 (Activation) (None, 24, 24, 128)  0           stage2_unit4_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_9 (ZeroPadding2D (None, 26, 26, 128)  0           stage2_unit4_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_conv2 (Conv2D)     (None, 24, 24, 128)  147456      zero_padding2d_9[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_bn3 (BatchNormaliz (None, 24, 24, 128)  512         stage2_unit4_conv2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_relu3 (Activation) (None, 24, 24, 128)  0           stage2_unit4_bn3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_conv3 (Conv2D)     (None, 24, 24, 512)  65536       stage2_unit4_relu3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 24, 24, 512)  0           stage2_unit4_conv3[0][0]         \n",
      "                                                                 add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_bn1 (BatchNormaliz (None, 24, 24, 512)  2048        add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_relu1 (Activation) (None, 24, 24, 512)  0           stage3_unit1_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_conv1 (Conv2D)     (None, 24, 24, 256)  131072      stage3_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_bn2 (BatchNormaliz (None, 24, 24, 256)  1024        stage3_unit1_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_relu2 (Activation) (None, 24, 24, 256)  0           stage3_unit1_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_10 (ZeroPadding2 (None, 26, 26, 256)  0           stage3_unit1_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_conv2 (Conv2D)     (None, 12, 12, 256)  589824      zero_padding2d_10[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_bn3 (BatchNormaliz (None, 12, 12, 256)  1024        stage3_unit1_conv2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_relu3 (Activation) (None, 12, 12, 256)  0           stage3_unit1_bn3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_conv3 (Conv2D)     (None, 12, 12, 1024) 262144      stage3_unit1_relu3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_sc (Conv2D)        (None, 12, 12, 1024) 524288      stage3_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 12, 12, 1024) 0           stage3_unit1_conv3[0][0]         \n",
      "                                                                 stage3_unit1_sc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_bn1 (BatchNormaliz (None, 12, 12, 1024) 4096        add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_relu1 (Activation) (None, 12, 12, 1024) 0           stage3_unit2_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_conv1 (Conv2D)     (None, 12, 12, 256)  262144      stage3_unit2_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_bn2 (BatchNormaliz (None, 12, 12, 256)  1024        stage3_unit2_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_relu2 (Activation) (None, 12, 12, 256)  0           stage3_unit2_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_11 (ZeroPadding2 (None, 14, 14, 256)  0           stage3_unit2_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_conv2 (Conv2D)     (None, 12, 12, 256)  589824      zero_padding2d_11[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_bn3 (BatchNormaliz (None, 12, 12, 256)  1024        stage3_unit2_conv2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_relu3 (Activation) (None, 12, 12, 256)  0           stage3_unit2_bn3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_conv3 (Conv2D)     (None, 12, 12, 1024) 262144      stage3_unit2_relu3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 12, 12, 1024) 0           stage3_unit2_conv3[0][0]         \n",
      "                                                                 add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_bn1 (BatchNormaliz (None, 12, 12, 1024) 4096        add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_relu1 (Activation) (None, 12, 12, 1024) 0           stage3_unit3_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_conv1 (Conv2D)     (None, 12, 12, 256)  262144      stage3_unit3_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_bn2 (BatchNormaliz (None, 12, 12, 256)  1024        stage3_unit3_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_relu2 (Activation) (None, 12, 12, 256)  0           stage3_unit3_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_12 (ZeroPadding2 (None, 14, 14, 256)  0           stage3_unit3_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_conv2 (Conv2D)     (None, 12, 12, 256)  589824      zero_padding2d_12[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_bn3 (BatchNormaliz (None, 12, 12, 256)  1024        stage3_unit3_conv2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_relu3 (Activation) (None, 12, 12, 256)  0           stage3_unit3_bn3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_conv3 (Conv2D)     (None, 12, 12, 1024) 262144      stage3_unit3_relu3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 12, 12, 1024) 0           stage3_unit3_conv3[0][0]         \n",
      "                                                                 add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_bn1 (BatchNormaliz (None, 12, 12, 1024) 4096        add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_relu1 (Activation) (None, 12, 12, 1024) 0           stage3_unit4_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_conv1 (Conv2D)     (None, 12, 12, 256)  262144      stage3_unit4_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_bn2 (BatchNormaliz (None, 12, 12, 256)  1024        stage3_unit4_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_relu2 (Activation) (None, 12, 12, 256)  0           stage3_unit4_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_13 (ZeroPadding2 (None, 14, 14, 256)  0           stage3_unit4_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_conv2 (Conv2D)     (None, 12, 12, 256)  589824      zero_padding2d_13[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_bn3 (BatchNormaliz (None, 12, 12, 256)  1024        stage3_unit4_conv2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_relu3 (Activation) (None, 12, 12, 256)  0           stage3_unit4_bn3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_conv3 (Conv2D)     (None, 12, 12, 1024) 262144      stage3_unit4_relu3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 12, 12, 1024) 0           stage3_unit4_conv3[0][0]         \n",
      "                                                                 add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_bn1 (BatchNormaliz (None, 12, 12, 1024) 4096        add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_relu1 (Activation) (None, 12, 12, 1024) 0           stage3_unit5_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_conv1 (Conv2D)     (None, 12, 12, 256)  262144      stage3_unit5_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_bn2 (BatchNormaliz (None, 12, 12, 256)  1024        stage3_unit5_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_relu2 (Activation) (None, 12, 12, 256)  0           stage3_unit5_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_14 (ZeroPadding2 (None, 14, 14, 256)  0           stage3_unit5_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_conv2 (Conv2D)     (None, 12, 12, 256)  589824      zero_padding2d_14[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_bn3 (BatchNormaliz (None, 12, 12, 256)  1024        stage3_unit5_conv2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_relu3 (Activation) (None, 12, 12, 256)  0           stage3_unit5_bn3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_conv3 (Conv2D)     (None, 12, 12, 1024) 262144      stage3_unit5_relu3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 12, 12, 1024) 0           stage3_unit5_conv3[0][0]         \n",
      "                                                                 add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_bn1 (BatchNormaliz (None, 12, 12, 1024) 4096        add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_relu1 (Activation) (None, 12, 12, 1024) 0           stage3_unit6_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_conv1 (Conv2D)     (None, 12, 12, 256)  262144      stage3_unit6_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_bn2 (BatchNormaliz (None, 12, 12, 256)  1024        stage3_unit6_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_relu2 (Activation) (None, 12, 12, 256)  0           stage3_unit6_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_15 (ZeroPadding2 (None, 14, 14, 256)  0           stage3_unit6_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_conv2 (Conv2D)     (None, 12, 12, 256)  589824      zero_padding2d_15[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_bn3 (BatchNormaliz (None, 12, 12, 256)  1024        stage3_unit6_conv2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_relu3 (Activation) (None, 12, 12, 256)  0           stage3_unit6_bn3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_conv3 (Conv2D)     (None, 12, 12, 1024) 262144      stage3_unit6_relu3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 12, 12, 1024) 0           stage3_unit6_conv3[0][0]         \n",
      "                                                                 add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_bn1 (BatchNormaliz (None, 12, 12, 1024) 4096        add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_relu1 (Activation) (None, 12, 12, 1024) 0           stage4_unit1_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_conv1 (Conv2D)     (None, 12, 12, 512)  524288      stage4_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_bn2 (BatchNormaliz (None, 12, 12, 512)  2048        stage4_unit1_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_relu2 (Activation) (None, 12, 12, 512)  0           stage4_unit1_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_16 (ZeroPadding2 (None, 14, 14, 512)  0           stage4_unit1_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_conv2 (Conv2D)     (None, 6, 6, 512)    2359296     zero_padding2d_16[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_bn3 (BatchNormaliz (None, 6, 6, 512)    2048        stage4_unit1_conv2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_relu3 (Activation) (None, 6, 6, 512)    0           stage4_unit1_bn3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_conv3 (Conv2D)     (None, 6, 6, 2048)   1048576     stage4_unit1_relu3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_sc (Conv2D)        (None, 6, 6, 2048)   2097152     stage4_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 6, 6, 2048)   0           stage4_unit1_conv3[0][0]         \n",
      "                                                                 stage4_unit1_sc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_bn1 (BatchNormaliz (None, 6, 6, 2048)   8192        add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_relu1 (Activation) (None, 6, 6, 2048)   0           stage4_unit2_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_conv1 (Conv2D)     (None, 6, 6, 512)    1048576     stage4_unit2_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_bn2 (BatchNormaliz (None, 6, 6, 512)    2048        stage4_unit2_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_relu2 (Activation) (None, 6, 6, 512)    0           stage4_unit2_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_17 (ZeroPadding2 (None, 8, 8, 512)    0           stage4_unit2_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_conv2 (Conv2D)     (None, 6, 6, 512)    2359296     zero_padding2d_17[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_bn3 (BatchNormaliz (None, 6, 6, 512)    2048        stage4_unit2_conv2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_relu3 (Activation) (None, 6, 6, 512)    0           stage4_unit2_bn3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_conv3 (Conv2D)     (None, 6, 6, 2048)   1048576     stage4_unit2_relu3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 6, 6, 2048)   0           stage4_unit2_conv3[0][0]         \n",
      "                                                                 add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_bn1 (BatchNormaliz (None, 6, 6, 2048)   8192        add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_relu1 (Activation) (None, 6, 6, 2048)   0           stage4_unit3_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_conv1 (Conv2D)     (None, 6, 6, 512)    1048576     stage4_unit3_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_bn2 (BatchNormaliz (None, 6, 6, 512)    2048        stage4_unit3_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_relu2 (Activation) (None, 6, 6, 512)    0           stage4_unit3_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_18 (ZeroPadding2 (None, 8, 8, 512)    0           stage4_unit3_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_conv2 (Conv2D)     (None, 6, 6, 512)    2359296     zero_padding2d_18[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_bn3 (BatchNormaliz (None, 6, 6, 512)    2048        stage4_unit3_conv2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_relu3 (Activation) (None, 6, 6, 512)    0           stage4_unit3_bn3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_conv3 (Conv2D)     (None, 6, 6, 2048)   1048576     stage4_unit3_relu3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 6, 6, 2048)   0           stage4_unit3_conv3[0][0]         \n",
      "                                                                 add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "bn1 (BatchNormalization)        (None, 6, 6, 2048)   8192        add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu1 (Activation)              (None, 6, 6, 2048)   0           bn1[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 12, 12, 2048) 0           relu1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 12, 12, 2560) 0           up_sampling2d_1[0][0]            \n",
      "                                                                 stage4_unit1_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv6_1_conv (Conv2D)           (None, 12, 12, 256)  5898496     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv6_1_bn (BatchNormalization) (None, 12, 12, 256)  1024        conv6_1_conv[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv6_1_activation (Activation) (None, 12, 12, 256)  0           conv6_1_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv6_2_conv (Conv2D)           (None, 12, 12, 256)  590080      conv6_1_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv6_2_bn (BatchNormalization) (None, 12, 12, 256)  1024        conv6_2_conv[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv6_2_activation (Activation) (None, 12, 12, 256)  0           conv6_2_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 24, 24, 256)  0           conv6_2_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 24, 24, 512)  0           up_sampling2d_2[0][0]            \n",
      "                                                                 stage3_unit1_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv7_1_conv (Conv2D)           (None, 24, 24, 192)  884928      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv7_1_bn (BatchNormalization) (None, 24, 24, 192)  768         conv7_1_conv[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv7_1_activation (Activation) (None, 24, 24, 192)  0           conv7_1_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv7_2_conv (Conv2D)           (None, 24, 24, 192)  331968      conv7_1_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv7_2_bn (BatchNormalization) (None, 24, 24, 192)  768         conv7_2_conv[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv7_2_activation (Activation) (None, 24, 24, 192)  0           conv7_2_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 48, 48, 192)  0           conv7_2_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 48, 48, 320)  0           up_sampling2d_3[0][0]            \n",
      "                                                                 stage2_unit1_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv8_1_conv (Conv2D)           (None, 48, 48, 128)  368768      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv8_1_bn (BatchNormalization) (None, 48, 48, 128)  512         conv8_1_conv[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv8_1_activation (Activation) (None, 48, 48, 128)  0           conv8_1_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv8_2_conv (Conv2D)           (None, 48, 48, 128)  147584      conv8_1_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv8_2_bn (BatchNormalization) (None, 48, 48, 128)  512         conv8_2_conv[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv8_2_activation (Activation) (None, 48, 48, 128)  0           conv8_2_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 96, 96, 128)  0           conv8_2_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 96, 96, 192)  0           up_sampling2d_4[0][0]            \n",
      "                                                                 relu0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv9_1_conv (Conv2D)           (None, 96, 96, 64)   110656      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv9_1_bn (BatchNormalization) (None, 96, 96, 64)   256         conv9_1_conv[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv9_1_activation (Activation) (None, 96, 96, 64)   0           conv9_1_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv9_2_conv (Conv2D)           (None, 96, 96, 64)   36928       conv9_1_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv9_2_bn (BatchNormalization) (None, 96, 96, 64)   256         conv9_2_conv[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv9_2_activation (Activation) (None, 96, 96, 64)   0           conv9_2_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2D)  (None, 192, 192, 64) 0           conv9_2_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 192, 192, 67) 0           up_sampling2d_5[0][0]            \n",
      "                                                                 data[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "conv10_1_conv (Conv2D)          (None, 192, 192, 32) 19328       concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv10_1_bn (BatchNormalization (None, 192, 192, 32) 128         conv10_1_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv10_1_activation (Activation (None, 192, 192, 32) 0           conv10_1_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv10_2_conv (Conv2D)          (None, 192, 192, 32) 9248        conv10_1_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv10_2_bn (BatchNormalization (None, 192, 192, 32) 128         conv10_2_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv10_2_activation (Activation (None, 192, 192, 32) 0           conv10_2_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout2d_1 (SpatialDro (None, 192, 192, 32) 0           conv10_2_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "prediction (Conv2D)             (None, 192, 192, 1)  33          spatial_dropout2d_1[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 31,949,450\n",
      "Trainable params: 31,901,188\n",
      "Non-trainable params: 48,262\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No weights passed, training from scratch\n",
      "Epoch 1/50\n",
      "260/260 [==============================] - 123s 475ms/step - loss: 0.5779 - Kaggle_IoU_Precision: 0.2379 - val_loss: 0.3834 - val_Kaggle_IoU_Precision: 0.4516\n",
      "Epoch 2/50\n",
      "260/260 [==============================] - 114s 437ms/step - loss: 0.4737 - Kaggle_IoU_Precision: 0.4853 - val_loss: 0.3005 - val_Kaggle_IoU_Precision: 0.7538\n",
      "Epoch 3/50\n",
      "260/260 [==============================] - 114s 437ms/step - loss: 0.4442 - Kaggle_IoU_Precision: 0.5814 - val_loss: 0.3030 - val_Kaggle_IoU_Precision: 0.7334\n",
      "Epoch 4/50\n",
      "260/260 [==============================] - 114s 437ms/step - loss: 0.4348 - Kaggle_IoU_Precision: 0.6047 - val_loss: 0.2440 - val_Kaggle_IoU_Precision: 0.7702\n",
      "Epoch 5/50\n",
      " 44/260 [====>.........................] - ETA: 1:29 - loss: 0.4318 - Kaggle_IoU_Precision: 0.5967"
     ]
    }
   ],
   "source": [
    "!./train_all.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!./evaluate_all.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!./predict_all.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "import gc\n",
    "from keras.optimizers import Adam, RMSprop, SGD\n",
    "\n",
    "from utils import predict_test, evaluate, ensemble, ThreadsafeIter, classification_predict_test\n",
    "from datasets.generators import SegmentationDataGenerator, ClassificationDataGenerator\n",
    "\n",
    "from params import args\n",
    "from callbacks import get_callback\n",
    "from augmentations import get_augmentations\n",
    "\n",
    "from models.models import get_model\n",
    "\n",
    "from losses import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train = pd.read_csv(os.path.join(args.data_root,'train_proc_v2.csv'))\n",
    "test = pd.read_csv(os.path.join(args.data_root,'sample_submission.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cyclic LR\n",
    "# T = nb_epochs\n",
    "# M = nb_snapshots\n",
    "# alpha_zero = init_lr\n",
    "\n",
    "T = 200\n",
    "M = 4\n",
    "alpha_zero = 0.0001\n",
    "\n",
    "import numpy as np\n",
    "t = 199\n",
    "\n",
    "cos_inner = np.pi * (t % (T // M))  # t - 1 is used when t has 1-based indexing.\n",
    "cos_inner /= T // M\n",
    "cos_out = np.cos(cos_inner) + 1\n",
    "float(alpha_zero / 2 * cos_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(os.path.join(args.images_dir,'{}.png'.format('88839f49f9')), cv2.IMREAD_COLOR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from albumentations import *\n",
    "#augmentation = PadIfNeeded(min_height=128, min_width=128, p=1.0, border_mode=0) \n",
    "augmentation = Compose([\n",
    "            #RandomRotate90(p=1),\n",
    "                HorizontalFlip(p=.5),\n",
    "                RandomBrightness(p=.2,limit=0.2),\n",
    "                RandomContrast(p=.1,limit=0.2),\n",
    "                ShiftScaleRotate(shift_limit=0.1625, scale_limit=0., rotate_limit=0, p=1),\n",
    "                RandomCrop(height=96, width=96,p=1)\n",
    "            ], p=1)\n",
    "\n",
    "data = {\"image\": img}\n",
    "augmented = augmentation(**data)\n",
    "img_pad = augmented[\"image\"]\n",
    "\n",
    "# from albumentations import PadIfNeeded\n",
    "# augmentation = PadIfNeeded(min_height=128, min_width=128, p=1.0, border_mode=4) \n",
    "# data = {\"image\": img}\n",
    "# augmented = augmentation(**data)\n",
    "# img_pad = augmented[\"image\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for network in args.network.split(','):\n",
    "    folds = [int(f) for f in args.fold.split(',')]\n",
    "    for fold in folds:\n",
    "        K.clear_session()\n",
    "        print('***************************** FOLD {} *****************************'.format(fold))\n",
    "\n",
    "        MODEL_PATH = os.path.join(args.models_dir,network+args.alias)\n",
    "\n",
    "#         if fold == 0:\n",
    "#             if os.path.isdir(MODEL_PATH):\n",
    "#                 raise ValueError('Such Model already exists')\n",
    "#             os.system(\"mkdir {}\".format(MODEL_PATH))\n",
    "#             os.system(\"cp params.py {}\".format(MODEL_PATH))\n",
    "\n",
    "        df_train = train[train.fold != fold].copy().reset_index(drop=True)\n",
    "        df_valid = train[train.fold == fold].copy().reset_index(drop=True)\n",
    "\n",
    "        ids_train, ids_valid = df_train[df_train.unique_pixels>1].id.values, df_valid.id.values\n",
    "\n",
    "        # Fold 0\n",
    "        # Training on 3127 samples\n",
    "        # Validating on 810 samples\n",
    "        # ids_train, ids_valid = df_train[(df_train.unique_pixels>1)&(~df_train.id.isin(bad_masks))].id.values, df_valid.id.values\n",
    "\n",
    "\n",
    "        print('Training on {} samples'.format(ids_train.shape[0]))\n",
    "        print('Validating on {} samples'.format(ids_valid.shape[0]))\n",
    "\n",
    "        # Initialize Model\n",
    "        weights_path = os.path.join(MODEL_PATH,'fold_{fold}.hdf5'.format(fold=fold))\n",
    "        #weights_path = os.path.join(MODEL_PATH,'fold_{fold}'.format(fold=fold))\n",
    "        \n",
    "        print(weights_path.split('/')[-2:])\n",
    "\n",
    "\n",
    "        model, preprocess = get_model(network, input_shape=(args.input_size, args.input_size, 3), train_base=True)\n",
    "        print(model.summary())\n",
    "        model.compile(optimizer=RMSprop(lr=args.learning_rate), loss=make_loss(args.loss_function),\n",
    "                          metrics=[Kaggle_IoU_Precision])\n",
    "\n",
    "        if args.weights is None:\n",
    "            print('No weights passed, training from scratch')\n",
    "        else:\n",
    "            wp = args.weights.format(fold)\n",
    "            print('Loading weights from {}'.format(wp))\n",
    "            model.load_weights(wp, by_name=True)\n",
    "\n",
    "        augs = get_augmentations(args.augmentation_name, p=args.augmentation_prob, input_shape=(args.input_size, args.input_size, 3))\n",
    "\n",
    "\n",
    "        dg = SegmentationDataGenerator(input_shape=(args.input_size, args.input_size), batch_size = args.batch_size, augs = augs,\n",
    "                          preprocess = preprocess)\n",
    "\n",
    "        train_generator = dg.train_batch_generator(ids_train)\n",
    "        validation_generator = dg.evaluation_batch_generator(ids_valid)\n",
    "\n",
    "        callbacks = get_callback(args.callback, weights_path=weights_path,\n",
    "                                fold = fold)\n",
    "\n",
    "#         # Fit the model with Generators:\n",
    "#         model.fit_generator(generator=ThreadsafeIter(train_generator),\n",
    "#                         steps_per_epoch=ids_train.shape[0] // args.batch_size * 2,\n",
    "#                         epochs=args.epochs,\n",
    "#                         callbacks=callbacks,\n",
    "#                         validation_data=ThreadsafeIter(validation_generator),\n",
    "#                         validation_steps=np.ceil(ids_valid.shape[0] / args.batch_size),\n",
    "#                         workers=12)\n",
    "\n",
    "        \n",
    "#         dir_path = os.path.join(MODEL_PATH,'oof')\n",
    "#         os.system(\"mkdir {}\".format(dir_path))\n",
    "#         best_res = 0\n",
    "#         best_weights_path = ''\n",
    "#         for w in sorted(os.listdir(MODEL_PATH))[-13:-2]:\n",
    "#             print(w)\n",
    "#             weights_path = os.path.join(MODEL_PATH,w)\n",
    "#             model.load_weights(weights_path,by_name=False)\n",
    "\n",
    "#             # SAVE OOF PREDICTIONS\n",
    "#             pred = predict_test(model=model,\n",
    "#                             preds_path=dir_path,\n",
    "#                             oof=True,\n",
    "#                             ids=ids_valid,\n",
    "#                             batch_size=args.batch_size*2,\n",
    "#                             thr=0.5,\n",
    "#                             TTA='',\n",
    "#                             preprocess=preprocess)\n",
    "#             res = evaluate([MODEL_PATH], train[train.fold.isin([fold])].id.values, 0.5, classification='')\n",
    "#             print(np.mean(res['iout']))\n",
    "#             if np.mean(res['iout']) > best_res:\n",
    "#                 best_res = np.mean(res['iout'])\n",
    "#                 best_weights_path = weights_path\n",
    "        \n",
    "#         print(best_weights_path)\n",
    "#         print(best_res)\n",
    "        \n",
    "#         best_weights_path = weights_path\n",
    "#         model.load_weights(best_weights_path)\n",
    "\n",
    "#         # SAVE OOF PREDICTIONS\n",
    "#         dir_path = os.path.join(MODEL_PATH,'oof')\n",
    "#         os.system(\"mkdir {}\".format(dir_path))\n",
    "#         pred = predict_test(model=model,\n",
    "#                         preds_path=dir_path,\n",
    "#                         oof=True,\n",
    "#                         ids=ids_valid,\n",
    "#                         batch_size=args.batch_size*2,\n",
    "#                         thr=0.5,\n",
    "#                         TTA='flip',\n",
    "#                         preprocess=preprocess)\n",
    "\n",
    "        # SAVE TEST PREDICTIONS\n",
    "#         dir_path = os.path.join(MODEL_PATH,'fold_{}'.format(fold))\n",
    "#         os.system(\"mkdir {}\".format(dir_path))\n",
    "#         pred = predict_test(model=model,\n",
    "#                         preds_path=dir_path,\n",
    "#                         oof=False,\n",
    "#                         ids=test.id.values,\n",
    "#                         batch_size=args.batch_size*2,\n",
    "#                         thr=0.5,\n",
    "#                         TTA='flip',\n",
    "#                         preprocess=preprocess)\n",
    "\n",
    "        # K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "200*114/60/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.alias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "577536"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "#     'unet_resnet_152_valid_plus_resize_202_pad_256_bs_12_corr',\n",
    "#           'unet_resnet_152_valid_plus_resize_202_pad_256_bs_12_corr',\n",
    "#           'unet_resnet_152_finetuning_v2_reduce_lr_flip',\n",
    "#           'unet_resnet_50unet_resnet_50_exp_0_144_192_new_scheduler_200_epochs',\n",
    "#           'unet_resnet_50unet_resnet_50_exp_0_144_192_new_scheduler_200_epochs_bce_jacard_dice',\n",
    "#           'resnet50_fpn_96_soft_early_stopping',\n",
    "#           'resnet50_fpn_old',\n",
    "#           'unet_resnet_34_valid_plus_resize_202_pad_256_bs_24',\n",
    "#           'unet_resnet_152_exp_0_202_256_scheduler_150_epochs_finetune',\n",
    "#           'unet_resnet_152_exp_0_202_256_scheduler_150_epochs_finetune'\n",
    "    'unet_resnet_50_exp_0_160_160_snapshot_50_epochs',\n",
    "    #'unet_resnet_50_exp_0_224_224_snapshot_50_epochs',\n",
    "    #'unet_resnet_50_exp_0_192_192_snapshot_50_epochs'\n",
    "         ]\n",
    "model_pathes = ['/home/branding_images/salt/'+x for x in models]\n",
    "res = evaluate(model_pathes, train[train.fold.isin([0])].id.values, 0.5, classification='')\n",
    "print(\"{} / {} / {}\".format(np.round(np.mean(res['iout']),5),np.round(np.mean(res['dice']),5),np.round(np.mean(res['jacard']),5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.88037 / 0.91051 / 0.89145"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!./evaluate_all.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet_resnet_50_exp_0_128_128_snapshot_50_epochs\n",
    "best: 0.84 / 0.88259 / 0.85977 + \n",
    "snapshot: 0.84012 / 0.88206 / 0.85958\n",
    "    \n",
    "unet_resnet_50_exp_0_160_160_snapshot_50_epochs\n",
    "best: 0.85815 / 0.89563 / 0.8748 + \n",
    "snapshot: 0.84951 / 0.88725 / 0.8658\n",
    "    \n",
    "unet_resnet_50_exp_0_192_192_snapshot_50_epochs\n",
    "best: 0.84938 / 0.88747 / 0.86692 +\n",
    "snapshot: 0.84605 / 0.8844 / 0.86327\n",
    "    \n",
    "unet_resnet_50_exp_0_224_224_snapshot_50_epochs\n",
    "best: 0.84568 / 0.8805 / 0.85981 +\n",
    "snapshot: 0.84753 / 0.88444 / 0.86321 +\n",
    "    \n",
    "unet_resnet_50_exp_0_256_256_snapshot_50_epochs\n",
    "best: 0.83395 / 0.87394 / 0.8526 +\n",
    "snapshot: 0.83037 / 0.86933 / 0.84849 +\n",
    "    \n",
    "unet_resnet_50_exp_0_144_192_snapshot_50_epochs\n",
    "best: 0.85827 / 0.89389 / 0.87291 +\n",
    "snapshot: 0.85457 / 0.89015 / 0.86881 +\n",
    "    \n",
    "unet_resnet_50_exp_0_160_192_snapshot_50_epochs\n",
    "best: 0.85568 / 0.89174 / 0.86991 +\n",
    "snapshot: 0.85494 / 0.89127 / 0.86885 +\n",
    "    \n",
    "unet_resnet_50_exp_0_176_192_snapshot_50_epochs\n",
    "best: 0.85815 / 0.89138 / 0.87119 +\n",
    "snapshot: 0.85025 / 0.88615 / 0.86518 -\n",
    "    \n",
    "unet_resnet_50_exp_0_144_224_snapshot_50_epochs\n",
    "best: 0.85198 / 0.88523 / 0.8643 +\n",
    "snapshot: 0.85494 / 0.89099 / 0.86941 -\n",
    "    \n",
    "unet_resnet_50_exp_0_192_224_snapshot_50_epochs\n",
    "best: 0.85914 / 0.89893 / 0.87727 +\n",
    "snapshot: 0.85864 / 0.89403 / 0.87285 -\n",
    "    \n",
    "unet_resnet_50_exp_0_202_256_snapshot_50_epochs\n",
    "best: 0.84901 / 0.88852 / 0.86643 +\n",
    "snapshot: 0.85136 / 0.8927 / 0.87084 -\n",
    "    \n",
    "unet_resnet_152_exp_0_192_224_snapshot_50_epochs\n",
    "best: 0.86395 / 0.89585 / 0.8749 +\n",
    "snapshot: 0.86321 / 0.89516 / 0.87405 -\n",
    "    \n",
    "unet_resnet_50_exp_0_144_192_snapshot_50_epochs_lr_00002_v2\n",
    "best: 0.85519 / 0.88991 / 0.86846\n",
    "snapshot: 0.85815 / 0.89012 / 0.86858\n",
    "\n",
    "    \n",
    "0.87284 +"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = '/home/branding_images/salt/unet_resnet_50_exp_0_144_192_snapshot_50_epochs_lr_00002_v2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import evaluate,evaluate_exp\n",
    "res = evaluate([MODEL_PATH], train[train.fold.isin([0])].id.values, 0.5, classification='')\n",
    "print(\"{} / {} / {}\".format(np.round(np.mean(res['iout']),5),np.round(np.mean(res['dice']),5),np.round(np.mean(res['jacard']),5)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.input_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = os.path.join(MODEL_PATH,'oof')\n",
    "#w='snapshot-1.h5'\n",
    "w='fold_0.hdf5'\n",
    "weights_path = os.path.join(MODEL_PATH,w)\n",
    "model.load_weights(weights_path,by_name=False)\n",
    "\n",
    "# SAVE OOF PREDICTIONS\n",
    "pred = predict_test(model=model,\n",
    "                preds_path=dir_path,\n",
    "                oof=True,\n",
    "                ids=ids_valid,\n",
    "                batch_size=args.batch_size*2,\n",
    "                thr=0.5,\n",
    "                TTA='flip',\n",
    "                preprocess=preprocess)\n",
    "res = evaluate([MODEL_PATH], train[train.fold.isin([0])].id.values, 0.5, classification='')\n",
    "print(\"{} / {} / {}\".format(np.round(np.mean(res['iout']),5),np.round(np.mean(res['dice']),5),np.round(np.mean(res['jacard']),5)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NEEW!\n",
    "**************************************\n",
    "unet_resnet_50_exp_0_resize_144_pad_192\n",
    "0.83531 / 0.88551 / 0.86118\n",
    "\n",
    "resnet50_fpn_exp_0_resize_144_pad_192\n",
    "0.84185 / 0.88208 / 0.85874   \n",
    "**************************************\n",
    "\n",
    "7 and 15 for early stopping\n",
    "\n",
    "# NO TTA\n",
    "? unet_resnet_50_exp_0_resize_144_pad_192\n",
    "? 0.83531 / 0.88551 / 0.86118\n",
    "\n",
    "unet_resnet_50_exp_0_144_192_new\n",
    "0.85951 / 0.89916 / 0.87709\n",
    "unet_resnet_50unet_resnet_50_exp_0_144_192_new_again\n",
    "0.85568 / 0.89098 / 0.86968\n",
    "\n",
    "- resnet50_fpn_exp_0_144_192_new\n",
    "0.85667 / 0.89677 / 0.87466\n",
    "\n",
    "- unet_resnet_50_exp_0_144_192_rotate_limit_15\n",
    "0.85753 / 0.89051 / 0.87015\n",
    "\n",
    "- unet_resnet_50_exp_0_144_192_no_dropout\n",
    "0.85173 / 0.89125 / 0.86898\n",
    "\n",
    "++ unet_resnet_50unet_resnet_50_exp_0_144_192_new_scheduler_200_epochs\n",
    "0.86519 / 0.89751 / 0.87723\n",
    "\n",
    "-? unet_resnet_50unet_resnet_50_exp_0_144_192_new_scheduler_200_epochs_bce_jacard_dice\n",
    "0.86198 / 0.89741 / 0.87645\n",
    "\n",
    "+? unet_resnet_50unet_resnet_50_exp_0_144_192_new_scheduler_200_epochs_finetune\n",
    "0.86654 / 0.90456 / 0.88377\n",
    "\n",
    "run ResNet152_fpn over the night"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NEEW!\n",
    "\n",
    "unet_resnet_34_exp_0_resize_144_pad_192_cyclic_lr_metric_checkpoint_v1\n",
    "0.82593 / 0.87479 / 0.85012\n",
    "\n",
    "\n",
    "unet_resnet_152_finetuning_cyclic_lr\n",
    "0 fold: 0.86494 / 0.89766 / 0.87698\n",
    "all folds:\n",
    "    \n",
    "unet_resnet_152_finetuning_v2_reduce_lr_flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir_path = os.path.join(MODEL_PATH,'oof')\n",
    "# os.system(\"mkdir {}\".format(dir_path))\n",
    "\n",
    "dir_path = os.path.join(MODEL_PATH,'oof')\n",
    "w='fold_0.25-0.17-0.8067-0.8226.hdf5'\n",
    "weights_path = os.path.join(MODEL_PATH,w)\n",
    "model.load_weights(weights_path,by_name=False)\n",
    "\n",
    "# SAVE OOF PREDICTIONS\n",
    "pred = predict_test(model=model,\n",
    "                preds_path=dir_path,\n",
    "                oof=True,\n",
    "                ids=ids_valid,\n",
    "                batch_size=args.batch_size*2,\n",
    "                thr=0.5,\n",
    "                TTA='',\n",
    "                preprocess=preprocess)\n",
    "res = evaluate([MODEL_PATH], train[train.fold.isin([0])].id.values, 0.5, classification='')\n",
    "print(np.mean(res['iout']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet_resnet_34_exp_0_resize_144_pad_192_early_stopping\n",
    "0.79975 / 0.85854 / 0.83097\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet_resnet_34_do_exp_0_resize_144_pad_192_do_04_02_middle_cycle_lr_div_16_1\n",
    "fold_0.39-0.19-0.8095-0.8258.hdf5\n",
    "0.8293827160493826\n",
    "\n",
    "fold_0.29-0.16-0.7881-0.8075.hdf5\n",
    "0.8212345679012346\n",
    "\n",
    "fold_0.37-0.19-0.8130-0.8294.hdf5\n",
    "0.8325925925925927"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet_resnet_34_do_exp_0_resize_144_pad_192_do_04_02_middle_checkpoint_cycle_lr\n",
    "fold_0.27-0.19-0.8004-0.8186.hdf5\n",
    "0.8218518518518519\n",
    "\n",
    "fold_0.17-0.16-0.8068-0.8210.hdf5\n",
    "0.8303703703703704\n",
    "\n",
    "fold_0.23-0.17-0.8112-0.8298.hdf5\n",
    "0.8306172839506172"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet_resnet_34_do_exp_0_resize_144_pad_192_do_04_02_middle_cycle_lr_1_x6\n",
    "fold_0.17-0.16-0.8068-0.8230.hdf5\n",
    "0.8288888888888889\n",
    "\n",
    "fold_0.25-0.17-0.8067-0.8226.hdf5\n",
    "0.8314814814814815\n",
    "without pixel deletion: 0.8267901234567901"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best?\n",
    "fold_0.24-0.15-0.8235-0.8385.hdf5\n",
    "0.83877 / 0.88339 / 0.85986\n",
    "\n",
    "fold_0.34-0.16-0.8289-0.8448.hdf5\n",
    "0.84704 / 0.88595 / 0.86255\n",
    "\n",
    "fold_0.33-0.16-0.8325-0.8449.hdf5\n",
    "0.84753 / 0.88669 / 0.86399\n",
    "\n",
    "fold_0.32-0.16-0.8275-0.8435.hdf5\n",
    "0.84309 / 0.88288 / 0.85965\n",
    "\n",
    "fold_0.31-0.16-0.8241-0.8394.hdf5\n",
    "0.84358 / 0.88345 / 0.85945\n",
    "\n",
    "fold_0.30-0.16-0.8268-0.8417.hdf5\n",
    "0.84148 / 0.88327 / 0.85987\n",
    "\n",
    "fold_0.29-0.16-0.8360-0.8509.hdf5\n",
    "0.85 / 0.89057 / 0.86772"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Total params: 25,282,186\n",
    "Trainable params: 25,264,132\n",
    "Non-trainable params: 18,054\n",
    "\n",
    "psp concat:\n",
    "Total params: 25,283,338\n",
    "Trainable params: 25,265,284\n",
    "Non-trainable params: 18,054\n",
    "    \n",
    "with UpSampling:\n",
    "Total params: 28,748,554\n",
    "Trainable params: 28,730,500\n",
    "Non-trainable params: 18,054\n",
    "    \n",
    "2 conv_blocks in the middle\n",
    "Total params: 30,005,898\n",
    "Trainable params: 29,985,796\n",
    "Non-trainable params: 20,102\n",
    "    \n",
    "increase capacity x2:\n",
    "Total params: 33,003,594\n",
    "Trainable params: 32,982,852\n",
    "Non-trainable params: 20,742"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = '/home/branding_images/salt/unet_resnet_50_valid_plus_resize_202_pad_256_bs_24'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'/home/branding_images/salt/classification/oof'\n",
    "res = evaluate([MODEL_PATH], train[train.fold.isin([0,1])].id.values, 0.5, classification='')\n",
    "print(\"{} / {} / {}\".format(np.round(np.mean(res['iout']),5),np.round(np.mean(res['dice']),5),np.round(np.mean(res['jacard']),5)))\n",
    "res = evaluate([MODEL_PATH], train[train.fold.isin([0])].id.values, 0.5, classification='')\n",
    "print(\"{} / {} / {}\".format(np.round(np.mean(res['iout']),5),np.round(np.mean(res['dice']),5),np.round(np.mean(res['jacard']),5)))\n",
    "res = evaluate([MODEL_PATH], train[train.fold.isin([1])].id.values, 0.5, classification='')\n",
    "print(\"{} / {} / {}\".format(np.round(np.mean(res['iout']),5),np.round(np.mean(res['dice']),5),np.round(np.mean(res['jacard']),5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = evaluate([MODEL_PATH], train[train.fold.isin([0])].id.values, 0.5, classification='')\n",
    "print(\"{} / {} / {}\".format(np.round(np.mean(res['iout']),5),np.round(np.mean(res['dice']),5),np.round(np.mean(res['jacard']),5)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res = evaluate(model_pathes, train[train.fold.isin([0])].id.values, 0.5, classification='')\n",
    "# print(\"{} / {} / {}\".format(np.round(np.mean(res['iout']),5),np.round(np.mean(res['dice']),5),np.round(np.mean(res['jacard']),5)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "96 -- 3x3\n",
    "192 -- 6x6\n",
    "256 -- 8x8\n",
    "//32\n",
    "288 -- would be 9x9\n",
    "384 -- would be 12x12\n",
    "512 -- would be 16x16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet_resnet_34_do_exp_0_resize_144_pad_192_do_04_last\n",
    "0.83432 / 0.88136 / 0.8565\n",
    "unet_resnet_34_do_exp_0_resize_144_pad_192_do_04_last_again\n",
    "0.84728 / 0.89039 / 0.86695\n",
    "\n",
    "unet_resnet_34_do_exp_0_resize_144_pad_192_do_04_last_02_do_in_middle\n",
    "0.84864 / 0.89183 / 0.86803\n",
    "    TTA: 0.8521 / 0.89261 / 0.86979\n",
    "unet_resnet_34_do_exp_0_resize_144_pad_192_do_04_last_02_do_in_middle_again\n",
    "0.84802 / 0.88714 / 0.8648\n",
    "unet_resnet_34_do_exp_0_resize_144_pad_192_do_04_last_02_do_in_middle_try\n",
    "0.84556 / 0.88715 / 0.8643\n",
    "\n",
    "0.83753 / 0.88699 / 0.86237\n",
    "\n",
    "unet_resnet_34_do_exp_0_resize_144_pad_192_do_04_last_02_do_in_middle_from_scratch\n",
    "0.79198 / 0.84075 / 0.81404\n",
    "\n",
    "unet_resnet_34_do_exp_0_resize_144_pad_192_do_04_last_02_do_in_middle_lr_0001\n",
    "0.82654 / 0.86517 / 0.84159\n",
    "\n",
    "unet_resnet_34_do_exp_0_resize_144_pad_192_do_04_last_02_do_in_middle_Conv2DTranspose\n",
    "0.83728 / 0.88476 / 0.86042\n",
    "unet_resnet_34_do_exp_0_resize_144_pad_192_do_04_last_02_do_in_middle_Conv2DTranspose_again\n",
    "0.83802 / 0.88051 / 0.85617\n",
    "\n",
    "unet_resnet_34_do_exp_0_resize_144_pad_192_do_04_last_02_do_in_middle_2_conv_blocks_in_middle\n",
    "0.84049 / 0.87981 / 0.85704\n",
    "\n",
    "unet_resnet_34_do_exp_0_resize_144_pad_192_do_04_last_02_do_in_middle_x2_capacity\n",
    "0.84074 / 0.88782 / 0.86356\n",
    "\n",
    "RMSPROP!\n",
    "unet_resnet_34_do_exp_0_resize_144_pad_192_do_04_last_02_do_in_middle_sgd_0001\n",
    "0.82802 / 0.86422 / 0.84122\n",
    "\n",
    "unet_resnet_34_do_exp_0_resize_144_pad_192_do_04_last_02_do_in_middle_sgd_001\n",
    "0.7579 / 0.82288 / 0.7932\n",
    "\n",
    "unet_resnet_34_do_exp_0_resize_144_pad_192_do_04_last_02_do_in_middle_adam_00001\n",
    "0.83988 / 0.88111 / 0.85803\n",
    "\n",
    "\n",
    "psp_concat\n",
    "unet_resnet_34_do_exp_0_resize_144_pad_192_do_04_last_psp_concat\n",
    "0.84333 / 0.88874 / 0.86519\n",
    "unet_resnet_34_do_exp_0_resize_144_pad_192_do_04_last_psp_concat_again\n",
    "0.83877 / 0.88339 / 0.85986\n",
    "\n",
    "    \n",
    "unet_resnet_34_do_exp_0_resize_144_pad_192_do_04_02_in_middle_96_crop    \n",
    "0.83667 / 0.8827 / 0.85833    \n",
    " \n",
    "# YOU'VE UPDATED ALBUMENTATIOOONNSS!\n",
    "unet_resnet_34_do_exp_0_resize_144_pad_192_do_04_02_in_middle_92_crop_resize_101\n",
    "0.83235 / 0.87777 / 0.85349\n",
    "\n",
    "# YOU'VE UPDATED ALBUMENTATIOOONNSS!\n",
    "unet_resnet_34_do_exp_0_resize_144_pad_192_do_04_02_in_middle_96_crop_no_scaling\n",
    "0.83716 / 0.87899 / 0.85579\n",
    "\n",
    "\n",
    "\n",
    "# YOU'VE UPDATED ALBUMENTATIOOONNSS!\n",
    "RESIZE TO 192!\n",
    "unet_resnet_34_do_exp_0_resize_192_do_04_02_in_middle\n",
    "0.83086 / 0.87579 / 0.85235\n",
    "unet_resnet_34_do_exp_0_resize_144_pad_192_do_04_02_middle_checkpoint\n",
    "0.83593 / 0.87663 / 0.85302\n",
    "unet_resnet_34_do_exp_0_resize_144_pad_192_do_04_02_middle_checkpoint_again\n",
    "0.82901 / 0.87291 / 0.84924\n",
    "\n",
    "# YOU'VE UPDATED ALBUMENTATIOOONNSS!\n",
    "unet_resnet_34_do_exp_0_resize_144_pad_192_do_04_02_middle_checkpoint_corr\n",
    "0.8258 / 0.87866 / 0.85393\n",
    "unet_resnet_34_do_exp_0_resize_144_pad_192_do_04_02_middle_checkpoint_corr_again\n",
    "0.84432 / 0.8842 / 0.86197\n",
    "unet_resnet_34_do_exp_0_resize_144_pad_192_do_04_02_middle_checkpoint_revert_albumentations\n",
    "0.83753 / 0.88699 / 0.86237\n",
    "< 30 pix: 0.84111 / 0.88865 / 0.8645\n",
    "*********************************************************\n",
    "unet_resnet_34_exp_0_resize_144_pad_192\n",
    "0.82519 / 0.87639 / 0.85106\n",
    "\n",
    "unet_resnet_34_do_exp_0_resize_144_pad_192\n",
    "0.83086 / 0.87799 / 0.85441\n",
    "\n",
    "resnet34_fpn_exp_0_resize_144_pad_192\n",
    "0.8342 / 0.88145 / 0.85613\n",
    "\n",
    "unet_resnet_50_exp_0_resize_144_pad_192\n",
    "0.83531 / 0.88551 / 0.86118\n",
    "\n",
    "resnet50_fpn_exp_0_resize_144_pad_192\n",
    "0.84185 / 0.88208 / 0.85874    \n",
    "*********************************************************\n",
    "    \n",
    "unet_resnet_34_do_exp_0_resize_144_pad_192_wtf\n",
    "0.83333 / 0.88131 / 0.85726\n",
    "    TTA: 0.8442 / 0.88683 / 0.86383\n",
    "unet_resnet_34_do_exp_0_resize_144_pad_192_wtf_again\n",
    "0.84062 / 0.88159 / 0.85864\n",
    "    TTA: 0.84198 / 0.884 / 0.86134\n",
    "\n",
    "just on epoch to freeze the encoder (to warm-up decoder a little bit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet_resnet_34_exp_2_resize_144_pad_192 \n",
    "0.83451 / 0.88055 / 0.857\n",
    "    fold 0: 0.84716 / 0.88915 / 0.86693\n",
    "    fold 1: 0.82177 / 0.87189 / 0.847\n",
    "unet_resnet_34_exp_2_resize_144_pad_192_again\n",
    "0.83271 / 0.87971 / 0.85611\n",
    "    fold 0: 0.84222 / 0.88539 / 0.8622\n",
    "    fold 1: 0.82313 / 0.87398 / 0.84997\n",
    "        \n",
    "unet_resnet_34exp_2_resize_144_pad_192_start\n",
    "0.83538 / 0.87858 / 0.85525\n",
    "    fold 0: 0.84358 / 0.88594 / 0.86279\n",
    "    fold 1: 0.82711 / 0.87116 / 0.84765\n",
    "\n",
    "unet_resnet_34_exp_2_resize_144_pad_192_mask_thr\n",
    "0.83222 / 0.87609 / 0.85278\n",
    "    fold 0: 0.84259 / 0.88166 / 0.85915\n",
    "    fold 1: 0.82177 / 0.87047 / 0.84637\n",
    "        \n",
    "unet_resnet_34_do_exp_2_resize_144_pad_192_delete_do -- Deleting DO -- good candidate for the ensemble\n",
    "0.82999 / 0.87756 / 0.85355\n",
    "    fold 0: 0.82951 / 0.87334 / 0.84972\n",
    "    fold 1: 0.83047 / 0.8818 / 0.85741\n",
    "\n",
    "        \n",
    "unet_resnet_34_do_exp_2_resize_144_pad_192_do_04_last\n",
    "0.8381 / 0.88303 / 0.85918\n",
    "    fold 0: 0.84728 / 0.89413 / 0.86973\n",
    "    fold 1: 0.82886 / 0.87184 / 0.84856\n",
    "\n",
    "unet_resnet_34_do_exp_2_resize_144_pad_192_do_04_last_again        \n",
    "0.83178 / 0.87809 / 0.85378\n",
    "    0.83395 / 0.87813 / 0.85414\n",
    "    0.8296 / 0.87804 / 0.85341\n",
    "\n",
    "unet_resnet_34_do_exp_2_resize_144_pad_192_do_03_last_02_2_prev\n",
    "0.83216 / 0.88123 / 0.85614\n",
    "    0.83531 / 0.88476 / 0.85978\n",
    "    0.82898 / 0.87768 / 0.85247\n",
    "\n",
    "unet_resnet_34_do_exp_2_resize_144_pad_192_do_02_2_prev\n",
    "0.82999 / 0.87626 / 0.85208\n",
    "    0.84963 / 0.88953 / 0.86673\n",
    "    0.8102 / 0.86289 / 0.83732\n",
    "    \n",
    "unet_resnet_34_do_exp_2_resize_144_pad_192_do_02_2_prev_02_last\n",
    "0.82999 / 0.87628 / 0.85176\n",
    "    0.84012 / 0.88533 / 0.86138\n",
    "    0.81978 / 0.86716 / 0.84208\n",
    "    \n",
    "unet_resnet_34_do_exp_2_resize_144_pad_192_do_04_last_no_bn\n",
    "0.81964 / 0.8681 / 0.84299\n",
    "    0.81889 / 0.86998 / 0.84438\n",
    "    0.8204 / 0.8662 / 0.84159\n",
    "\n",
    "unet_resnet_152_exp_0_resize_144_pad_192_do_04_last\n",
    "0.85531 / 0.89504 / 0.87287\n",
    "\n",
    "unet_resnet_152_exp_0_resize_144_pad_192_do_04_last_finetune\n",
    "0.85222 / 0.89078 / 0.86944\n",
    "\n",
    "unet_resnet_152_exp_0_resize_144_pad_192_do_04_last_lb_metric\n",
    "0.84667 / 0.88902 / 0.86639\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet_resnet_34_exp_2_resize_192\n",
    "0.83389 / 0.87669 / 0.8532\n",
    "    fold 0: 0.84123 / 0.8801 / 0.85735\n",
    "    fold 1: 0.82649 / 0.87325 / 0.84902\n",
    "unet_resnet_34_exp_2_resize_192_again\n",
    "0.83209 / 0.87658 / 0.85316\n",
    "    fold 0: 0.84506 / 0.88389 / 0.86132\n",
    "    fold 1: 0.81903 / 0.86922 / 0.84493\n",
    "\n",
    "unet_resnet_34_exp_2_resize_144_pad_192 \n",
    "0.83451 / 0.88055 / 0.857\n",
    "    fold 0: 0.84716 / 0.88915 / 0.86693\n",
    "    fold 1: 0.82177 / 0.87189 / 0.847\n",
    "unet_resnet_34_exp_2_resize_144_pad_192_again\n",
    "0.83271 / 0.87971 / 0.85611\n",
    "    fold 0: 0.84222 / 0.88539 / 0.8622\n",
    "    fold 1: 0.82313 / 0.87398 / 0.84997\n",
    "    \n",
    "unet_resnet_34_valid_plus_resize_202_pad_256_bs_24\n",
    "0.8412 / 0.88176 / 0.85929\n",
    "    fold 0: 0.84901 / 0.88497 / 0.86356\n",
    "    fold 1: 0.83333 / 0.87852 / 0.85499\n",
    "unet_resnet_34_exp_2_resize_202_pad_256_bs_24_again\n",
    "0.83835 / 0.88224 / 0.85882\n",
    "    fold 0: 0.84691 / 0.88655 / 0.86338\n",
    "    fold 1: 0.82973 / 0.8779 / 0.85421\n",
    "\n",
    "unet_resnet_50_exp_2_exp_2_resize_144_pad_192\n",
    "0.82214 / 0.87442 / 0.85021\n",
    "\n",
    "unet_resnet_50_valid_plus_resize_202_pad_256_bs_24\n",
    "0.83848 / 0.88182 / 0.85931\n",
    "\n",
    "unet_resnet_152_valid_plus_resize_202_pad_256_bs_12_corr\n",
    "0.85031 / 0.88821 / 0.86668\n",
    "    0.85716 / 0.89305 / 0.87196\n",
    "    0.84341 / 0.88334 / 0.86136\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res = evaluate([MODEL_PATH], train.id.values, 0.5, classification='')\n",
    "print(\"{} / {} / {}\".format(np.round(np.mean(res['iout']),5),np.round(np.mean(res['dice']),5),np.round(np.mean(res['jacard']),5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['unet_resnet_34_valid_plus_resize_202_pad_256_bs_24',\n",
    "'unet_resnet_50_valid_plus_resize_202_pad_256_bs_24',\n",
    "         'unet_resnet_152_valid_plus_resize_202_pad_256_bs_12_corr','resnet50_fpn_96','unet_resnet_152_finetuning_cyclic_lr'\n",
    "         ]\n",
    "model_pathes = ['/home/branding_images/salt/'+x for x in models]\n",
    "res = evaluate(model_pathes, train.id.values, 0.5, classification='')\n",
    "print(\"{} / {} / {}\".format(np.round(np.mean(res['iout']),5),np.round(np.mean(res['dice']),5),np.round(np.mean(res['jacard']),5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base 0.85105 / 0.88973 / 0.86871\n",
    "\n",
    "resnet50_fpn_96\n",
    "0.85245 / 0.8922 / 0.87103\n",
    "\n",
    "30 pixels:\n",
    "0.85262 / 0.89038 / 0.8698\n",
    "\n",
    "10 pixels:\n",
    "0.85255 / 0.89154 / 0.87058"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['iout'] = res['iout']\n",
    "train.groupby('fold').iout.aggregate('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pathes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pred = ensemble(model_pathes,[0,1,2,3,4],test.id.values,0.5, classification='')\n",
    "#pred = ensemble([MODEL_PATH],[0,1,2,3,4],test.id.values,0.5, classification='')\n",
    "#pred = ensemble([MODEL_PATH],[0],test.id.values,0.5, classification='')\n",
    "pred = ensemble(model_pathes,[0],test.id.values,0.5, classification='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test['rle_mask'] = pred\n",
    "#test[['id','rle_mask']].to_csv('101_102_103_85105.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['rle_mask'] = pred\n",
    "test[['id','rle_mask']].to_csv('unet_resnet_152_exp_0_202_256_scheduler_150_epochs_finetune_0_fold_87272.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.87037 / 0.90118 / 0.88158"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ensemble 0 fold\n",
    "0.8763 / 0.9064 / 0.88711"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['rle_mask'] = pred\n",
    "test[['id','rle_mask']].to_csv('ensemble_0_fold_88037.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.rle_mask.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.rle_mask.value_counts(normalize=True,dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot2x2Array(image, mask):\n",
    "    f, axarr = plt.subplots(1,2)\n",
    "    axarr[0].imshow(image)\n",
    "    axarr[1].imshow(mask)\n",
    "    axarr[0].grid()\n",
    "    axarr[1].grid()\n",
    "    axarr[0].set_title('Image')\n",
    "    axarr[1].set_title('Mask')\n",
    "    \n",
    "for i in range(5):\n",
    "    image, mask = dataset[np.random.randint(0, len(dataset))]\n",
    "    plot2x2Array(image, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_results(idx):\n",
    "    from rle import rle_decode\n",
    "    img = rle_decode(pred[idx],(101,101))\n",
    "    plt.figure(figsize=(4,4))\n",
    "    plt.imshow(img)\n",
    "    \n",
    "    plt.figure(figsize=(4,4))\n",
    "    plt.imshow(cv2.imread('train/images/{}.png'.format(ids_valid[idx])))\n",
    "    plt.figure(figsize=(4,4))\n",
    "    plt.imshow(cv2.imread('train/masks/{}.png'.format(ids_valid[idx])))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    show_results(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_probs=[]\n",
    "network = 'classification'\n",
    "folds = [int(f) for f in args.fold.split(',')]\n",
    "for fold in folds:\n",
    "    K.clear_session()\n",
    "    print('***************************** FOLD {} *****************************'.format(fold))\n",
    "\n",
    "    MODEL_PATH = os.path.join(args.models_dir,network+args.alias)\n",
    "\n",
    "    if fold == 0:\n",
    "        if os.path.isdir(MODEL_PATH):\n",
    "            raise ValueError('Such Model already exists')\n",
    "        os.system(\"mkdir {}\".format(MODEL_PATH))\n",
    "        os.system(\"cp params.py {}\".format(MODEL_PATH))\n",
    "\n",
    "    df_train = train[train.fold != fold].copy().reset_index(drop=True)\n",
    "    df_valid = train[train.fold == fold].copy().reset_index(drop=True)\n",
    "\n",
    "    ids_train, ids_valid = df_train.id.values, df_valid.id.values\n",
    "\n",
    "    print('Training on {} samples'.format(ids_train.shape[0]))\n",
    "    print('Validating on {} samples'.format(ids_valid.shape[0]))\n",
    "\n",
    "    # Initialize Model\n",
    "    weights_path = os.path.join(MODEL_PATH,'fold_{fold}.hdf5'.format(fold=fold))\n",
    "\n",
    "    print(weights_path.split('/')[-2:])\n",
    "\n",
    "    model, preprocess = get_model(network, input_shape=(args.input_size, args.input_size, 3), train_base=True)\n",
    "    print(model.summary())\n",
    "    model.compile(optimizer=RMSprop(lr=args.learning_rate), loss='binary_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "    if args.weights is None:\n",
    "        print('No weights passed, training from scratch')\n",
    "    else:\n",
    "        wp = args.weights.format(fold)\n",
    "        print('Loading weights from {}'.format(wp))\n",
    "        model.load_weights(wp, by_name=True)\n",
    "\n",
    "    augs = get_augmentations(args.augmentation_name, p=args.augmentation_prob, input_shape=(args.input_size, args.input_size, 3))\n",
    "\n",
    "\n",
    "    dg = ClassificationDataGenerator(input_shape=(args.input_size, args.input_size), batch_size = args.batch_size, augs = augs,\n",
    "                      preprocess = preprocess)\n",
    "\n",
    "    train_generator = dg.train_batch_generator(ids_train)\n",
    "    validation_generator = dg.evaluation_batch_generator(ids_valid)\n",
    "\n",
    "    callbacks = get_callback(args.callback, weights_path=weights_path,\n",
    "                            fold = fold)\n",
    "\n",
    "    # Fit the model with Generators:\n",
    "    model.fit_generator(generator=ThreadsafeIter(train_generator),\n",
    "                    steps_per_epoch=ids_train.shape[0] // args.batch_size * 2,\n",
    "                    epochs=args.epochs,\n",
    "                    callbacks=callbacks,\n",
    "                    validation_data=ThreadsafeIter(validation_generator),\n",
    "                    validation_steps=np.ceil(ids_valid.shape[0] / args.batch_size),\n",
    "                    workers=8)\n",
    "\n",
    "    model.load_weights(weights_path)\n",
    "\n",
    "    # SAVE OOF PREDICTIONS\n",
    "    dir_path = os.path.join(MODEL_PATH,'oof')\n",
    "    os.system(\"mkdir {}\".format(dir_path))\n",
    "    pred = classification_predict_test(model=model,\n",
    "                    preds_path=dir_path,\n",
    "                    oof=True,\n",
    "                    ids=ids_valid,\n",
    "                    batch_size=args.batch_size*4,\n",
    "                    thr=0.5,\n",
    "                    TTA='',\n",
    "                    preprocess=preprocess)\n",
    "    df_valid['prob'] = pred\n",
    "    validation_probs.append(df_valid)\n",
    "\n",
    "    # SAVE TEST PREDICTIONS\n",
    "    dir_path = os.path.join(MODEL_PATH,'fold_{}'.format(fold))\n",
    "    os.system(\"mkdir {}\".format(dir_path))\n",
    "    pred = classification_predict_test(model=model,\n",
    "                    preds_path=dir_path,\n",
    "                    oof=False,\n",
    "                    ids=test.id.values,\n",
    "                    batch_size=args.batch_size*4,\n",
    "                    thr=0.5,\n",
    "                    TTA='',\n",
    "                    preprocess=preprocess)\n",
    "    test['prob'] = pred\n",
    "    test.to_csv(os.path.join(dir_path,'probs_test_fold_{}.csv'.format(fold)),index=False)\n",
    "\n",
    "    K.clear_session()\n",
    "    # Run a single fold\n",
    "    # break\n",
    "\n",
    "dir_path = os.path.join(MODEL_PATH,'oof')\n",
    "pd.concat(validation_probs).to_csv(os.path.join(dir_path,'probs_oof.csv'),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
