{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "import gc\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "\n",
    "from utils import predict_test, evaluate, ensemble, ThreadsafeIter, classification_predict_test\n",
    "from datasets.generators import SegmentationDataGenerator, ClassificationDataGenerator\n",
    "\n",
    "from params import args\n",
    "from callbacks import get_callback\n",
    "from augmentations import get_augmentations\n",
    "\n",
    "from models.models import get_model\n",
    "\n",
    "from losses import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = '/home/p/babakhin/Branding/salt/data/'\n",
    "train = pd.read_csv(os.path.join(DATA_ROOT,'train_proc_v2.csv'))\n",
    "test = pd.read_csv(os.path.join(DATA_ROOT,'sample_submission.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************************** FOLD 0 *****************************\n",
      "Training on 3127 samples\n",
      "Validating on 810 samples\n",
      "['unet_resnet_34_exp_2_128_optical_distortion', 'fold_0.hdf5']\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "data (InputLayer)               (None, 128, 128, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bn_data (BatchNormalization)    (None, 128, 128, 3)  9           data[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPadding2D (None, 134, 134, 3)  0           bn_data[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv0 (Conv2D)                  (None, 64, 64, 64)   9408        zero_padding2d_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bn0 (BatchNormalization)        (None, 64, 64, 64)   256         conv0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "relu0 (Activation)              (None, 64, 64, 64)   0           bn0[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPadding2D (None, 66, 66, 64)   0           relu0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "pooling0 (MaxPooling2D)         (None, 32, 32, 64)   0           zero_padding2d_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_bn1 (BatchNormaliz (None, 32, 32, 64)   256         pooling0[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_relu1 (Activation) (None, 32, 32, 64)   0           stage1_unit1_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_3 (ZeroPadding2D (None, 34, 34, 64)   0           stage1_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_conv1 (Conv2D)     (None, 32, 32, 64)   36864       zero_padding2d_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_bn2 (BatchNormaliz (None, 32, 32, 64)   256         stage1_unit1_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_relu2 (Activation) (None, 32, 32, 64)   0           stage1_unit1_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_4 (ZeroPadding2D (None, 34, 34, 64)   0           stage1_unit1_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_conv2 (Conv2D)     (None, 32, 32, 64)   36864       zero_padding2d_4[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_sc (Conv2D)        (None, 32, 32, 64)   4096        stage1_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 32, 32, 64)   0           stage1_unit1_conv2[0][0]         \n",
      "                                                                 stage1_unit1_sc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_bn1 (BatchNormaliz (None, 32, 32, 64)   256         add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_relu1 (Activation) (None, 32, 32, 64)   0           stage1_unit2_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_5 (ZeroPadding2D (None, 34, 34, 64)   0           stage1_unit2_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_conv1 (Conv2D)     (None, 32, 32, 64)   36864       zero_padding2d_5[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_bn2 (BatchNormaliz (None, 32, 32, 64)   256         stage1_unit2_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_relu2 (Activation) (None, 32, 32, 64)   0           stage1_unit2_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_6 (ZeroPadding2D (None, 34, 34, 64)   0           stage1_unit2_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_conv2 (Conv2D)     (None, 32, 32, 64)   36864       zero_padding2d_6[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 32, 32, 64)   0           stage1_unit2_conv2[0][0]         \n",
      "                                                                 add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_bn1 (BatchNormaliz (None, 32, 32, 64)   256         add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_relu1 (Activation) (None, 32, 32, 64)   0           stage1_unit3_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_7 (ZeroPadding2D (None, 34, 34, 64)   0           stage1_unit3_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_conv1 (Conv2D)     (None, 32, 32, 64)   36864       zero_padding2d_7[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_bn2 (BatchNormaliz (None, 32, 32, 64)   256         stage1_unit3_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_relu2 (Activation) (None, 32, 32, 64)   0           stage1_unit3_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_8 (ZeroPadding2D (None, 34, 34, 64)   0           stage1_unit3_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_conv2 (Conv2D)     (None, 32, 32, 64)   36864       zero_padding2d_8[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 32, 32, 64)   0           stage1_unit3_conv2[0][0]         \n",
      "                                                                 add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_bn1 (BatchNormaliz (None, 32, 32, 64)   256         add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_relu1 (Activation) (None, 32, 32, 64)   0           stage2_unit1_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_9 (ZeroPadding2D (None, 34, 34, 64)   0           stage2_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_conv1 (Conv2D)     (None, 16, 16, 128)  73728       zero_padding2d_9[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_bn2 (BatchNormaliz (None, 16, 16, 128)  512         stage2_unit1_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_relu2 (Activation) (None, 16, 16, 128)  0           stage2_unit1_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_10 (ZeroPadding2 (None, 18, 18, 128)  0           stage2_unit1_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_conv2 (Conv2D)     (None, 16, 16, 128)  147456      zero_padding2d_10[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_sc (Conv2D)        (None, 16, 16, 128)  8192        stage2_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 16, 16, 128)  0           stage2_unit1_conv2[0][0]         \n",
      "                                                                 stage2_unit1_sc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_bn1 (BatchNormaliz (None, 16, 16, 128)  512         add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_relu1 (Activation) (None, 16, 16, 128)  0           stage2_unit2_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_11 (ZeroPadding2 (None, 18, 18, 128)  0           stage2_unit2_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_conv1 (Conv2D)     (None, 16, 16, 128)  147456      zero_padding2d_11[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_bn2 (BatchNormaliz (None, 16, 16, 128)  512         stage2_unit2_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_relu2 (Activation) (None, 16, 16, 128)  0           stage2_unit2_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_12 (ZeroPadding2 (None, 18, 18, 128)  0           stage2_unit2_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_conv2 (Conv2D)     (None, 16, 16, 128)  147456      zero_padding2d_12[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 16, 16, 128)  0           stage2_unit2_conv2[0][0]         \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_bn1 (BatchNormaliz (None, 16, 16, 128)  512         add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_relu1 (Activation) (None, 16, 16, 128)  0           stage2_unit3_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_13 (ZeroPadding2 (None, 18, 18, 128)  0           stage2_unit3_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_conv1 (Conv2D)     (None, 16, 16, 128)  147456      zero_padding2d_13[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_bn2 (BatchNormaliz (None, 16, 16, 128)  512         stage2_unit3_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_relu2 (Activation) (None, 16, 16, 128)  0           stage2_unit3_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_14 (ZeroPadding2 (None, 18, 18, 128)  0           stage2_unit3_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_conv2 (Conv2D)     (None, 16, 16, 128)  147456      zero_padding2d_14[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 16, 16, 128)  0           stage2_unit3_conv2[0][0]         \n",
      "                                                                 add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_bn1 (BatchNormaliz (None, 16, 16, 128)  512         add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_relu1 (Activation) (None, 16, 16, 128)  0           stage2_unit4_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_15 (ZeroPadding2 (None, 18, 18, 128)  0           stage2_unit4_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_conv1 (Conv2D)     (None, 16, 16, 128)  147456      zero_padding2d_15[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_bn2 (BatchNormaliz (None, 16, 16, 128)  512         stage2_unit4_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_relu2 (Activation) (None, 16, 16, 128)  0           stage2_unit4_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_16 (ZeroPadding2 (None, 18, 18, 128)  0           stage2_unit4_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_conv2 (Conv2D)     (None, 16, 16, 128)  147456      zero_padding2d_16[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 16, 16, 128)  0           stage2_unit4_conv2[0][0]         \n",
      "                                                                 add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_bn1 (BatchNormaliz (None, 16, 16, 128)  512         add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_relu1 (Activation) (None, 16, 16, 128)  0           stage3_unit1_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_17 (ZeroPadding2 (None, 18, 18, 128)  0           stage3_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_conv1 (Conv2D)     (None, 8, 8, 256)    294912      zero_padding2d_17[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_bn2 (BatchNormaliz (None, 8, 8, 256)    1024        stage3_unit1_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_relu2 (Activation) (None, 8, 8, 256)    0           stage3_unit1_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_18 (ZeroPadding2 (None, 10, 10, 256)  0           stage3_unit1_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_conv2 (Conv2D)     (None, 8, 8, 256)    589824      zero_padding2d_18[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_sc (Conv2D)        (None, 8, 8, 256)    32768       stage3_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 8, 8, 256)    0           stage3_unit1_conv2[0][0]         \n",
      "                                                                 stage3_unit1_sc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_bn1 (BatchNormaliz (None, 8, 8, 256)    1024        add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_relu1 (Activation) (None, 8, 8, 256)    0           stage3_unit2_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_19 (ZeroPadding2 (None, 10, 10, 256)  0           stage3_unit2_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_conv1 (Conv2D)     (None, 8, 8, 256)    589824      zero_padding2d_19[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_bn2 (BatchNormaliz (None, 8, 8, 256)    1024        stage3_unit2_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_relu2 (Activation) (None, 8, 8, 256)    0           stage3_unit2_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_20 (ZeroPadding2 (None, 10, 10, 256)  0           stage3_unit2_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_conv2 (Conv2D)     (None, 8, 8, 256)    589824      zero_padding2d_20[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 8, 8, 256)    0           stage3_unit2_conv2[0][0]         \n",
      "                                                                 add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_bn1 (BatchNormaliz (None, 8, 8, 256)    1024        add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_relu1 (Activation) (None, 8, 8, 256)    0           stage3_unit3_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_21 (ZeroPadding2 (None, 10, 10, 256)  0           stage3_unit3_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_conv1 (Conv2D)     (None, 8, 8, 256)    589824      zero_padding2d_21[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_bn2 (BatchNormaliz (None, 8, 8, 256)    1024        stage3_unit3_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_relu2 (Activation) (None, 8, 8, 256)    0           stage3_unit3_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_22 (ZeroPadding2 (None, 10, 10, 256)  0           stage3_unit3_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_conv2 (Conv2D)     (None, 8, 8, 256)    589824      zero_padding2d_22[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 8, 8, 256)    0           stage3_unit3_conv2[0][0]         \n",
      "                                                                 add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_bn1 (BatchNormaliz (None, 8, 8, 256)    1024        add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_relu1 (Activation) (None, 8, 8, 256)    0           stage3_unit4_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_23 (ZeroPadding2 (None, 10, 10, 256)  0           stage3_unit4_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_conv1 (Conv2D)     (None, 8, 8, 256)    589824      zero_padding2d_23[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_bn2 (BatchNormaliz (None, 8, 8, 256)    1024        stage3_unit4_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_relu2 (Activation) (None, 8, 8, 256)    0           stage3_unit4_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_24 (ZeroPadding2 (None, 10, 10, 256)  0           stage3_unit4_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_conv2 (Conv2D)     (None, 8, 8, 256)    589824      zero_padding2d_24[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 8, 8, 256)    0           stage3_unit4_conv2[0][0]         \n",
      "                                                                 add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_bn1 (BatchNormaliz (None, 8, 8, 256)    1024        add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_relu1 (Activation) (None, 8, 8, 256)    0           stage3_unit5_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_25 (ZeroPadding2 (None, 10, 10, 256)  0           stage3_unit5_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_conv1 (Conv2D)     (None, 8, 8, 256)    589824      zero_padding2d_25[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_bn2 (BatchNormaliz (None, 8, 8, 256)    1024        stage3_unit5_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_relu2 (Activation) (None, 8, 8, 256)    0           stage3_unit5_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_26 (ZeroPadding2 (None, 10, 10, 256)  0           stage3_unit5_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_conv2 (Conv2D)     (None, 8, 8, 256)    589824      zero_padding2d_26[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 8, 8, 256)    0           stage3_unit5_conv2[0][0]         \n",
      "                                                                 add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_bn1 (BatchNormaliz (None, 8, 8, 256)    1024        add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_relu1 (Activation) (None, 8, 8, 256)    0           stage3_unit6_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_27 (ZeroPadding2 (None, 10, 10, 256)  0           stage3_unit6_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_conv1 (Conv2D)     (None, 8, 8, 256)    589824      zero_padding2d_27[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_bn2 (BatchNormaliz (None, 8, 8, 256)    1024        stage3_unit6_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_relu2 (Activation) (None, 8, 8, 256)    0           stage3_unit6_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_28 (ZeroPadding2 (None, 10, 10, 256)  0           stage3_unit6_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_conv2 (Conv2D)     (None, 8, 8, 256)    589824      zero_padding2d_28[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 8, 8, 256)    0           stage3_unit6_conv2[0][0]         \n",
      "                                                                 add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_bn1 (BatchNormaliz (None, 8, 8, 256)    1024        add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_relu1 (Activation) (None, 8, 8, 256)    0           stage4_unit1_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_29 (ZeroPadding2 (None, 10, 10, 256)  0           stage4_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_conv1 (Conv2D)     (None, 4, 4, 512)    1179648     zero_padding2d_29[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_bn2 (BatchNormaliz (None, 4, 4, 512)    2048        stage4_unit1_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_relu2 (Activation) (None, 4, 4, 512)    0           stage4_unit1_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_30 (ZeroPadding2 (None, 6, 6, 512)    0           stage4_unit1_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_conv2 (Conv2D)     (None, 4, 4, 512)    2359296     zero_padding2d_30[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_sc (Conv2D)        (None, 4, 4, 512)    131072      stage4_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 4, 4, 512)    0           stage4_unit1_conv2[0][0]         \n",
      "                                                                 stage4_unit1_sc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_bn1 (BatchNormaliz (None, 4, 4, 512)    2048        add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_relu1 (Activation) (None, 4, 4, 512)    0           stage4_unit2_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_31 (ZeroPadding2 (None, 6, 6, 512)    0           stage4_unit2_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_conv1 (Conv2D)     (None, 4, 4, 512)    2359296     zero_padding2d_31[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_bn2 (BatchNormaliz (None, 4, 4, 512)    2048        stage4_unit2_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_relu2 (Activation) (None, 4, 4, 512)    0           stage4_unit2_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_32 (ZeroPadding2 (None, 6, 6, 512)    0           stage4_unit2_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_conv2 (Conv2D)     (None, 4, 4, 512)    2359296     zero_padding2d_32[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 4, 4, 512)    0           stage4_unit2_conv2[0][0]         \n",
      "                                                                 add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_bn1 (BatchNormaliz (None, 4, 4, 512)    2048        add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_relu1 (Activation) (None, 4, 4, 512)    0           stage4_unit3_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_33 (ZeroPadding2 (None, 6, 6, 512)    0           stage4_unit3_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_conv1 (Conv2D)     (None, 4, 4, 512)    2359296     zero_padding2d_33[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_bn2 (BatchNormaliz (None, 4, 4, 512)    2048        stage4_unit3_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_relu2 (Activation) (None, 4, 4, 512)    0           stage4_unit3_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_34 (ZeroPadding2 (None, 6, 6, 512)    0           stage4_unit3_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_conv2 (Conv2D)     (None, 4, 4, 512)    2359296     zero_padding2d_34[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 4, 4, 512)    0           stage4_unit3_conv2[0][0]         \n",
      "                                                                 add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "bn1 (BatchNormalization)        (None, 4, 4, 512)    2048        add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu1 (Activation)              (None, 4, 4, 512)    0           bn1[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 8, 8, 512)    0           relu1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 8, 8, 768)    0           up_sampling2d_1[0][0]            \n",
      "                                                                 stage4_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv6_1_conv (Conv2D)           (None, 8, 8, 256)    1769728     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv6_1_bn (BatchNormalization) (None, 8, 8, 256)    1024        conv6_1_conv[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv6_1_activation (Activation) (None, 8, 8, 256)    0           conv6_1_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv6_2_conv (Conv2D)           (None, 8, 8, 256)    590080      conv6_1_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv6_2_bn (BatchNormalization) (None, 8, 8, 256)    1024        conv6_2_conv[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv6_2_activation (Activation) (None, 8, 8, 256)    0           conv6_2_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 16, 16, 256)  0           conv6_2_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 16, 16, 384)  0           up_sampling2d_2[0][0]            \n",
      "                                                                 stage3_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv7_1_conv (Conv2D)           (None, 16, 16, 192)  663744      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv7_1_bn (BatchNormalization) (None, 16, 16, 192)  768         conv7_1_conv[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv7_1_activation (Activation) (None, 16, 16, 192)  0           conv7_1_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv7_2_conv (Conv2D)           (None, 16, 16, 192)  331968      conv7_1_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv7_2_bn (BatchNormalization) (None, 16, 16, 192)  768         conv7_2_conv[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv7_2_activation (Activation) (None, 16, 16, 192)  0           conv7_2_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 32, 32, 192)  0           conv7_2_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 32, 32, 256)  0           up_sampling2d_3[0][0]            \n",
      "                                                                 stage2_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv8_1_conv (Conv2D)           (None, 32, 32, 128)  295040      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv8_1_bn (BatchNormalization) (None, 32, 32, 128)  512         conv8_1_conv[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv8_1_activation (Activation) (None, 32, 32, 128)  0           conv8_1_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv8_2_conv (Conv2D)           (None, 32, 32, 128)  147584      conv8_1_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv8_2_bn (BatchNormalization) (None, 32, 32, 128)  512         conv8_2_conv[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv8_2_activation (Activation) (None, 32, 32, 128)  0           conv8_2_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 64, 64, 128)  0           conv8_2_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 64, 64, 192)  0           up_sampling2d_4[0][0]            \n",
      "                                                                 relu0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv9_1_conv (Conv2D)           (None, 64, 64, 64)   110656      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv9_1_bn (BatchNormalization) (None, 64, 64, 64)   256         conv9_1_conv[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv9_1_activation (Activation) (None, 64, 64, 64)   0           conv9_1_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv9_2_conv (Conv2D)           (None, 64, 64, 64)   36928       conv9_1_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv9_2_bn (BatchNormalization) (None, 64, 64, 64)   256         conv9_2_conv[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv9_2_activation (Activation) (None, 64, 64, 64)   0           conv9_2_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2D)  (None, 128, 128, 64) 0           conv9_2_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 128, 128, 67) 0           up_sampling2d_5[0][0]            \n",
      "                                                                 data[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "conv10_1_conv (Conv2D)          (None, 128, 128, 32) 19328       concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv10_1_bn (BatchNormalization (None, 128, 128, 32) 128         conv10_1_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv10_1_activation (Activation (None, 128, 128, 32) 0           conv10_1_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv10_2_conv (Conv2D)          (None, 128, 128, 32) 9248        conv10_1_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv10_2_bn (BatchNormalization (None, 128, 128, 32) 128         conv10_2_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv10_2_activation (Activation (None, 128, 128, 32) 0           conv10_2_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout2d_1 (SpatialDro (None, 128, 128, 32) 0           conv10_2_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "prediction (Conv2D)             (None, 128, 128, 1)  33          spatial_dropout2d_1[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 25,282,186\n",
      "Trainable params: 25,264,132\n",
      "Non-trainable params: 18,054\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "No weights passed, training from scratch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "194/194 [==============================] - 47s 241ms/step - loss: 0.6252 - dice_coef: 0.4643 - jacard_coef: 0.3066 - val_loss: 0.4897 - val_dice_coef: 0.6304 - val_jacard_coef: 0.4620\n",
      "Epoch 2/300\n",
      "194/194 [==============================] - 40s 205ms/step - loss: 0.5038 - dice_coef: 0.5536 - jacard_coef: 0.3867 - val_loss: 0.3232 - val_dice_coef: 0.7507 - val_jacard_coef: 0.6041\n",
      "Epoch 3/300\n",
      "194/194 [==============================] - 40s 206ms/step - loss: 0.4640 - dice_coef: 0.5906 - jacard_coef: 0.4227 - val_loss: 0.3003 - val_dice_coef: 0.7766 - val_jacard_coef: 0.6381\n",
      "Epoch 4/300\n",
      "194/194 [==============================] - 40s 206ms/step - loss: 0.4392 - dice_coef: 0.6136 - jacard_coef: 0.4472 - val_loss: 0.2921 - val_dice_coef: 0.8021 - val_jacard_coef: 0.6715\n",
      "Epoch 5/300\n",
      "194/194 [==============================] - 40s 206ms/step - loss: 0.4280 - dice_coef: 0.6289 - jacard_coef: 0.4640 - val_loss: 0.2399 - val_dice_coef: 0.8222 - val_jacard_coef: 0.7012\n",
      "Epoch 6/300\n",
      "194/194 [==============================] - 40s 206ms/step - loss: 0.4143 - dice_coef: 0.6407 - jacard_coef: 0.4756 - val_loss: 0.2383 - val_dice_coef: 0.8484 - val_jacard_coef: 0.7397\n",
      "Epoch 7/300\n",
      "194/194 [==============================] - 40s 205ms/step - loss: 0.4034 - dice_coef: 0.6553 - jacard_coef: 0.4934 - val_loss: 0.2254 - val_dice_coef: 0.8457 - val_jacard_coef: 0.7355\n",
      "Epoch 8/300\n",
      "194/194 [==============================] - 40s 206ms/step - loss: 0.4001 - dice_coef: 0.6564 - jacard_coef: 0.4943 - val_loss: 0.2299 - val_dice_coef: 0.8597 - val_jacard_coef: 0.7565\n",
      "Epoch 9/300\n",
      "194/194 [==============================] - 40s 206ms/step - loss: 0.3978 - dice_coef: 0.6600 - jacard_coef: 0.4987 - val_loss: 0.2240 - val_dice_coef: 0.8542 - val_jacard_coef: 0.7480\n",
      "Epoch 10/300\n",
      "194/194 [==============================] - 40s 206ms/step - loss: 0.4006 - dice_coef: 0.6598 - jacard_coef: 0.4960 - val_loss: 0.2749 - val_dice_coef: 0.8203 - val_jacard_coef: 0.6988\n",
      "Epoch 11/300\n",
      "194/194 [==============================] - 40s 206ms/step - loss: 0.3935 - dice_coef: 0.6652 - jacard_coef: 0.5041 - val_loss: 0.2942 - val_dice_coef: 0.8285 - val_jacard_coef: 0.7140\n",
      "Epoch 12/300\n",
      "194/194 [==============================] - 40s 206ms/step - loss: 0.3873 - dice_coef: 0.6778 - jacard_coef: 0.5179 - val_loss: 0.2419 - val_dice_coef: 0.8475 - val_jacard_coef: 0.7393\n",
      "Epoch 13/300\n",
      "194/194 [==============================] - 40s 206ms/step - loss: 0.3901 - dice_coef: 0.6700 - jacard_coef: 0.5099 - val_loss: 0.1943 - val_dice_coef: 0.8740 - val_jacard_coef: 0.7800\n",
      "Epoch 14/300\n",
      "194/194 [==============================] - 40s 206ms/step - loss: 0.3812 - dice_coef: 0.6793 - jacard_coef: 0.5206 - val_loss: 0.1975 - val_dice_coef: 0.8686 - val_jacard_coef: 0.7708\n",
      "Epoch 15/300\n",
      "194/194 [==============================] - 40s 206ms/step - loss: 0.3752 - dice_coef: 0.6843 - jacard_coef: 0.5269 - val_loss: 0.1973 - val_dice_coef: 0.8867 - val_jacard_coef: 0.7991\n",
      "Epoch 16/300\n",
      "194/194 [==============================] - 40s 205ms/step - loss: 0.3752 - dice_coef: 0.6836 - jacard_coef: 0.5254 - val_loss: 0.1972 - val_dice_coef: 0.8793 - val_jacard_coef: 0.7884\n",
      "Epoch 17/300\n",
      "194/194 [==============================] - 40s 206ms/step - loss: 0.3680 - dice_coef: 0.6958 - jacard_coef: 0.5392 - val_loss: 0.1854 - val_dice_coef: 0.8851 - val_jacard_coef: 0.7962\n",
      "Epoch 18/300\n",
      "194/194 [==============================] - 40s 206ms/step - loss: 0.3648 - dice_coef: 0.6975 - jacard_coef: 0.5420 - val_loss: 0.2201 - val_dice_coef: 0.8747 - val_jacard_coef: 0.7820\n",
      "Epoch 19/300\n",
      "194/194 [==============================] - 40s 206ms/step - loss: 0.3635 - dice_coef: 0.7019 - jacard_coef: 0.5474 - val_loss: 0.1963 - val_dice_coef: 0.8857 - val_jacard_coef: 0.7978\n",
      "Epoch 20/300\n",
      "194/194 [==============================] - 40s 206ms/step - loss: 0.3627 - dice_coef: 0.6999 - jacard_coef: 0.5459 - val_loss: 0.2340 - val_dice_coef: 0.8602 - val_jacard_coef: 0.7595\n",
      "Epoch 21/300\n",
      "194/194 [==============================] - 40s 205ms/step - loss: 0.3574 - dice_coef: 0.7050 - jacard_coef: 0.5495 - val_loss: 0.1922 - val_dice_coef: 0.8841 - val_jacard_coef: 0.7939\n",
      "Epoch 22/300\n",
      "194/194 [==============================] - 40s 206ms/step - loss: 0.3684 - dice_coef: 0.6960 - jacard_coef: 0.5405 - val_loss: 0.2179 - val_dice_coef: 0.8729 - val_jacard_coef: 0.7784\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "Epoch 23/300\n",
      "194/194 [==============================] - 40s 205ms/step - loss: 0.3444 - dice_coef: 0.7117 - jacard_coef: 0.5599 - val_loss: 0.1674 - val_dice_coef: 0.8984 - val_jacard_coef: 0.8183\n",
      "Epoch 24/300\n",
      "194/194 [==============================] - 40s 206ms/step - loss: 0.3429 - dice_coef: 0.7152 - jacard_coef: 0.5635 - val_loss: 0.1642 - val_dice_coef: 0.9019 - val_jacard_coef: 0.8234\n",
      "Epoch 25/300\n",
      "194/194 [==============================] - 40s 206ms/step - loss: 0.3374 - dice_coef: 0.7267 - jacard_coef: 0.5764 - val_loss: 0.1584 - val_dice_coef: 0.9034 - val_jacard_coef: 0.8260\n",
      "Epoch 26/300\n",
      "194/194 [==============================] - 40s 205ms/step - loss: 0.3380 - dice_coef: 0.7195 - jacard_coef: 0.5702 - val_loss: 0.1649 - val_dice_coef: 0.8978 - val_jacard_coef: 0.8165\n",
      "Epoch 27/300\n",
      "194/194 [==============================] - 40s 206ms/step - loss: 0.3488 - dice_coef: 0.7078 - jacard_coef: 0.5550 - val_loss: 0.1582 - val_dice_coef: 0.9061 - val_jacard_coef: 0.8305\n",
      "Epoch 28/300\n",
      "194/194 [==============================] - 40s 206ms/step - loss: 0.3266 - dice_coef: 0.7301 - jacard_coef: 0.5822 - val_loss: 0.1606 - val_dice_coef: 0.9038 - val_jacard_coef: 0.8268\n",
      "Epoch 29/300\n",
      "194/194 [==============================] - 40s 205ms/step - loss: 0.3347 - dice_coef: 0.7189 - jacard_coef: 0.5687 - val_loss: 0.1657 - val_dice_coef: 0.9026 - val_jacard_coef: 0.8249\n",
      "Epoch 30/300\n",
      "194/194 [==============================] - 40s 205ms/step - loss: 0.3310 - dice_coef: 0.7300 - jacard_coef: 0.5821 - val_loss: 0.1567 - val_dice_coef: 0.9102 - val_jacard_coef: 0.8373\n",
      "Epoch 31/300\n",
      "194/194 [==============================] - 40s 206ms/step - loss: 0.3309 - dice_coef: 0.7257 - jacard_coef: 0.5774 - val_loss: 0.1629 - val_dice_coef: 0.9039 - val_jacard_coef: 0.8269\n",
      "Epoch 32/300\n",
      "194/194 [==============================] - 40s 206ms/step - loss: 0.3416 - dice_coef: 0.7181 - jacard_coef: 0.5667 - val_loss: 0.1711 - val_dice_coef: 0.8967 - val_jacard_coef: 0.8147\n",
      "Epoch 33/300\n",
      "194/194 [==============================] - 40s 206ms/step - loss: 0.3227 - dice_coef: 0.7322 - jacard_coef: 0.5845 - val_loss: 0.1639 - val_dice_coef: 0.8982 - val_jacard_coef: 0.8174\n",
      "Epoch 34/300\n",
      "194/194 [==============================] - 40s 206ms/step - loss: 0.3258 - dice_coef: 0.7330 - jacard_coef: 0.5854 - val_loss: 0.1542 - val_dice_coef: 0.9130 - val_jacard_coef: 0.8416\n",
      "Epoch 35/300\n",
      "194/194 [==============================] - 40s 206ms/step - loss: 0.3264 - dice_coef: 0.7351 - jacard_coef: 0.5870 - val_loss: 0.1552 - val_dice_coef: 0.9128 - val_jacard_coef: 0.8414\n",
      "Epoch 36/300\n",
      "194/194 [==============================] - 40s 206ms/step - loss: 0.3221 - dice_coef: 0.7362 - jacard_coef: 0.5904 - val_loss: 0.1612 - val_dice_coef: 0.9016 - val_jacard_coef: 0.8230\n",
      "Epoch 37/300\n",
      "194/194 [==============================] - 40s 205ms/step - loss: 0.3178 - dice_coef: 0.7404 - jacard_coef: 0.5937 - val_loss: 0.1722 - val_dice_coef: 0.9016 - val_jacard_coef: 0.8231\n",
      "Epoch 38/300\n",
      "194/194 [==============================] - 40s 206ms/step - loss: 0.3374 - dice_coef: 0.7225 - jacard_coef: 0.5731 - val_loss: 0.1603 - val_dice_coef: 0.9131 - val_jacard_coef: 0.8427\n",
      "Epoch 39/300\n",
      "194/194 [==============================] - 40s 206ms/step - loss: 0.3179 - dice_coef: 0.7419 - jacard_coef: 0.5959 - val_loss: 0.1844 - val_dice_coef: 0.8883 - val_jacard_coef: 0.8023\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "Epoch 40/300\n",
      "194/194 [==============================] - 40s 206ms/step - loss: 0.3128 - dice_coef: 0.7453 - jacard_coef: 0.6004 - val_loss: 0.1707 - val_dice_coef: 0.8993 - val_jacard_coef: 0.8202\n",
      "Epoch 41/300\n",
      "194/194 [==============================] - 40s 206ms/step - loss: 0.3160 - dice_coef: 0.7413 - jacard_coef: 0.5953 - val_loss: 0.1682 - val_dice_coef: 0.9029 - val_jacard_coef: 0.8254\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/300\n",
      "194/194 [==============================] - 40s 206ms/step - loss: 0.3170 - dice_coef: 0.7364 - jacard_coef: 0.5899 - val_loss: 0.1602 - val_dice_coef: 0.9065 - val_jacard_coef: 0.8313\n",
      "Epoch 43/300\n",
      "194/194 [==============================] - 40s 206ms/step - loss: 0.3257 - dice_coef: 0.7327 - jacard_coef: 0.5858 - val_loss: 0.1609 - val_dice_coef: 0.9082 - val_jacard_coef: 0.8343\n",
      "Epoch 44/300\n",
      "194/194 [==============================] - 40s 206ms/step - loss: 0.3190 - dice_coef: 0.7408 - jacard_coef: 0.5944 - val_loss: 0.1620 - val_dice_coef: 0.9061 - val_jacard_coef: 0.8306\n",
      "\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a66c539c6748453683519a6ea6f756ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***************************** FOLD 1 *****************************\n",
      "Training on 3134 samples\n",
      "Validating on 804 samples\n",
      "['unet_resnet_34_exp_2_128_optical_distortion', 'fold_1.hdf5']\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "data (InputLayer)               (None, 128, 128, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bn_data (BatchNormalization)    (None, 128, 128, 3)  9           data[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPadding2D (None, 134, 134, 3)  0           bn_data[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv0 (Conv2D)                  (None, 64, 64, 64)   9408        zero_padding2d_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bn0 (BatchNormalization)        (None, 64, 64, 64)   256         conv0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "relu0 (Activation)              (None, 64, 64, 64)   0           bn0[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPadding2D (None, 66, 66, 64)   0           relu0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "pooling0 (MaxPooling2D)         (None, 32, 32, 64)   0           zero_padding2d_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_bn1 (BatchNormaliz (None, 32, 32, 64)   256         pooling0[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_relu1 (Activation) (None, 32, 32, 64)   0           stage1_unit1_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_3 (ZeroPadding2D (None, 34, 34, 64)   0           stage1_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_conv1 (Conv2D)     (None, 32, 32, 64)   36864       zero_padding2d_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_bn2 (BatchNormaliz (None, 32, 32, 64)   256         stage1_unit1_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_relu2 (Activation) (None, 32, 32, 64)   0           stage1_unit1_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_4 (ZeroPadding2D (None, 34, 34, 64)   0           stage1_unit1_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_conv2 (Conv2D)     (None, 32, 32, 64)   36864       zero_padding2d_4[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_sc (Conv2D)        (None, 32, 32, 64)   4096        stage1_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 32, 32, 64)   0           stage1_unit1_conv2[0][0]         \n",
      "                                                                 stage1_unit1_sc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_bn1 (BatchNormaliz (None, 32, 32, 64)   256         add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_relu1 (Activation) (None, 32, 32, 64)   0           stage1_unit2_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_5 (ZeroPadding2D (None, 34, 34, 64)   0           stage1_unit2_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_conv1 (Conv2D)     (None, 32, 32, 64)   36864       zero_padding2d_5[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_bn2 (BatchNormaliz (None, 32, 32, 64)   256         stage1_unit2_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_relu2 (Activation) (None, 32, 32, 64)   0           stage1_unit2_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_6 (ZeroPadding2D (None, 34, 34, 64)   0           stage1_unit2_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_conv2 (Conv2D)     (None, 32, 32, 64)   36864       zero_padding2d_6[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 32, 32, 64)   0           stage1_unit2_conv2[0][0]         \n",
      "                                                                 add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_bn1 (BatchNormaliz (None, 32, 32, 64)   256         add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_relu1 (Activation) (None, 32, 32, 64)   0           stage1_unit3_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_7 (ZeroPadding2D (None, 34, 34, 64)   0           stage1_unit3_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_conv1 (Conv2D)     (None, 32, 32, 64)   36864       zero_padding2d_7[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_bn2 (BatchNormaliz (None, 32, 32, 64)   256         stage1_unit3_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_relu2 (Activation) (None, 32, 32, 64)   0           stage1_unit3_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_8 (ZeroPadding2D (None, 34, 34, 64)   0           stage1_unit3_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_conv2 (Conv2D)     (None, 32, 32, 64)   36864       zero_padding2d_8[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 32, 32, 64)   0           stage1_unit3_conv2[0][0]         \n",
      "                                                                 add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_bn1 (BatchNormaliz (None, 32, 32, 64)   256         add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_relu1 (Activation) (None, 32, 32, 64)   0           stage2_unit1_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_9 (ZeroPadding2D (None, 34, 34, 64)   0           stage2_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_conv1 (Conv2D)     (None, 16, 16, 128)  73728       zero_padding2d_9[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_bn2 (BatchNormaliz (None, 16, 16, 128)  512         stage2_unit1_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_relu2 (Activation) (None, 16, 16, 128)  0           stage2_unit1_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_10 (ZeroPadding2 (None, 18, 18, 128)  0           stage2_unit1_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_conv2 (Conv2D)     (None, 16, 16, 128)  147456      zero_padding2d_10[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_sc (Conv2D)        (None, 16, 16, 128)  8192        stage2_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 16, 16, 128)  0           stage2_unit1_conv2[0][0]         \n",
      "                                                                 stage2_unit1_sc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_bn1 (BatchNormaliz (None, 16, 16, 128)  512         add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_relu1 (Activation) (None, 16, 16, 128)  0           stage2_unit2_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_11 (ZeroPadding2 (None, 18, 18, 128)  0           stage2_unit2_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_conv1 (Conv2D)     (None, 16, 16, 128)  147456      zero_padding2d_11[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_bn2 (BatchNormaliz (None, 16, 16, 128)  512         stage2_unit2_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_relu2 (Activation) (None, 16, 16, 128)  0           stage2_unit2_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_12 (ZeroPadding2 (None, 18, 18, 128)  0           stage2_unit2_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_conv2 (Conv2D)     (None, 16, 16, 128)  147456      zero_padding2d_12[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 16, 16, 128)  0           stage2_unit2_conv2[0][0]         \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_bn1 (BatchNormaliz (None, 16, 16, 128)  512         add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_relu1 (Activation) (None, 16, 16, 128)  0           stage2_unit3_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_13 (ZeroPadding2 (None, 18, 18, 128)  0           stage2_unit3_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_conv1 (Conv2D)     (None, 16, 16, 128)  147456      zero_padding2d_13[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_bn2 (BatchNormaliz (None, 16, 16, 128)  512         stage2_unit3_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_relu2 (Activation) (None, 16, 16, 128)  0           stage2_unit3_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_14 (ZeroPadding2 (None, 18, 18, 128)  0           stage2_unit3_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_conv2 (Conv2D)     (None, 16, 16, 128)  147456      zero_padding2d_14[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 16, 16, 128)  0           stage2_unit3_conv2[0][0]         \n",
      "                                                                 add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_bn1 (BatchNormaliz (None, 16, 16, 128)  512         add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_relu1 (Activation) (None, 16, 16, 128)  0           stage2_unit4_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_15 (ZeroPadding2 (None, 18, 18, 128)  0           stage2_unit4_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_conv1 (Conv2D)     (None, 16, 16, 128)  147456      zero_padding2d_15[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_bn2 (BatchNormaliz (None, 16, 16, 128)  512         stage2_unit4_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_relu2 (Activation) (None, 16, 16, 128)  0           stage2_unit4_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_16 (ZeroPadding2 (None, 18, 18, 128)  0           stage2_unit4_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_conv2 (Conv2D)     (None, 16, 16, 128)  147456      zero_padding2d_16[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 16, 16, 128)  0           stage2_unit4_conv2[0][0]         \n",
      "                                                                 add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_bn1 (BatchNormaliz (None, 16, 16, 128)  512         add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_relu1 (Activation) (None, 16, 16, 128)  0           stage3_unit1_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_17 (ZeroPadding2 (None, 18, 18, 128)  0           stage3_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_conv1 (Conv2D)     (None, 8, 8, 256)    294912      zero_padding2d_17[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_bn2 (BatchNormaliz (None, 8, 8, 256)    1024        stage3_unit1_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_relu2 (Activation) (None, 8, 8, 256)    0           stage3_unit1_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_18 (ZeroPadding2 (None, 10, 10, 256)  0           stage3_unit1_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_conv2 (Conv2D)     (None, 8, 8, 256)    589824      zero_padding2d_18[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_sc (Conv2D)        (None, 8, 8, 256)    32768       stage3_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 8, 8, 256)    0           stage3_unit1_conv2[0][0]         \n",
      "                                                                 stage3_unit1_sc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_bn1 (BatchNormaliz (None, 8, 8, 256)    1024        add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_relu1 (Activation) (None, 8, 8, 256)    0           stage3_unit2_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_19 (ZeroPadding2 (None, 10, 10, 256)  0           stage3_unit2_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_conv1 (Conv2D)     (None, 8, 8, 256)    589824      zero_padding2d_19[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_bn2 (BatchNormaliz (None, 8, 8, 256)    1024        stage3_unit2_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_relu2 (Activation) (None, 8, 8, 256)    0           stage3_unit2_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_20 (ZeroPadding2 (None, 10, 10, 256)  0           stage3_unit2_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_conv2 (Conv2D)     (None, 8, 8, 256)    589824      zero_padding2d_20[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 8, 8, 256)    0           stage3_unit2_conv2[0][0]         \n",
      "                                                                 add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_bn1 (BatchNormaliz (None, 8, 8, 256)    1024        add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_relu1 (Activation) (None, 8, 8, 256)    0           stage3_unit3_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_21 (ZeroPadding2 (None, 10, 10, 256)  0           stage3_unit3_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_conv1 (Conv2D)     (None, 8, 8, 256)    589824      zero_padding2d_21[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_bn2 (BatchNormaliz (None, 8, 8, 256)    1024        stage3_unit3_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_relu2 (Activation) (None, 8, 8, 256)    0           stage3_unit3_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_22 (ZeroPadding2 (None, 10, 10, 256)  0           stage3_unit3_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_conv2 (Conv2D)     (None, 8, 8, 256)    589824      zero_padding2d_22[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 8, 8, 256)    0           stage3_unit3_conv2[0][0]         \n",
      "                                                                 add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_bn1 (BatchNormaliz (None, 8, 8, 256)    1024        add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_relu1 (Activation) (None, 8, 8, 256)    0           stage3_unit4_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_23 (ZeroPadding2 (None, 10, 10, 256)  0           stage3_unit4_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_conv1 (Conv2D)     (None, 8, 8, 256)    589824      zero_padding2d_23[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_bn2 (BatchNormaliz (None, 8, 8, 256)    1024        stage3_unit4_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_relu2 (Activation) (None, 8, 8, 256)    0           stage3_unit4_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_24 (ZeroPadding2 (None, 10, 10, 256)  0           stage3_unit4_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_conv2 (Conv2D)     (None, 8, 8, 256)    589824      zero_padding2d_24[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 8, 8, 256)    0           stage3_unit4_conv2[0][0]         \n",
      "                                                                 add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_bn1 (BatchNormaliz (None, 8, 8, 256)    1024        add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_relu1 (Activation) (None, 8, 8, 256)    0           stage3_unit5_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_25 (ZeroPadding2 (None, 10, 10, 256)  0           stage3_unit5_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_conv1 (Conv2D)     (None, 8, 8, 256)    589824      zero_padding2d_25[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_bn2 (BatchNormaliz (None, 8, 8, 256)    1024        stage3_unit5_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_relu2 (Activation) (None, 8, 8, 256)    0           stage3_unit5_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_26 (ZeroPadding2 (None, 10, 10, 256)  0           stage3_unit5_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_conv2 (Conv2D)     (None, 8, 8, 256)    589824      zero_padding2d_26[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 8, 8, 256)    0           stage3_unit5_conv2[0][0]         \n",
      "                                                                 add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_bn1 (BatchNormaliz (None, 8, 8, 256)    1024        add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_relu1 (Activation) (None, 8, 8, 256)    0           stage3_unit6_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_27 (ZeroPadding2 (None, 10, 10, 256)  0           stage3_unit6_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_conv1 (Conv2D)     (None, 8, 8, 256)    589824      zero_padding2d_27[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_bn2 (BatchNormaliz (None, 8, 8, 256)    1024        stage3_unit6_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_relu2 (Activation) (None, 8, 8, 256)    0           stage3_unit6_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_28 (ZeroPadding2 (None, 10, 10, 256)  0           stage3_unit6_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_conv2 (Conv2D)     (None, 8, 8, 256)    589824      zero_padding2d_28[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 8, 8, 256)    0           stage3_unit6_conv2[0][0]         \n",
      "                                                                 add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_bn1 (BatchNormaliz (None, 8, 8, 256)    1024        add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_relu1 (Activation) (None, 8, 8, 256)    0           stage4_unit1_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_29 (ZeroPadding2 (None, 10, 10, 256)  0           stage4_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_conv1 (Conv2D)     (None, 4, 4, 512)    1179648     zero_padding2d_29[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_bn2 (BatchNormaliz (None, 4, 4, 512)    2048        stage4_unit1_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_relu2 (Activation) (None, 4, 4, 512)    0           stage4_unit1_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_30 (ZeroPadding2 (None, 6, 6, 512)    0           stage4_unit1_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_conv2 (Conv2D)     (None, 4, 4, 512)    2359296     zero_padding2d_30[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_sc (Conv2D)        (None, 4, 4, 512)    131072      stage4_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 4, 4, 512)    0           stage4_unit1_conv2[0][0]         \n",
      "                                                                 stage4_unit1_sc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_bn1 (BatchNormaliz (None, 4, 4, 512)    2048        add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_relu1 (Activation) (None, 4, 4, 512)    0           stage4_unit2_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_31 (ZeroPadding2 (None, 6, 6, 512)    0           stage4_unit2_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_conv1 (Conv2D)     (None, 4, 4, 512)    2359296     zero_padding2d_31[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_bn2 (BatchNormaliz (None, 4, 4, 512)    2048        stage4_unit2_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_relu2 (Activation) (None, 4, 4, 512)    0           stage4_unit2_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_32 (ZeroPadding2 (None, 6, 6, 512)    0           stage4_unit2_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_conv2 (Conv2D)     (None, 4, 4, 512)    2359296     zero_padding2d_32[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 4, 4, 512)    0           stage4_unit2_conv2[0][0]         \n",
      "                                                                 add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_bn1 (BatchNormaliz (None, 4, 4, 512)    2048        add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_relu1 (Activation) (None, 4, 4, 512)    0           stage4_unit3_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_33 (ZeroPadding2 (None, 6, 6, 512)    0           stage4_unit3_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_conv1 (Conv2D)     (None, 4, 4, 512)    2359296     zero_padding2d_33[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_bn2 (BatchNormaliz (None, 4, 4, 512)    2048        stage4_unit3_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_relu2 (Activation) (None, 4, 4, 512)    0           stage4_unit3_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_34 (ZeroPadding2 (None, 6, 6, 512)    0           stage4_unit3_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_conv2 (Conv2D)     (None, 4, 4, 512)    2359296     zero_padding2d_34[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 4, 4, 512)    0           stage4_unit3_conv2[0][0]         \n",
      "                                                                 add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "bn1 (BatchNormalization)        (None, 4, 4, 512)    2048        add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu1 (Activation)              (None, 4, 4, 512)    0           bn1[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 8, 8, 512)    0           relu1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 8, 8, 768)    0           up_sampling2d_1[0][0]            \n",
      "                                                                 stage4_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv6_1_conv (Conv2D)           (None, 8, 8, 256)    1769728     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv6_1_bn (BatchNormalization) (None, 8, 8, 256)    1024        conv6_1_conv[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv6_1_activation (Activation) (None, 8, 8, 256)    0           conv6_1_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv6_2_conv (Conv2D)           (None, 8, 8, 256)    590080      conv6_1_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv6_2_bn (BatchNormalization) (None, 8, 8, 256)    1024        conv6_2_conv[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv6_2_activation (Activation) (None, 8, 8, 256)    0           conv6_2_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 16, 16, 256)  0           conv6_2_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 16, 16, 384)  0           up_sampling2d_2[0][0]            \n",
      "                                                                 stage3_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv7_1_conv (Conv2D)           (None, 16, 16, 192)  663744      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv7_1_bn (BatchNormalization) (None, 16, 16, 192)  768         conv7_1_conv[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv7_1_activation (Activation) (None, 16, 16, 192)  0           conv7_1_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv7_2_conv (Conv2D)           (None, 16, 16, 192)  331968      conv7_1_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv7_2_bn (BatchNormalization) (None, 16, 16, 192)  768         conv7_2_conv[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv7_2_activation (Activation) (None, 16, 16, 192)  0           conv7_2_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 32, 32, 192)  0           conv7_2_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 32, 32, 256)  0           up_sampling2d_3[0][0]            \n",
      "                                                                 stage2_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv8_1_conv (Conv2D)           (None, 32, 32, 128)  295040      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv8_1_bn (BatchNormalization) (None, 32, 32, 128)  512         conv8_1_conv[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv8_1_activation (Activation) (None, 32, 32, 128)  0           conv8_1_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv8_2_conv (Conv2D)           (None, 32, 32, 128)  147584      conv8_1_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv8_2_bn (BatchNormalization) (None, 32, 32, 128)  512         conv8_2_conv[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv8_2_activation (Activation) (None, 32, 32, 128)  0           conv8_2_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 64, 64, 128)  0           conv8_2_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 64, 64, 192)  0           up_sampling2d_4[0][0]            \n",
      "                                                                 relu0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv9_1_conv (Conv2D)           (None, 64, 64, 64)   110656      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv9_1_bn (BatchNormalization) (None, 64, 64, 64)   256         conv9_1_conv[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv9_1_activation (Activation) (None, 64, 64, 64)   0           conv9_1_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv9_2_conv (Conv2D)           (None, 64, 64, 64)   36928       conv9_1_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv9_2_bn (BatchNormalization) (None, 64, 64, 64)   256         conv9_2_conv[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv9_2_activation (Activation) (None, 64, 64, 64)   0           conv9_2_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2D)  (None, 128, 128, 64) 0           conv9_2_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 128, 128, 67) 0           up_sampling2d_5[0][0]            \n",
      "                                                                 data[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "conv10_1_conv (Conv2D)          (None, 128, 128, 32) 19328       concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv10_1_bn (BatchNormalization (None, 128, 128, 32) 128         conv10_1_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv10_1_activation (Activation (None, 128, 128, 32) 0           conv10_1_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv10_2_conv (Conv2D)          (None, 128, 128, 32) 9248        conv10_1_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv10_2_bn (BatchNormalization (None, 128, 128, 32) 128         conv10_2_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv10_2_activation (Activation (None, 128, 128, 32) 0           conv10_2_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout2d_1 (SpatialDro (None, 128, 128, 32) 0           conv10_2_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "prediction (Conv2D)             (None, 128, 128, 1)  33          spatial_dropout2d_1[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 25,282,186\n",
      "Trainable params: 25,264,132\n",
      "Non-trainable params: 18,054\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "No weights passed, training from scratch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "194/194 [==============================] - 45s 233ms/step - loss: 0.5809 - dice_coef: 0.4666 - jacard_coef: 0.3092 - val_loss: 0.3956 - val_dice_coef: 0.6453 - val_jacard_coef: 0.4811\n",
      "Epoch 2/300\n",
      "194/194 [==============================] - 40s 205ms/step - loss: 0.4844 - dice_coef: 0.5771 - jacard_coef: 0.4098 - val_loss: 0.2910 - val_dice_coef: 0.7852 - val_jacard_coef: 0.6510\n",
      "Epoch 3/300\n",
      "194/194 [==============================] - 40s 205ms/step - loss: 0.4371 - dice_coef: 0.6236 - jacard_coef: 0.4579 - val_loss: 0.2823 - val_dice_coef: 0.7961 - val_jacard_coef: 0.6662\n",
      "Epoch 4/300\n",
      "194/194 [==============================] - 40s 205ms/step - loss: 0.4221 - dice_coef: 0.6430 - jacard_coef: 0.4785 - val_loss: 0.2560 - val_dice_coef: 0.8287 - val_jacard_coef: 0.7128\n",
      "Epoch 5/300\n",
      "194/194 [==============================] - 40s 205ms/step - loss: 0.4043 - dice_coef: 0.6591 - jacard_coef: 0.4967 - val_loss: 0.2603 - val_dice_coef: 0.8241 - val_jacard_coef: 0.7078\n",
      "Epoch 6/300\n",
      "194/194 [==============================] - 40s 205ms/step - loss: 0.4076 - dice_coef: 0.6557 - jacard_coef: 0.4928 - val_loss: 0.2274 - val_dice_coef: 0.8564 - val_jacard_coef: 0.7551\n",
      "Epoch 7/300\n",
      "194/194 [==============================] - 40s 205ms/step - loss: 0.4011 - dice_coef: 0.6614 - jacard_coef: 0.4985 - val_loss: 0.2351 - val_dice_coef: 0.8310 - val_jacard_coef: 0.7162\n",
      "Epoch 8/300\n",
      "194/194 [==============================] - 40s 204ms/step - loss: 0.3946 - dice_coef: 0.6730 - jacard_coef: 0.5129 - val_loss: 0.2114 - val_dice_coef: 0.8530 - val_jacard_coef: 0.7491\n",
      "Epoch 9/300\n",
      "194/194 [==============================] - 40s 205ms/step - loss: 0.3855 - dice_coef: 0.6799 - jacard_coef: 0.5201 - val_loss: 0.2209 - val_dice_coef: 0.8566 - val_jacard_coef: 0.7556\n",
      "Epoch 10/300\n",
      "194/194 [==============================] - 40s 205ms/step - loss: 0.3868 - dice_coef: 0.6779 - jacard_coef: 0.5187 - val_loss: 0.2579 - val_dice_coef: 0.8530 - val_jacard_coef: 0.7495\n",
      "Epoch 11/300\n",
      "194/194 [==============================] - 40s 205ms/step - loss: 0.3884 - dice_coef: 0.6771 - jacard_coef: 0.5190 - val_loss: 0.3340 - val_dice_coef: 0.8111 - val_jacard_coef: 0.6905\n",
      "Epoch 12/300\n",
      "194/194 [==============================] - 40s 205ms/step - loss: 0.3764 - dice_coef: 0.6916 - jacard_coef: 0.5345 - val_loss: 0.2537 - val_dice_coef: 0.8418 - val_jacard_coef: 0.7356\n",
      "Epoch 13/300\n",
      "194/194 [==============================] - 40s 205ms/step - loss: 0.3781 - dice_coef: 0.6860 - jacard_coef: 0.5280 - val_loss: 0.2141 - val_dice_coef: 0.8529 - val_jacard_coef: 0.7509\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "Epoch 14/300\n",
      "194/194 [==============================] - 40s 204ms/step - loss: 0.3549 - dice_coef: 0.7129 - jacard_coef: 0.5587 - val_loss: 0.1899 - val_dice_coef: 0.8702 - val_jacard_coef: 0.7759\n",
      "Epoch 15/300\n",
      "194/194 [==============================] - 40s 205ms/step - loss: 0.3498 - dice_coef: 0.7134 - jacard_coef: 0.5614 - val_loss: 0.1805 - val_dice_coef: 0.8808 - val_jacard_coef: 0.7938\n",
      "Epoch 16/300\n",
      "194/194 [==============================] - 40s 204ms/step - loss: 0.3520 - dice_coef: 0.7106 - jacard_coef: 0.5567 - val_loss: 0.1789 - val_dice_coef: 0.8805 - val_jacard_coef: 0.7930\n",
      "Epoch 17/300\n",
      "194/194 [==============================] - 40s 205ms/step - loss: 0.3438 - dice_coef: 0.7163 - jacard_coef: 0.5653 - val_loss: 0.1905 - val_dice_coef: 0.8763 - val_jacard_coef: 0.7866\n",
      "Epoch 18/300\n",
      "194/194 [==============================] - 40s 205ms/step - loss: 0.3410 - dice_coef: 0.7201 - jacard_coef: 0.5682 - val_loss: 0.1812 - val_dice_coef: 0.8812 - val_jacard_coef: 0.7935\n",
      "Epoch 19/300\n",
      "194/194 [==============================] - 40s 205ms/step - loss: 0.3465 - dice_coef: 0.7146 - jacard_coef: 0.5616 - val_loss: 0.1842 - val_dice_coef: 0.8774 - val_jacard_coef: 0.7878\n",
      "Epoch 20/300\n",
      "122/194 [=================>............] - ETA: 14s - loss: 0.3432 - dice_coef: 0.7164 - jacard_coef: 0.5639"
     ]
    }
   ],
   "source": [
    "for network in args.network.split(','):\n",
    "    folds = [int(f) for f in args.fold.split(',')]\n",
    "    for fold in folds:\n",
    "        K.clear_session()\n",
    "        print('***************************** FOLD {} *****************************'.format(fold))\n",
    "\n",
    "        MODEL_PATH = os.path.join(args.models_dir,network+args.alias)\n",
    "\n",
    "        if fold == 0:\n",
    "            if os.path.isdir(MODEL_PATH):\n",
    "                raise ValueError('Such Model already exists')\n",
    "            os.system(\"mkdir {}\".format(MODEL_PATH))\n",
    "            os.system(\"cp params.py {}\".format(MODEL_PATH))\n",
    "\n",
    "        df_train = train[train.fold != fold].copy().reset_index(drop=True)\n",
    "        df_valid = train[train.fold == fold].copy().reset_index(drop=True)\n",
    "\n",
    "        ids_train, ids_valid = df_train[df_train.unique_pixels>1].id.values, df_valid.id.values\n",
    "\n",
    "        # Fold 0\n",
    "        # Training on 3127 samples\n",
    "        # Validating on 810 samples\n",
    "        # ids_train, ids_valid = df_train[(df_train.unique_pixels>1)&(~df_train.id.isin(bad_masks))].id.values, df_valid.id.values\n",
    "\n",
    "\n",
    "        print('Training on {} samples'.format(ids_train.shape[0]))\n",
    "        print('Validating on {} samples'.format(ids_valid.shape[0]))\n",
    "\n",
    "        # Initialize Model\n",
    "        weights_path = os.path.join(MODEL_PATH,'fold_{fold}.hdf5'.format(fold=fold))\n",
    "\n",
    "        print(weights_path.split('/')[-2:])\n",
    "\n",
    "\n",
    "        model, preprocess = get_model(network, input_shape=(args.input_size, args.input_size, 3), train_base=True)\n",
    "        print(model.summary())\n",
    "        model.compile(optimizer=RMSprop(lr=args.learning_rate), loss=make_loss(args.loss_function),\n",
    "                          metrics=[dice_coef, jacard_coef])\n",
    "\n",
    "        if args.weights is None:\n",
    "            print('No weights passed, training from scratch')\n",
    "        else:\n",
    "            wp = args.weights.format(fold)\n",
    "            print('Loading weights from {}'.format(wp))\n",
    "            model.load_weights(wp, by_name=True)\n",
    "\n",
    "        augs = get_augmentations(args.augmentation_name, p=args.augmentation_prob, input_shape=(args.input_size, args.input_size, 3))\n",
    "\n",
    "\n",
    "        dg = SegmentationDataGenerator(input_shape=(args.input_size, args.input_size), batch_size = args.batch_size, augs = augs,\n",
    "                          preprocess = preprocess)\n",
    "\n",
    "        train_generator = dg.train_batch_generator(ids_train)\n",
    "        validation_generator = dg.evaluation_batch_generator(ids_valid)\n",
    "\n",
    "        callbacks = get_callback(args.callback, weights_path=weights_path,\n",
    "                                fold = fold)\n",
    "\n",
    "        # Fit the model with Generators:\n",
    "        model.fit_generator(generator=ThreadsafeIter(train_generator),\n",
    "                        steps_per_epoch=ids_train.shape[0] // args.batch_size * 2,\n",
    "                        epochs=args.epochs,\n",
    "                        callbacks=callbacks,\n",
    "                        validation_data=ThreadsafeIter(validation_generator),\n",
    "                        validation_steps=np.ceil(ids_valid.shape[0] / args.batch_size),\n",
    "                        workers=8)\n",
    "\n",
    "        model.load_weights(weights_path)\n",
    "\n",
    "        # SAVE OOF PREDICTIONS\n",
    "        dir_path = os.path.join(MODEL_PATH,'oof')\n",
    "        os.system(\"mkdir {}\".format(dir_path))\n",
    "        pred = predict_test(model=model,\n",
    "                        preds_path=dir_path,\n",
    "                        oof=True,\n",
    "                        ids=ids_valid,\n",
    "                        batch_size=args.batch_size*4,\n",
    "                        thr=0.5,\n",
    "                        TTA='',\n",
    "                        preprocess=preprocess)\n",
    "\n",
    "        # SAVE TEST PREDICTIONS\n",
    "#         dir_path = os.path.join(MODEL_PATH,'fold_{}'.format(fold))\n",
    "#         os.system(\"mkdir {}\".format(dir_path))\n",
    "#         pred = predict_test(model=model,\n",
    "#                         preds_path=dir_path,\n",
    "#                         oof=False,\n",
    "#                         ids=test.id.values,\n",
    "#                         batch_size=args.batch_size*2,\n",
    "#                         thr=0.5,\n",
    "#                         TTA='flip',\n",
    "#                         preprocess=preprocess)\n",
    "\n",
    "        K.clear_session()\n",
    "        # Run a single fold\n",
    "        # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPEREMNT with models without folds!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_50_224: 0.79148 / 0.84983 / 0.82436\n",
    "resnet50_fpn_old (~0.1600): 0.82296 / 0.87922 / 0.85315\n",
    "  \n",
    "resnet34_new: 0.80605 / 0.86341 / 0.83653\n",
    "    CHECK WEIGHTS TIME\n",
    "    DELETE PREPROCESSING\n",
    "    \n",
    "OLD_UPDATED_WITH_PARAMS_BATCH_SIZE_AND_CROP (0.1900): 0.80395 / 0.8557 / 0.82988\n",
    "Return Batch Size and Crop (~0.1541): 0.81444 / 0.86188 / 0.83796\n",
    "Set Batch size to 32 (~0.1514): 0.81938 / 0.86952 / 0.84411\n",
    "PAD_AND_CROP:\n",
    "    \n",
    "Freezing beforehand (0.1762)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.early_stop_patience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = '/home/branding_images/salt/unet_resnet_34_exp_2_128_shift_p_1_again/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'/home/branding_images/salt/classification/oof'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = evaluate([MODEL_PATH], train[train.fold.isin([0,1])].id.values, 0.5, classification='')\n",
    "print(\"{} / {} / {}\".format(np.round(np.mean(res['iout']),5),np.round(np.mean(res['dice']),5),np.round(np.mean(res['jacard']),5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet_resnet_34_exp_2_128\n",
    "0.83067 / 0.87668 / 0.85237\n",
    "unet_resnet_34_exp_2_128_again\n",
    "0.82038 / 0.87012 / 0.84568\n",
    "\n",
    "unet_resnet_34_exp_2_128_shift_p_1\n",
    "0.81983 / 0.86893 / 0.84417\n",
    "unet_resnet_34_exp_2_128_shift_p_1_again\n",
    "0.82187 / 0.86955 / 0.84518\n",
    "\n",
    "\n",
    "unet_resnet_34_exp_2_128_shift_p_08_shift_025\n",
    "0.82429 / 0.87048 / 0.84619\n",
    "\n",
    "unet_resnet_34_exp_2_128_shift_p_07_scale_02\n",
    "0.81884 / 0.86482 / 0.84085\n",
    "\n",
    "unet_resnet_34_exp_2_128_shift_p_07_scale_06\n",
    "0.82776 / 0.87532 / 0.85079\n",
    "unet_resnet_34_exp_2_128_shift_p_07_scale_06_again\n",
    "0.82212 / 0.8738 / 0.84824"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial 2 folds 0.80812 / 0.86215 / 0.83612\n",
    "again: 0.81995 / 0.86938 / 0.84416\n",
    "    \n",
    "unet_resnet_34_exp_2_folds_lr_001:\n",
    "0.76258 / 0.81572 / 0.78989\n",
    "\n",
    "unet_resnet_34_exp_2_folds_lr_0001:\n",
    "0.78885 / 0.84258 / 0.81624\n",
    "\n",
    "unet_resnet_34_exp_2_folds_vertical_flip\n",
    "0.7847 / 0.83687 / 0.81089\n",
    "\n",
    "unet_resnet_34_exp_2_folds_transpose_corr_v2\n",
    "0.81183 / 0.8625 / 0.83739\n",
    "unet_resnet_34_exp_2_folds_transpose_corr_v2_again\n",
    "0.79981 / 0.85433 / 0.82802\n",
    "\n",
    "unet_resnet_34_exp_2_folds_contrast (0.2-0.1)\n",
    "0.8109 / 0.86076 / 0.83574\n",
    "unet_resnet_34_exp_2_folds_contrast_again\n",
    "0.81629 / 0.86572 / 0.84094\n",
    "\n",
    "unet_resnet_34_exp_2_folds_contrast_corr (0.1-0.1)\n",
    "0.80496 / 0.85516 / 0.82939\n",
    "unet_resnet_34_exp_2_folds_contrast_corr_again\n",
    "0.81152 / 0.8637 / 0.837\n",
    "\n",
    "unet_resnet_34_exp_2_folds_blur\n",
    "0.79461 / 0.84789 / 0.82089\n",
    "\n",
    "unet_resnet_34_exp_2_folds_gaus_noise\n",
    "0.80719 / 0.8622 / 0.83523\n",
    "unet_resnet_34_exp_2_folds_gaus_noise_again\n",
    "0.79678 / 0.84703 / 0.8213\n",
    "\n",
    "unet_resnet_34_exp_2_folds_no_contrast_brightness\n",
    "0.81221 / 0.8642 / 0.83845\n",
    "unet_resnet_34_exp_2_folds_no_contrast_brightness_again\n",
    "0.80657 / 0.85867 / 0.83347\n",
    "\n",
    "unet_resnet_34_exp_2_folds_one_of_contrast_brightness:\n",
    "0.77881 / 0.83784 / 0.81064\n",
    "unet_resnet_34_exp_2_folds_one_of_contrast_brightness_again\n",
    "0.81196 / 0.86585 / 0.84046\n",
    "\n",
    "unet_resnet_34_exp_2_folds_shift_limit_1625\n",
    "0.8176 / 0.86312 / 0.83837\n",
    "unet_resnet_34_exp_2_folds_shift_limit_1625_again\n",
    "0.82224 / 0.8723 / 0.84684\n",
    "\n",
    "unet_resnet_34_exp_2_folds_brightness_contrast_0_5\n",
    "0.81481 / 0.8672 / 0.84179\n",
    "\n",
    "unet_resnet_34_better_augs_224\n",
    "0.82739 / 0.87377 / 0.84944"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res = evaluate([MODEL_PATH], train.id.values, 0.5, classification='')\n",
    "print(\"{} / {} / {}\".format(np.round(np.mean(res['iout']),5),np.round(np.mean(res['dice']),5),np.round(np.mean(res['jacard']),5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['resnet50_fpn_pad_crop',\n",
    "'resnet50_fpn_freeze_for_5_epochs',\n",
    "'resnet50_fpn_hor_flip_aug',\n",
    "'resnet_50_224',\n",
    "'resnet50_fpn_128',\n",
    "'resnet101_fpn_96_bs_32',\n",
    "'resnet50_fpn_96_soft_early_stopping',\n",
    "'resnet50_fpn_jacard_only',\n",
    "'unet_128_96',\n",
    "'resnet50_fpn_spatial_do',\n",
    "'resnet34_fpn',\n",
    "'resnet50_fpn_old',\n",
    "'unet_mobilenet_128']\n",
    "model_pathes = ['/home/branding_images/salt/'+x for x in models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# import numpy as np\n",
    "# import pydensecrf.densecrf as dcrf\n",
    "# from skimage.io import imread, imsave\n",
    "# from pydensecrf.utils import unary_from_labels, create_pairwise_bilateral\n",
    "# from skimage.color import gray2rgb\n",
    "# from skimage.color import rgb2gray\n",
    "# import matplotlib.pyplot as plt\n",
    "# import pandas as pd\n",
    "# from tqdm import tqdm\n",
    "# %matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['iout'] = res['iout']\n",
    "train.groupby('fold').iout.aggregate('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pred = ensemble(model_pathes,[0,1,2,3,4],test.id.values,0.5)\n",
    "pred = ensemble([MODEL_PATH],[0,1,2,3,4],test.id.values,0.5, classification='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['rle_mask'] = pred\n",
    "test[['id','rle_mask']].to_csv('unet_resnet_34_better_augs_224_tta_5_folds_83533.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot2x2Array(image, mask):\n",
    "    f, axarr = plt.subplots(1,2)\n",
    "    axarr[0].imshow(image)\n",
    "    axarr[1].imshow(mask)\n",
    "    axarr[0].grid()\n",
    "    axarr[1].grid()\n",
    "    axarr[0].set_title('Image')\n",
    "    axarr[1].set_title('Mask')\n",
    "    \n",
    "for i in range(5):\n",
    "    image, mask = dataset[np.random.randint(0, len(dataset))]\n",
    "    plot2x2Array(image, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_results(idx):\n",
    "    from rle import rle_decode\n",
    "    img = rle_decode(pred[idx],(101,101))\n",
    "    plt.figure(figsize=(4,4))\n",
    "    plt.imshow(img)\n",
    "    \n",
    "    plt.figure(figsize=(4,4))\n",
    "    plt.imshow(cv2.imread('train/images/{}.png'.format(ids_valid[idx])))\n",
    "    plt.figure(figsize=(4,4))\n",
    "    plt.imshow(cv2.imread('train/masks/{}.png'.format(ids_valid[idx])))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = os.path.join(args.models_dir,network+args.alias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    show_results(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_probs=[]\n",
    "network = 'classification'\n",
    "folds = [int(f) for f in args.fold.split(',')]\n",
    "for fold in folds:\n",
    "    K.clear_session()\n",
    "    print('***************************** FOLD {} *****************************'.format(fold))\n",
    "\n",
    "    MODEL_PATH = os.path.join(args.models_dir,network+args.alias)\n",
    "\n",
    "    if fold == 0:\n",
    "        if os.path.isdir(MODEL_PATH):\n",
    "            raise ValueError('Such Model already exists')\n",
    "        os.system(\"mkdir {}\".format(MODEL_PATH))\n",
    "        os.system(\"cp params.py {}\".format(MODEL_PATH))\n",
    "\n",
    "    df_train = train[train.fold != fold].copy().reset_index(drop=True)\n",
    "    df_valid = train[train.fold == fold].copy().reset_index(drop=True)\n",
    "\n",
    "    ids_train, ids_valid = df_train.id.values, df_valid.id.values\n",
    "\n",
    "    print('Training on {} samples'.format(ids_train.shape[0]))\n",
    "    print('Validating on {} samples'.format(ids_valid.shape[0]))\n",
    "\n",
    "    # Initialize Model\n",
    "    weights_path = os.path.join(MODEL_PATH,'fold_{fold}.hdf5'.format(fold=fold))\n",
    "\n",
    "    print(weights_path.split('/')[-2:])\n",
    "\n",
    "    model, preprocess = get_model(network, input_shape=(args.input_size, args.input_size, 3), train_base=True)\n",
    "    print(model.summary())\n",
    "    model.compile(optimizer=RMSprop(lr=args.learning_rate), loss='binary_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "    if args.weights is None:\n",
    "        print('No weights passed, training from scratch')\n",
    "    else:\n",
    "        wp = args.weights.format(fold)\n",
    "        print('Loading weights from {}'.format(wp))\n",
    "        model.load_weights(wp, by_name=True)\n",
    "\n",
    "    augs = get_augmentations(args.augmentation_name, p=args.augmentation_prob, input_shape=(args.input_size, args.input_size, 3))\n",
    "\n",
    "\n",
    "    dg = ClassificationDataGenerator(input_shape=(args.input_size, args.input_size), batch_size = args.batch_size, augs = augs,\n",
    "                      preprocess = preprocess)\n",
    "\n",
    "    train_generator = dg.train_batch_generator(ids_train)\n",
    "    validation_generator = dg.evaluation_batch_generator(ids_valid)\n",
    "\n",
    "    callbacks = get_callback(args.callback, weights_path=weights_path,\n",
    "                            fold = fold)\n",
    "\n",
    "    # Fit the model with Generators:\n",
    "    model.fit_generator(generator=ThreadsafeIter(train_generator),\n",
    "                    steps_per_epoch=ids_train.shape[0] // args.batch_size * 2,\n",
    "                    epochs=args.epochs,\n",
    "                    callbacks=callbacks,\n",
    "                    validation_data=ThreadsafeIter(validation_generator),\n",
    "                    validation_steps=np.ceil(ids_valid.shape[0] / args.batch_size),\n",
    "                    workers=8)\n",
    "\n",
    "    model.load_weights(weights_path)\n",
    "\n",
    "    # SAVE OOF PREDICTIONS\n",
    "    dir_path = os.path.join(MODEL_PATH,'oof')\n",
    "    os.system(\"mkdir {}\".format(dir_path))\n",
    "    pred = classification_predict_test(model=model,\n",
    "                    preds_path=dir_path,\n",
    "                    oof=True,\n",
    "                    ids=ids_valid,\n",
    "                    batch_size=args.batch_size*4,\n",
    "                    thr=0.5,\n",
    "                    TTA='',\n",
    "                    preprocess=preprocess)\n",
    "    df_valid['prob'] = pred\n",
    "    validation_probs.append(df_valid)\n",
    "\n",
    "    # SAVE TEST PREDICTIONS\n",
    "    dir_path = os.path.join(MODEL_PATH,'fold_{}'.format(fold))\n",
    "    os.system(\"mkdir {}\".format(dir_path))\n",
    "    pred = classification_predict_test(model=model,\n",
    "                    preds_path=dir_path,\n",
    "                    oof=False,\n",
    "                    ids=test.id.values,\n",
    "                    batch_size=args.batch_size*4,\n",
    "                    thr=0.5,\n",
    "                    TTA='',\n",
    "                    preprocess=preprocess)\n",
    "    test['prob'] = pred\n",
    "    test.to_csv(os.path.join(dir_path,'probs_test_fold_{}.csv'.format(fold)),index=False)\n",
    "\n",
    "    K.clear_session()\n",
    "    # Run a single fold\n",
    "    # break\n",
    "\n",
    "dir_path = os.path.join(MODEL_PATH,'oof')\n",
    "pd.concat(validation_probs).to_csv(os.path.join(dir_path,'probs_oof.csv'),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = os.path.join(MODEL_PATH,'oof')\n",
    "tt = pd.read_csv(os.path.join(dir_path,'probs_oof_fold_{}.csv'.format(fold)))\n",
    "tt[pd.isnull(tt['rle_mask'])&(tt.unique_pixels > 1)].prob.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Add random crops augmentation\n",
    "\n",
    "Do not load the weights (start training from scratch?)\n",
    "\n",
    "Apply Cyclic LR\n",
    "\n",
    "Finetune models for each fold (maybe stucked in local optima). Probably, finetune without augmentations\n",
    "\n",
    "TRY TTA and Blend of top-5 models.\n",
    "\n",
    "Add more augmentations to 'initial'\n",
    "\n",
    "Delete VGG from unet_resnet_50 in the end\n",
    "Compare keras resnet_50 and resnet_50_fixed. There is average pooling at the end.\n",
    "And no padding in the beginning. And min sizes are different\n",
    "\n",
    "I think this pipeline works really well considering its simplicity, but I made a big mistake.\n",
    "- I didn't noticed that some test outputs from stage 1 were horribly wrong until today and didn't\n",
    "have chance to correct it. :( I should have found the issue early only if\n",
    "I had good visualization or simple sanity check logic.\n",
    "\n",
    "The best lesson from this competition is that good visualization/analyzing tool is really important.\n",
    "                             \n",
    "Random crops. E.g. the same 96 and resize during inference.\n",
    "    While random crops 96 in the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNET d4 augs (0.62)\n",
    "! LINKNET (0.70)\n",
    "cv.gaussian blur for masks predicted smooting\n",
    "\n",
    "loss: iou is overprediction. bce+jaccard\n",
    "we could use 96 or 128 size.\n",
    "bce+jaccard: 0.15 on validation; iou -- 0.8. LB 0.74\n",
    "\n",
    "Start with predicting: whether an image has mask at all -- binary classification.\n",
    "    Then multiply these prior probabilities on mask obtained! Again: classification pipeline.\n",
    "        \n",
    "Some 100% incorrect masks!\n",
    "\n",
    "FIND DUPLICATES OF IMAGES! In train and test\n",
    "\n",
    "Change Kaggle architectures with comments from ods:\n",
    "Use SpatialDropout2D and decrease dropout rate\n",
    "Conv2DTranspose works worse than NN upsampling + conv\n",
    "\"You don't need multiprocessing, it will run batches preparation in different processes\"\n",
    "-- use multiprocessing in keras\n",
    "\n",
    "CRF postprocessing for predictions obtained! Just Function from kaggle -- you could check on validation!\n",
    "\n",
    "TRY TO BINIRIZE MASK AFTER APPLYING RESIZE\n",
    "HOW IS MY DICE CALCULATED? IT SHOULD HAVE THRESHOLD\n",
    "\n",
    "Increase Smoothing Parameter in Dice!\n",
    "\n",
    "Write Own Cyclic LR? Custom with saving checkpoints!\n",
    "\n",
    "Pretrain model on classification (whether the mask exist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Try to use own reduceLR. Because it's not clear where keras starts with decreasing LR\n",
    "(I guess, from the last epoch. Not the best! So, reinitialize the model. Add some functions to not repeat the code)\n",
    "\n",
    "Pretrained model for each fold:\n",
    "    pretrain of pseudolabels (the best ensemble so far) and high augmentations\n",
    "    or train simultaneously\n",
    "    \n",
    "Try different LR and policies (factor)\n",
    "\n",
    "Jacard loss with threshold\n",
    "https://github.com/lyakaap/Kaggle-Carvana-3rd-Place-Solution/blob/master/losses.py\n",
    "    \n",
    "Evgeny used Adam with inital LR=1e-4 and several lr drops at fixed steps.\n",
    "\n",
    "Segnet and\n",
    "Linknet (https://github.com/davidtvs/Keras-LinkNet/tree/master/models) architectures\n",
    "\"\"\"\n",
    "model = LinkNet(num_classes, input_shape=input_shape)\n",
    "        model = model.get_model(\n",
    "            pretrained_encoder=pretrained_encoder, weights_path=weights_path\n",
    "        )\n",
    "\"\"\"\n",
    "\n",
    "DeepLab v3+\n",
    "https://github.com/bonlime/keras-deeplab-v3-plus\n",
    "\n",
    "Tensorboard callback with images!\n",
    "https://github.com/davidtvs/Keras-LinkNet/blob/master/callbacks.py\n",
    "https://stackoverflow.com/questions/43784921/how-to-display-custom-images-in-tensorboard-using-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
