{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "from params import args\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train_proc_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = pd.read_csv('data/depths.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.merge(depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[test.z==63].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(args.masks_dir,'{}.png'.format('88839f49f9'))\n",
    "m = cv2.imread(path, cv2.IMREAD_GRAYSCALE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.augmentation_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from params import args\n",
    "from augmentations import get_augmentations\n",
    "def read_image(path, input_size):\n",
    "    img = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    # img = cv2.resize(img, input_size)\n",
    "    # [:,:,::-1]\n",
    "\n",
    "    return img\n",
    "    \n",
    "def read_mask(path, input_size):\n",
    "    mask = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    # mask = cv2.resize(mask, input_size)\n",
    "\n",
    "    return mask  \n",
    "\n",
    "id = '0f5ada4dc3'\n",
    "\n",
    "# Read with resizing\n",
    "img = read_image(os.path.join(args.images_dir,'{}.png'.format(id)), None)\n",
    "mask = read_mask(os.path.join(args.masks_dir,'{}.png'.format(id)), None)\n",
    "\n",
    "plt.figure(figsize=(3,3))\n",
    "plt.imshow(img)\n",
    "\n",
    "print(img[0][0])\n",
    "\n",
    "# Random Crops during training\n",
    "augs = get_augmentations(args.augmentation_name, p=args.augmentation_prob, input_shape=(args.input_size, args.input_size, 3))\n",
    "\n",
    "if augs:\n",
    "    data = {\"image\": img, \"mask\": mask}\n",
    "    augmented = augs(**data)\n",
    "    img, mask = augmented[\"image\"], augmented[\"mask\"]\n",
    "    \n",
    "plt.figure(figsize=(3,3))\n",
    "plt.imshow(img)\n",
    "print(img[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train.sort_values('rle_mask')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "borders = []\n",
    "all_imgs_test = []\n",
    "\n",
    "for id in test[test.z==942].id.values:\n",
    "    path = os.path.join(args.test_folder,'{}.png'.format(id))\n",
    "    img = cv2.imread(path, cv2.IMREAD_COLOR)    \n",
    "    all_imgs_test.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "borders = []\n",
    "all_imgs_train = []\n",
    "\n",
    "for id in train[train.z==942].id.values:\n",
    "    path = os.path.join(args.images_dir,'{}.png'.format(id))\n",
    "    path_mask = os.path.join(args.masks_dir,'{}.png'.format(id))\n",
    "    img = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    mask = cv2.imread(path_mask, cv2.IMREAD_GRAYSCALE)     \n",
    "    all_imgs_train.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.hstack([all_imgs_test[-1],all_imgs_train[-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.hstack(all_imgs_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.hstack(all_imgs_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "borders = []\n",
    "\n",
    "for id in train[train.z==63].id.values:\n",
    "    path = os.path.join(args.images_dir,'{}.png'.format(id))\n",
    "    path_mask = os.path.join(args.masks_dir,'{}.png'.format(id))\n",
    "    img = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    mask = cv2.imread(path_mask, cv2.IMREAD_GRAYSCALE)     \n",
    "    \n",
    "    plt.figure(figsize=(4,4))\n",
    "    plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train.sort_values('z')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "borders = []\n",
    "\n",
    "for id in train.id.values:\n",
    "    path = os.path.join(args.images_dir,'{}.png'.format(id))\n",
    "    path_mask = os.path.join(args.masks_dir,'{}.png'.format(id))\n",
    "    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    mask = cv2.imread(path_mask, cv2.IMREAD_GRAYSCALE)     \n",
    "    \n",
    "    up_border = img[0,:]\n",
    "    down_border = img[-1,:]\n",
    "    left_border = img[:,0]\n",
    "    right_border = img[:,-1]\n",
    "    \n",
    "    borders.extend(up_border,down_border,left_border,right_border)\n",
    "\n",
    "# prepare df with all data\n",
    "lens = [len(border) for border in borders]\n",
    "img_idx = list(range(len(border)//4))*4\n",
    "position = ['up','down','left','right']*len(len(border)//4)\n",
    "nn = [None]*len(position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img[0,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height, width = img.shape[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_raw_data(image_size=(101, 101), space = 'bgr',load_mask=True):\n",
    "    \"\"\"Load raw data.\"\"\"\n",
    "    # Python lists to store the training images/masks and test images.\n",
    "    x_train, y_train, x_test = [],[],[]\n",
    "\n",
    "    for id in tqdm.tqdm_notebook(train.id.values):\n",
    "        path = os.path.join(args.images_dir,'{}.png'.format(id))\n",
    "        path_mask = os.path.join(args.masks_dir,'{}.png'.format(id))\n",
    "        img = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "        if load_mask:\n",
    "            mask = cv2.imread(path_mask, cv2.IMREAD_GRAYSCALE)\n",
    "            mask = np.expand_dims(mask, axis=2)\n",
    "            y_train.append(mask)\n",
    "        x_train.append(img)\n",
    "        \n",
    "    # Read and resize test images. \n",
    "    \n",
    "    for id in tqdm.tqdm_notebook(test.id.values):\n",
    "        path = os.path.join(args.test_folder,'{}.png'.format(id))\n",
    "        img = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "        x_test.append(img)\n",
    "\n",
    "    # Transform lists into 4-dim numpy arrays.\n",
    "    x_train = np.array(x_train)\n",
    "    #if load_mask:\n",
    "    y_train = np.array(y_train)\n",
    "    #return x_train, y_train\n",
    "    #y_train = np.expand_dims(np.array(y_train), axis=4)\n",
    "    x_test = np.array(x_test)\n",
    "    print('Data loaded')\n",
    "    if load_mask:\n",
    "        return x_train, y_train, x_test\n",
    "    else:\n",
    "        return x_train, x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test = load_raw_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_images(data,indexes):\n",
    "    \"\"\" Combines img from data using indexes as follows:\n",
    "        0 1\n",
    "        2 3 \n",
    "    \"\"\"\n",
    "    up = np.hstack([data[indexes[0]],data[indexes[1]]])\n",
    "    down = np.hstack([data[indexes[2]],data[indexes[3]]])\n",
    "    full = np.vstack([up,down])\n",
    "    return full\n",
    "\n",
    "def make_mosaic(data,return_connectivity = False, plot_images = False,external_df = None):\n",
    "    \"\"\"Find images with simular borders and combine them to one big image\"\"\"\n",
    "    if external_df is not None:\n",
    "        external_df['mosaic_idx'] = np.nan\n",
    "        external_df['mosaic_position'] = np.nan\n",
    "        # print(external_df.head())\n",
    "    \n",
    "    # extract borders from images\n",
    "    borders = []\n",
    "    for x in data:\n",
    "        borders.extend([x[0,:,:].flatten(),x[-1,:,:].flatten(),\n",
    "                        x[:,0,:].flatten(),x[:,-1,:].flatten()])\n",
    "    borders = list(np.array(borders))\n",
    "\n",
    "    # prepare df with all data\n",
    "    lens = [len(border) for border in borders]\n",
    "    img_idx = list(range(len(data)))*4\n",
    "    img_idx.sort()\n",
    "    position = ['up','down','left','right']*len(data)\n",
    "    nn = [None]*len(position)\n",
    "    #print(np.vstack([img_idx,position,borders,lens,nn]).shape)\n",
    "    # df = pd.DataFrame([img_idx,position,borders,lens,nn])\n",
    "    df = pd.DataFrame({'img_idx':img_idx,'position':position,'border':borders,'len':lens,'nn':nn})\n",
    "#     df = pd.DataFrame(data=np.vstack([img_idx,position,borders,,nn]).T,\n",
    "#                       columns=['img_idx','position','border',,'nn'])\n",
    "    uniq_lens = df['len'].unique()\n",
    "    \n",
    "    for idx,l in enumerate(uniq_lens):\n",
    "        # fit NN on borders of certain size with 1 neighbor\n",
    "        nn = NearestNeighbors(n_neighbors=1).fit(np.stack(df[df.len == l]['border'].values))\n",
    "        distances, neighbors = nn.kneighbors()\n",
    "        real_neighbor = np.array([None]*len(neighbors))\n",
    "        distances, neighbors = distances.flatten(),neighbors.flatten()\n",
    "\n",
    "        # if many borders are close to one, we want to take only the closest\n",
    "        uniq_neighbors = np.unique(neighbors)\n",
    "\n",
    "        # difficult to understand but works :c\n",
    "        for un_n in uniq_neighbors:\n",
    "            # min distance for borders with same nn\n",
    "            min_index = list(distances).index(distances[neighbors == un_n].min())\n",
    "            # check that min is double-sided\n",
    "            double_sided = distances[neighbors[min_index]] == distances[neighbors == un_n].min()\n",
    "            if double_sided and distances[neighbors[min_index]] < 1000:\n",
    "                real_neighbor[min_index] = neighbors[min_index]\n",
    "                real_neighbor[neighbors[min_index]] = min_index\n",
    "        indexes = df[df.len == l].index\n",
    "        for idx2,r_n in enumerate(real_neighbor):\n",
    "            if r_n is not None:\n",
    "                df['nn'].iloc[indexes[idx2]] = indexes[r_n]\n",
    "    \n",
    "    # img connectivity graph. \n",
    "    img_connectivity = {}\n",
    "    for img in df.img_idx.unique():\n",
    "        slc = df[df['img_idx'] == img]\n",
    "        img_nn = {}\n",
    "\n",
    "        # get near images_id & position\n",
    "        for nn_border,position in zip(slc[slc['nn'].notnull()]['nn'],\n",
    "                                      slc[slc['nn'].notnull()]['position']):\n",
    "\n",
    "            # filter obvious errors when we try to connect bottom of one image to bottom of another\n",
    "            # my hypotesis is that images were simply cut, without rotation\n",
    "            if position == df.iloc[nn_border]['position']:\n",
    "                continue\n",
    "            img_nn[position] = df.iloc[nn_border]['img_idx']\n",
    "        img_connectivity[img] = img_nn\n",
    "\n",
    "    imgs = []\n",
    "    indexes = set()\n",
    "    mosaic_idx = 0\n",
    "    \n",
    "    # errors in connectivity are filtered \n",
    "    good_img_connectivity = {}\n",
    "    for k,v in img_connectivity.items():\n",
    "        if v.get('down') is not None:\n",
    "            if v.get('right') is not None:\n",
    "                # need down right image\n",
    "                # check if both right and down image are connected to the same image in the down right corner\n",
    "                if (img_connectivity[v['right']].get('down') is not None) and img_connectivity[v['down']].get('right') is not None:\n",
    "                    if img_connectivity[v['right']]['down'] == img_connectivity[v['down']]['right']:\n",
    "                        v['down_right'] = img_connectivity[v['right']]['down']\n",
    "                        temp_indexes = [k,v['right'],v['down'],v['down_right']]\n",
    "                        if (len(np.unique(temp_indexes)) < 4) or (len(indexes.intersection(temp_indexes)) > 0):\n",
    "                            continue\n",
    "                        # надо тут фильтровать что они не одинаковые\n",
    "                        good_img_connectivity[k] = temp_indexes\n",
    "                        indexes.update(temp_indexes)\n",
    "                        imgs.append(combine_images(data,temp_indexes))\n",
    "                        if external_df is not None:\n",
    "                            external_df['mosaic_idx'].iloc[temp_indexes] = mosaic_idx\n",
    "                            external_df['mosaic_position'].iloc[temp_indexes] = ['up_left','up_right','down_left','down_right']\n",
    "                            mosaic_idx += 1\n",
    "                        continue\n",
    "            if v.get('left') is not None:\n",
    "                # need down left image\n",
    "                if img_connectivity[v['left']].get('down') is not None and img_connectivity[v['down']].get('left') is not None:\n",
    "                    if img_connectivity[v['left']]['down'] == img_connectivity[v['down']]['left']:\n",
    "                        v['down_left'] = img_connectivity[v['left']]['down']\n",
    "                        temp_indexes = [v['left'],k,v['down_left'],v['down']]\n",
    "                        if (len(np.unique(temp_indexes)) < 4) or (len(indexes.intersection(temp_indexes)) > 0):\n",
    "                            continue\n",
    "                        good_img_connectivity[k] = temp_indexes\n",
    "                        indexes.update(temp_indexes)\n",
    "                        imgs.append(combine_images(data,temp_indexes))\n",
    "                        \n",
    "                        if external_df is not None:\n",
    "                            external_df['mosaic_idx'].iloc[temp_indexes] = mosaic_idx\n",
    "                            external_df['mosaic_position'].iloc[temp_indexes] = ['up_left','up_right','down_left','down_right']\n",
    "                            \n",
    "                            mosaic_idx += 1 \n",
    "                        continue\n",
    "        if v.get('up') is not None:\n",
    "            if v.get('right') is not None:\n",
    "                # need up right image\n",
    "                if img_connectivity[v['right']].get('up') is not None and img_connectivity[v['up']].get('right') is not None:\n",
    "                    if img_connectivity[v['right']]['up'] == img_connectivity[v['up']]['right']:\n",
    "                        v['up_right'] = img_connectivity[v['right']]['up']\n",
    "                        temp_indexes = [v['up'],v['up_right'],k,v['right']]\n",
    "                        if (len(np.unique(temp_indexes)) < 4) or (len(indexes.intersection(temp_indexes)) > 0):\n",
    "                            continue\n",
    "                        good_img_connectivity[k] = temp_indexes\n",
    "                        indexes.update(temp_indexes)\n",
    "                        imgs.append(combine_images(data,temp_indexes))\n",
    "                        \n",
    "                        if external_df is not None:\n",
    "                            external_df['mosaic_idx'].iloc[temp_indexes] = mosaic_idx\n",
    "                            external_df['mosaic_position'].iloc[temp_indexes] = ['up_left','up_right','down_left','down_right']\n",
    "                            \n",
    "                            mosaic_idx += 1 \n",
    "                        continue\n",
    "            if v.get('left') is not None:\n",
    "                # need up left image\n",
    "                if img_connectivity[v['left']].get('up') is not None and img_connectivity[v['up']].get('left') is not None:\n",
    "                    if img_connectivity[v['left']]['up'] == img_connectivity[v['up']]['left']:\n",
    "                        v['up_left'] = img_connectivity[v['left']]['up']\n",
    "                        temp_indexes = [v['up_left'],v['up'],v['left'],k]\n",
    "                        if (len(np.unique(temp_indexes)) < 4) or (len(indexes.intersection(temp_indexes)) > 0):\n",
    "                            continue\n",
    "                        good_img_connectivity[k] = temp_indexes\n",
    "                        indexes.update(temp_indexes)\n",
    "                        imgs.append(combine_images(data,temp_indexes))\n",
    "                        \n",
    "                        if external_df is not None:\n",
    "                            external_df['mosaic_idx'].iloc[temp_indexes] = mosaic_idx\n",
    "                            external_df['mosaic_position'].iloc[temp_indexes] = ['up_left','up_right','down_left','down_right']\n",
    "                            \n",
    "                            mosaic_idx += 1 \n",
    "                        continue\n",
    "\n",
    "    # same images are present 4 times (one for every piece) so we need to filter them\n",
    "    print('Images before filtering: {}'.format(np.shape(imgs)))\n",
    "    \n",
    "    # can use np. unique only on images of one size, flatten first, then select\n",
    "    flattened = np.array([i.flatten() for i in imgs])\n",
    "    uniq_lens = np.unique([i.shape for i in flattened])\n",
    "    filtered_imgs = []\n",
    "    for un_l in uniq_lens:\n",
    "        filtered_imgs.extend(np.unique(np.array([i for i in imgs if i.flatten().shape == un_l]),axis=0))\n",
    "        \n",
    "    filtered_imgs = np.array(filtered_imgs)\n",
    "    print('Images after filtering: {}'.format(np.shape(filtered_imgs)))\n",
    "    \n",
    "    if return_connectivity:\n",
    "        print(good_img_connectivity)\n",
    "    \n",
    "    if plot_images:\n",
    "        for i in filtered_imgs:\n",
    "            plt.imshow(i)\n",
    "            plt.show()\n",
    "            \n",
    "    # list of not combined images. return if you need\n",
    "    not_combined = list(set(range(len(data))) - indexes)\n",
    "    \n",
    "    if external_df is not None:\n",
    "        #un_mos_id = external_df[external_df.mosaic_idx.notnull()].mosaic_idx.unique()\n",
    "        #mos_dict = {k:v for k,v in zip(un_mos_id,range(len(un_mos_id)))}\n",
    "        #external_df.mosaic_idx = external_df.mosaic_idx.map(mos_dict)\n",
    "        ## print(temp.mosaic_idx.shape[0])\n",
    "        ## print(len(temp.mosaic_idx[temp.mosaic_idx.isnull()] ))\n",
    "        ## print(len(list(range(temp.mosaic_idx.shape[0]-len(temp.mosaic_idx[temp.mosaic_idx.isnull()]),\n",
    "        ##                     temp.mosaic_idx.shape[0]))))\n",
    "        external_df.loc[external_df[external_df['mosaic_idx'].isnull()].index,'mosaic_idx'] = range(\n",
    "            int(np.nanmax(external_df.mosaic_idx.unique())) + 1,\n",
    "            int(np.nanmax(external_df.mosaic_idx.unique())) + 1 + len(external_df.mosaic_idx[external_df.mosaic_idx.isnull()]))\n",
    "        external_df['mosaic_idx'] = external_df['mosaic_idx'].astype(np.int32)\n",
    "        if return_connectivity:\n",
    "            return filtered_imgs, external_df, good_img_connectivity\n",
    "        else:\n",
    "            return filtered_imgs, external_df\n",
    "    if return_connectivity:\n",
    "        return filtered_imgs,good_img_connectivity\n",
    "    else:\n",
    "        return filtered_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_imgs,good_img_connectivity = make_mosaic(x_test,return_connectivity=True,plot_images=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.iloc[175,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.iloc[1523,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.iloc[12757,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.iloc[5335,:].z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for el in [175, 1523, 12757, 5335]:\n",
    "    print(test.iloc[el,:].z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for el in [7569, 8689, 5412, 246]:\n",
    "    print(test.iloc[el,:].z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_img_connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_mosaic(x_train,return_connectivity=False,plot_images=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_img_connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Визуально картинки одной глубины, бывают сильно похожими на соседние, но крайне редко.\n",
    "d = 655\n",
    "width = 5\n",
    "height = len(depths[depths.z == d].index.values)//width + (len(depths[depths.z == d].index.values)%width >0)\n",
    "fig, axs = plt.subplots(height, width, figsize=(15, 14))\n",
    "for i, names in enumerate(depths[depths.z == d].index.values):\n",
    "   ax = axs[i // width, i % width]\n",
    "   try:\n",
    "       ax.imshow(np.asarray(Image.open(osp.join(path_train, 'images', f'{names}.png'))))\n",
    "   except:\n",
    "       ax.imshow(np.asarray(Image.open(osp.join(path_test, 'images', f'{names}.png'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FOLD Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train_proc_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[train.fold == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>rle_mask</th>\n",
       "      <th>z</th>\n",
       "      <th>fold</th>\n",
       "      <th>unique_pixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3577258d6b</td>\n",
       "      <td>NaN</td>\n",
       "      <td>304</td>\n",
       "      <td>2</td>\n",
       "      <td>178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9737133eff</td>\n",
       "      <td>NaN</td>\n",
       "      <td>104</td>\n",
       "      <td>2</td>\n",
       "      <td>235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88839f49f9</td>\n",
       "      <td>82 8 182 7 282 8 382 8 482 7 582 7 683 5 784 3...</td>\n",
       "      <td>618</td>\n",
       "      <td>4</td>\n",
       "      <td>213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7d87ab4aa8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>580</td>\n",
       "      <td>1</td>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>96cc5caec0</td>\n",
       "      <td>1 9090 9111 81 9260 33</td>\n",
       "      <td>857</td>\n",
       "      <td>4</td>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                           rle_mask    z  fold  \\\n",
       "0  3577258d6b                                                NaN  304     2   \n",
       "1  9737133eff                                                NaN  104     2   \n",
       "2  88839f49f9  82 8 182 7 282 8 382 8 482 7 582 7 683 5 784 3...  618     4   \n",
       "3  7d87ab4aa8                                                NaN  580     1   \n",
       "4  96cc5caec0                             1 9090 9111 81 9260 33  857     4   \n",
       "\n",
       "   unique_pixels  \n",
       "0            178  \n",
       "1            235  \n",
       "2            213  \n",
       "3            203  \n",
       "4            185  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_path = '/home/branding_images/salt/unet_resnet_152_exp_0_202_256_scheduler_150_epochs_finetune/oof'\n",
    "MODEL_PATH = '/home/branding_images/salt/unet_resnet_152_exp_0_202_256_scheduler_150_epochs_finetune'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-2f4f35ded540>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'pred' is not defined"
     ]
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 5)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/p/babakhin/Branding/salt_old/kaggle-salt/data/train/images'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.images_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashes = []\n",
    "import hashlib\n",
    "def get_md5(file_name):\n",
    "    return hashlib.md5(open(str(file_name), 'rb').read()).hexdigest()\n",
    "\n",
    "for id in train.id.values:\n",
    "\n",
    "    # Read with resizing\n",
    "    path = os.path.join(args.images_dir,'{}.png'.format(id))\n",
    "    hashes.append(get_md5(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashes = []\n",
    "import hashlib\n",
    "def get_md5(file_name):\n",
    "    return hashlib.md5(open(str(file_name), 'rb').read()).hexdigest()\n",
    "\n",
    "for id in test.id.values:\n",
    "\n",
    "    # Read with resizing\n",
    "    path = os.path.join(args.test_folder,'{}.png'.format(id))\n",
    "    hashes.append(get_md5(path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['hash'] = hashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['hash'] = hashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3921"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.hash.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17571"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.hash.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21492"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "17571+3921"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3920, 6)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train.unique_pixels > 1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>rle_mask</th>\n",
       "      <th>z</th>\n",
       "      <th>fold</th>\n",
       "      <th>unique_pixels</th>\n",
       "      <th>hash</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3577258d6b</td>\n",
       "      <td>NaN</td>\n",
       "      <td>304</td>\n",
       "      <td>2</td>\n",
       "      <td>178</td>\n",
       "      <td>102235b4640695cd867f9db57d527218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9737133eff</td>\n",
       "      <td>NaN</td>\n",
       "      <td>104</td>\n",
       "      <td>2</td>\n",
       "      <td>235</td>\n",
       "      <td>fd2c2b0658051fdd6a41e7a29c3a1e11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88839f49f9</td>\n",
       "      <td>82 8 182 7 282 8 382 8 482 7 582 7 683 5 784 3...</td>\n",
       "      <td>618</td>\n",
       "      <td>4</td>\n",
       "      <td>213</td>\n",
       "      <td>636fbb4dc0e8ec48a9c553322a8aacde</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7d87ab4aa8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>580</td>\n",
       "      <td>1</td>\n",
       "      <td>203</td>\n",
       "      <td>31ae567f1d3c0ab0b28727688a8641c7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>96cc5caec0</td>\n",
       "      <td>1 9090 9111 81 9260 33</td>\n",
       "      <td>857</td>\n",
       "      <td>4</td>\n",
       "      <td>185</td>\n",
       "      <td>d29f4a244de40374f11a4b47d512b68c</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                           rle_mask    z  fold  \\\n",
       "0  3577258d6b                                                NaN  304     2   \n",
       "1  9737133eff                                                NaN  104     2   \n",
       "2  88839f49f9  82 8 182 7 282 8 382 8 482 7 582 7 683 5 784 3...  618     4   \n",
       "3  7d87ab4aa8                                                NaN  580     1   \n",
       "4  96cc5caec0                             1 9090 9111 81 9260 33  857     4   \n",
       "\n",
       "   unique_pixels                              hash  \n",
       "0            178  102235b4640695cd867f9db57d527218  \n",
       "1            235  fd2c2b0658051fdd6a41e7a29c3a1e11  \n",
       "2            213  636fbb4dc0e8ec48a9c553322a8aacde  \n",
       "3            203  31ae567f1d3c0ab0b28727688a8641c7  \n",
       "4            185  d29f4a244de40374f11a4b47d512b68c  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "foo:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "21491"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([train,test]).hash.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from params import args\n",
    "from augmentations import get_augmentations\n",
    "def read_image(path, input_size):\n",
    "    img = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    # img = cv2.resize(img, input_size)\n",
    "    # [:,:,::-1]\n",
    "\n",
    "    return img\n",
    "    \n",
    "def read_mask(path, input_size):\n",
    "    mask = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    # mask = cv2.resize(mask, input_size)\n",
    "\n",
    "    return mask  \n",
    "\n",
    "for id in train[(train.num_of_pixel_in_mask > 0)&(train.num_of_pixel_in_mask < 300)].id.values[10:50]:\n",
    "\n",
    "    # Read with resizing\n",
    "    img = read_image(os.path.join(args.images_dir,'{}.png'.format(id)), None)\n",
    "    mask = read_mask(os.path.join(args.masks_dir,'{}.png'.format(id)), None)\n",
    "    pred = read_mask(os.path.join(preds_path,'{}.png'.format(id)), None)\n",
    "\n",
    "    plt.figure(figsize=(3,3))\n",
    "    plt.imshow(img)\n",
    "    plt.figure(figsize=(3,3))\n",
    "    plt.imshow(mask)\n",
    "    plt.figure(figsize=(3,3))\n",
    "    plt.imshow(np.where(pred/255 > 0.5, 255, 0))\n",
    "    plt.figure(figsize=(3,3))\n",
    "    plt.imshow(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res['iout']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['metric'] = res['iout']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = []\n",
    "for idx,row in train.iterrows():\n",
    "    mask = read_mask(os.path.join(args.masks_dir,'{}.png'.format(row['id'])), None)\n",
    "    mask = mask > 128\n",
    "    num_of_pixel_in_mask = mask.sum()\n",
    "    l.append(num_of_pixel_in_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[train['num_of_pixel_in_mask'] > 0]['num_of_pixel_in_mask'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[train['num_of_pixel_in_mask'] > 0]['num_of_pixel_in_mask'].plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[train['num_of_pixel_in_mask'] > 0]['num_of_pixel_in_mask'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['num_of_pixel_in_mask'] = l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " size (0, 0) | IOUT 0.9539 | sample nr 1562 | fraction 0.3905 | max gain 0.0180. 0.9743589743589743 38.5%\n",
    " size (1, 300) | IOUT 0.2588 | sample nr 311 | fraction 0.07775 | max gain 0.0576 0.3563636363636363 6.8%\n",
    " size (300, 1000) | IOUT 0.5446 | sample nr 260 | fraction 0.065 | max gain 0.0296 0.6088888888888888 5.5%\n",
    " size (1000, 3000) | IOUT 0.7626 | sample nr 508 | fraction 0.127 | max gain 0.0301 0.835 12.3%\n",
    " size (3000, 9000) | IOUT 0.8994 | sample nr 1090 | fraction 0.2725 | max gain 0.0274 0.9041666666666667 29.6%\n",
    " size (9000, 10201) | IOUT 0.8732 | sample nr 272 | fraction 0.068 | max gain 0.0086 0.9714285714285714 6.9%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond = (train.num_of_pixel_in_mask > 9000)&(train.num_of_pixel_in_mask < 11000)\n",
    "train[cond].metric.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[cond].metric.shape[0]/train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.groupby('metric').num_of_pixel_in_mask.aggregate(['mean','median','min','max'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thr_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thr_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linspace(0.01, 0.5, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    'unet_resnet_152_valid_plus_resize_202_pad_256_bs_12_corr',\n",
    "          'unet_resnet_152_valid_plus_resize_202_pad_256_bs_12_corr',\n",
    "          'unet_resnet_152_finetuning_v2_reduce_lr_flip',\n",
    "          'unet_resnet_50unet_resnet_50_exp_0_144_192_new_scheduler_200_epochs',\n",
    "          'unet_resnet_50unet_resnet_50_exp_0_144_192_new_scheduler_200_epochs_bce_jacard_dice',\n",
    "          'resnet50_fpn_96_soft_early_stopping',\n",
    "          'resnet50_fpn_old',\n",
    "          'unet_resnet_34_valid_plus_resize_202_pad_256_bs_24',\n",
    "          'unet_resnet_152_exp_0_202_256_scheduler_150_epochs_finetune',\n",
    "          'unet_resnet_152_exp_0_202_256_scheduler_150_epochs_finetune'\n",
    "\n",
    "         ]\n",
    "model_pathes = ['/home/branding_images/salt/'+x for x in models]\n",
    "res = evaluate(model_pathes, train[train.fold.isin([0])].id.values, 0.5, classification='')\n",
    "print(\"{} / {} / {}\".format(np.round(np.mean(res['iout']),5),np.round(np.mean(res['dice']),5),np.round(np.mean(res['jacard']),5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.88037 / 0.91051 / 0.89145\n",
    "\n",
    "0.8816 / 0.91113 / 0.89206"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import evaluate, evaluate_exp\n",
    "\n",
    "for l in range(6):\n",
    "    low_value = l*0.05\n",
    "    high_value = l*0.05\n",
    "    del_pixels = l*50\n",
    "    thr = l*0.05\n",
    "    print(thr)\n",
    "    res = evaluate_exp(model_pathes, train[train.fold.isin([0])].id.values, 0.5, classification=''\n",
    "                       ,low_value=0.5,pixels=3,del_pixels=del_pixels)\n",
    "    print(\"{} / {} / {}\".format(np.round(np.mean(res['iout']),5),np.round(np.mean(res['dice']),5),np.round(np.mean(res['jacard']),5)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial:\n",
    "0.87272 / 0.90683 / 0.88683\n",
    "\n",
    "thr 0.55:\n",
    "0.87457 / 0.90655 / 0.88679\n",
    "\n",
    "<= 5 pixels:\n",
    "0.87556 / 0.90655 / 0.88678"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linspace(0.5, 0.5, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thr_mask_1 = np.zeros((101,101))\n",
    "thr_mask_1+=0.5\n",
    "thr_mask_2 = np.zeros((101,101))\n",
    "thr_mask_2+=0.5\n",
    "for row, const in enumerate(np.linspace(0.1, 0.5, 10)):\n",
    "    thr_mask_1[row, :] = const\n",
    "    thr_mask_1[-row, :] = const\n",
    "    thr_mask_2[:, row] = const\n",
    "    thr_mask_2[:, -row] = const\n",
    "thr_mask = (thr_mask_1+thr_mask_2)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(thr_mask != 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.87272 / 0.90683 / 0.88683\n",
    "\n",
    "0.80062 / 0.86009 / 0.83598\n",
    "0.83506 / 0.88435 / 0.86126\n",
    "0.84765 / 0.89313 / 0.87048\n",
    "\n",
    "thr 0.4\n",
    "0.84 / 0.88604 / 0.86306"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.plot.scatter('metric','num_of_pixel_in_mask')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mosaic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('data/depths.csv')\n",
    "data=f.readlines()\n",
    "f.close()\n",
    "\n",
    "fils=[]\n",
    "dep=[]\n",
    "\n",
    "for i in data[1:]:\n",
    "    fils.append(i.split(',')[0])\n",
    "    dep.append(float(i.split(',')[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_='/home/p/babakhin/Branding/salt/'\n",
    "\n",
    "fnames=[]\n",
    "imag=[]\n",
    "r=[]\n",
    "l=[]\n",
    "u=[]\n",
    "d=[]\n",
    "dept=[]\n",
    "mask=[]\n",
    "\n",
    "#No mask generation\n",
    "ema=np.zeros((101,101))\n",
    "ema[0,:]=255\n",
    "\n",
    "for filename in os.listdir(dir_+'train/images'):\n",
    "    fnames.append(filename)\n",
    "    fimg=cv2.imread(dir_+'train/images/'+filename,0)\n",
    "    mask.append(cv2.imread(dir_+'/train/masks/'+filename,0))\n",
    "    imag.append(fimg)\n",
    "    r.append(fimg[:,-1])\n",
    "    l.append(fimg[:,0])\n",
    "    u.append(fimg[-1,:])\n",
    "    d.append(fimg[0,:])\n",
    "    dept.append(dep[fils.index(filename.split('.')[0])])\n",
    "\n",
    "for filename in os.listdir(dir_+'test/images'):\n",
    "    fnames.append(filename)\n",
    "    fimg=cv2.imread(dir_+'test/images/'+filename,0)\n",
    "    mask.append(ema)\n",
    "    imag.append(fimg)\n",
    "    r.append(fimg[:,-1])\n",
    "    l.append(fimg[:,0])\n",
    "    u.append(fimg[-1,:])\n",
    "    d.append(fimg[0,:])\n",
    "    dept.append(dep[fils.index(filename.split('.')[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=np.random.randint(22000,size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m=[20449,4439, 18152, 6156, 16461,3535,8944,15799,21609,453]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=np.random.randint(22000,size=5)\n",
    "for x in m:\n",
    "\n",
    "    corr_r=[]\n",
    "    corr_l=[]\n",
    "\n",
    "    for i in range(0,len(l)):\n",
    "        if i==x:\n",
    "            corr_r.append(0)\n",
    "        else:\n",
    "            corr_r.append(np.corrcoef(u[x],d[i])[0,1])\n",
    "\n",
    "    # Finding index of max correlation\n",
    "    ri=corr_r.index(max(corr_r))\n",
    "\n",
    "    # Normalization of images\n",
    "    a=imag[x]-np.mean(imag[x])\n",
    "    b=imag[ri]-np.mean(imag[ri])\n",
    "\n",
    "    mina=min([np.amin(a),np.amin(b)])\n",
    "    maxa=min([np.amax(a),np.amax(b)])\n",
    "\n",
    "    plt.figure(figsize=(7,10))\n",
    "    plt.subplot(211)\n",
    "    plt.imshow(a,cmap='gray',vmin=mina,vmax=maxa)\n",
    "    plt.imshow(mask[x],cmap='Greens',vmin=0,vmax=255,alpha=0.2)\n",
    "    plt.axis('off')\n",
    "    plt.text(50, 100, dept[x], fontsize=12)\n",
    "    plt.subplot(212)\n",
    "    plt.imshow(b,cmap='gray',vmin=mina,vmax=maxa)\n",
    "    plt.imshow(mask[ri],cmap='Greens',vmin=0,vmax=255,alpha=0.2)\n",
    "    plt.axis('off')\n",
    "    plt.text(0, 10, str(max(corr_r))[:5], fontsize=12)\n",
    "    plt.text(50, 100, dept[ri], fontsize=12)\n",
    "\n",
    "    # Tight layout of images\n",
    "    plt.suptitle(str(x))\n",
    "    plt.subplots_adjust(wspace=0, hspace=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m=np.random.randint(4000,size=1)\n",
    "for x in np.random.randint(22000,size=1):\n",
    "\n",
    "    corr_r=[]\n",
    "    corr_l=[]\n",
    "\n",
    "    for i in range(0,len(l)):\n",
    "        if i==x:\n",
    "            corr_r.append(0)\n",
    "        else:\n",
    "            corr_r.append(np.corrcoef(r[x],l[i])[0,1])\n",
    "\n",
    "    # Finding index of max correlation\n",
    "    ri=corr_r.index(max(corr_r))\n",
    "\n",
    "    # Normalization of images\n",
    "    a=imag[x]-np.mean(imag[x])\n",
    "    b=imag[ri]-np.mean(imag[ri])\n",
    "\n",
    "    mina=min([np.amin(a),np.amin(b)])\n",
    "    maxa=min([np.amax(a),np.amax(b)])\n",
    "\n",
    "    \n",
    "    if max(corr_r) > 0.:\n",
    "    \n",
    "        plt.figure(figsize=(10,7))\n",
    "        plt.subplot(121)\n",
    "        plt.imshow(a,cmap='gray',vmin=mina,vmax=maxa)\n",
    "        plt.imshow(mask[x],cmap='Greens',vmin=0,vmax=255,alpha=0.2)\n",
    "        plt.axis('off')\n",
    "        plt.text(50, 100, dept[x], fontsize=12)\n",
    "        plt.subplot(122)\n",
    "        plt.imshow(b,cmap='gray',vmin=mina,vmax=maxa)\n",
    "        plt.imshow(mask[ri],cmap='Greens',vmin=0,vmax=255,alpha=0.2)\n",
    "        plt.axis('off')\n",
    "        plt.text(0, 10, str(max(corr_r))[:5], fontsize=12)\n",
    "        plt.text(50, 100, dept[ri], fontsize=12)\n",
    "\n",
    "        # Tight layout of images\n",
    "        plt.suptitle(str(x))\n",
    "        plt.subplots_adjust(wspace=0, hspace=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "359 + 481 -- 0.933\n",
    "\n",
    "198+516 -- 0.789 -?\n",
    "\n",
    "311 + 764 -- 0.539\n",
    "\n",
    "557 + 618"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
